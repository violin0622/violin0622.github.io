<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sonata for solo Violin on Sonata for solo Violin</title>
    <link>https://violinsonata.site/</link>
    <description>Recent content in Sonata for solo Violin on Sonata for solo Violin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 04 Sep 2020 15:05:10 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Golang使用gRPC指南</title>
      <link>https://violinsonata.site/2020/use-grpc-in-golang/</link>
      <pubDate>Fri, 04 Sep 2020 15:05:10 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/use-grpc-in-golang/</guid>
      <description>

&lt;p&gt;本文以一个简单的CURD服务为例演示了如果一步步使用grpc的接口.&lt;/p&gt;

&lt;h2 id=&#34;使用protobuf&#34;&gt;使用protobuf&lt;/h2&gt;

&lt;h3 id=&#34;编写proto文件&#34;&gt;编写proto文件&lt;/h3&gt;

&lt;p&gt;proto文件是定义整个protobuf生态的基石, protobuf,grpc, grpc-gateway等代码都是通过proto文件来生成桩代码的.&lt;br /&gt;
proto文件主要包含 syntax, package, option, import, message, service 等几部分.&lt;br /&gt;
- syntax&lt;br /&gt;
  用于指定proto文件使用了protobuf协议的版本. 可以选择proto2或proto3, 推荐使用较新的版本proto3;
- package&lt;br /&gt;
  用于指定当前proto文件所在的包名称, 只需要声明完整包名的最后一部分即可. 例如某个文件&lt;code&gt;A.proto&lt;/code&gt;位于&lt;code&gt;github.com/someproject/api/Apple.proto&lt;/code&gt;, 那么这个文件的package只需要指定some_apis即可.&lt;br /&gt;
- option&lt;br /&gt;
  用于针对特定场景设定一些选项. 例如在v1.20以后的版本中, 用户如果想要将proto编译成Golang代码, 就需要指定&lt;code&gt;go_package&lt;/code&gt;选项.
- import&lt;br /&gt;
  proto文件可以分成多个, 不同的proto文件之间可以使用import字段互相引用, 达到代码复用的目的. import声明的路径可以是相对路径, 例如如果引入同一个目录下的其他proto文件, 则可以直接写文件名. 如果引入其他目录的文件, 也不必从文件系统根目录或项目根目录开始写起, 但是在编译的时候必须通过&lt;code&gt;-I&lt;/code&gt;参数指明找到被引入文件的起始路径, 换句话说 &lt;code&gt;-I&lt;/code&gt;+&lt;code&gt;import&lt;/code&gt; 需要指向proto文件的路径.
- message&lt;br /&gt;
  message用于定义数据结构.  如果不使用grpc远程调用, 而只是用protobuf作为数据传输的格式的话,  那么只需要定义message即可, 不需要定义service.
- service&lt;br /&gt;
  用于定义API服务的通信接口.&lt;/p&gt;

&lt;p&gt;我们先只用protobuf, 因此只需要不需要声明service, 只需要定义message就够了.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package api;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;;

message Apple{
  int32 number = 1;
  string name = 2;
  Size size = 3;

  enum Size{
    SIZE_UNDEFINED = 0;
    BIG = 4;
    MID = 5;
    SMALL = 6;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载protoc工具&#34;&gt;下载protoc工具&lt;/h3&gt;

&lt;p&gt;protoc 是用于编译proto文件生成对应桩代码的命令行工具. protoc工具使用C++编写, 其项目地址位于&lt;a href=&#34;https://github.com/protocolbuffers/protobuf&#34;&gt;https://github.com/protocolbuffers/protobuf &lt;/a&gt; .&lt;br /&gt;
对于非C++的用户, 可以直接下载预先编译好的二进制文件: &lt;a href=&#34;https://github.com/protocolbuffers/protobuf/releases&#34;&gt;https://github.com/protocolbuffers/protobuf/releases &lt;/a&gt;, 例如对于macOS用户, 选择 &lt;code&gt;protobuf-3.13.0-osx-x86_64.tar.gz&lt;/code&gt;下载解压, 并放在$PATH下面.&lt;/p&gt;

&lt;h3 id=&#34;下载protoc插件-protoc-gen-go&#34;&gt;下载protoc插件: protoc-gen-go&lt;/h3&gt;

&lt;p&gt;protoc编译proto文件时, 根据生成不同语言的桩代码的需求, 需要指定不同的插件. 例如需要生成Golang的桩代码, 便需要指定go语言的插件: &lt;code&gt;protoc-gen-go&lt;/code&gt;.&lt;br /&gt;
值得一提的是, golang的插件在2020年初经历了比较大的变更: 原来其项目地址位于&lt;a href=&#34;https://github.com/golang/protobuf&#34;&gt;github.com/golang/protobuf&lt;/a&gt;, 代码中的导入地址是 &lt;code&gt;github.com/golang/protobuf/proto&lt;/code&gt;, 其版本迭代到 v1.4,  2020年三月份由新的项目取代: &lt;a href=&#34;https://github.com/protocolbuffers/protobuf-go&#34;&gt;google.golang.org/protobuf&lt;/a&gt;, 版本从 v1.20 开始迭代. v1.20相对于v1.4作出了许多重大的变更, 包括部分API变更, 以及原有的部分可导出模块不再导出. 对于中国开发者来说比较重要的变更在于修复了打印结构体内的非ASCII字符会乱码的bug( &lt;a href=&#34;https://github.com/golang/protobuf/issues/572&#34;&gt;Issue #572&lt;/a&gt; ).&lt;br /&gt;
插件可以直接在项目的Github Release页面下载编译好的版本, 或者 git clone 然后自行安装:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone -b v1.31 git@github.com:protocolbuffers/protobuf-go.git
cd protobuf-go
# go install 会将项目编译生产的二进制文件放入 $GOPATH/bin. 
# 需要把 $GOPATH/bin 加入 $PATH 以使protoc能够找到. 
go install .
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;编译使用的命令参数可以见另一篇文章.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
  --go_out=paths=source_relative:. \
  api/apple.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以在api目录下看到生成的桩代码 &lt;code&gt;apple.pb.go&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── README.md
├── api
│   ├── apple.pb.go
│   └── apple.proto
├── go.mod
└── main.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;为了使用 apple.pb.go, 我们还需要在Golang代码中导入protobuf的运行库 &lt;code&gt;google.golang.org/protobuf/proto&lt;/code&gt;, 然后利用其中的&lt;code&gt;Marshal&lt;/code&gt;和&lt;code&gt;Unmashal&lt;/code&gt; 两个API 进行消息的编码解码.
&lt;a href=&#34;https://github.com/protocolbuffers/protobuf/blob/master/examples/add_person.go&#34;&gt;examples&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main
import(
	&amp;quot;bufio&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;strings&amp;quot;

  `google.golang.org/protobuf/proto`

  `github.com/grpc-apple/api`
)

func main(){
	if len(os.Args) != 2 {
		log.Fatalf(&amp;quot;Usage:  %s ADDRESS_BOOK_FILE\n&amp;quot;, os.Args[0])
	}
	fname := os.Args[1]

	// Read the existing address book.
	in, err := ioutil.ReadFile(fname)
	if err != nil {
		if os.IsNotExist(err) {
			fmt.Printf(&amp;quot;%s: File not found.  Creating new file.\n&amp;quot;, fname)
		} else {
			log.Fatalln(&amp;quot;Error reading file:&amp;quot;, err)
		}
	}

	// [START marshal_proto]
	book := &amp;amp;pb.AddressBook{}
	// [START_EXCLUDE]
	if err := proto.Unmarshal(in, book); err != nil {
		log.Fatalln(&amp;quot;Failed to parse address book:&amp;quot;, err)
	}

	// Add an address.
	addr, err := promptForAddress(os.Stdin)
	if err != nil {
		log.Fatalln(&amp;quot;Error with address:&amp;quot;, err)
	}
	book.People = append(book.People, addr)
	// [END_EXCLUDE]

	// Write the new address book back to disk.
	out, err := proto.Marshal(book)
	if err != nil {
		log.Fatalln(&amp;quot;Failed to encode address book:&amp;quot;, err)
	}
	if err := ioutil.WriteFile(fname, out, 0644); err != nil {
		log.Fatalln(&amp;quot;Failed to write address book:&amp;quot;, err)
	}
	// [END marshal_proto]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使用grpc&#34;&gt;使用grpc&lt;/h2&gt;

&lt;p&gt;我们需要查询, 创建, 更新, 修改, 删除五个接口.&lt;/p&gt;

&lt;h3 id=&#34;编写proto文件-1&#34;&gt;编写proto文件&lt;/h3&gt;

&lt;p&gt;事实上, 所有的定义都可以写进一个proto文件里, 不过在复杂项目中这样显然不好. 本文使用了多个不同目录下的proto文件, 以演示在复杂项目中不同的定义是怎样互相引用的.&lt;br /&gt;
此处我们为了定义五个接口而在新的目录&lt;code&gt;api/operation/&lt;/code&gt;创建了新的&lt;code&gt;operations.proto&lt;/code&gt;文件.&lt;br /&gt;
值得一提的是导入&lt;code&gt;apple.proto&lt;/code&gt;文件时指定的路径. 上文已经说了import与-I参数的关系, 实际上这两个参数还关系着生成的桩代码的位置. 在本项目中, 希望将桩代码与对应的proto文件放在一起.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package operation;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;;
// 引入protobuf官方提供的Empty结构作为部分接口的空返回值. 
import &amp;quot;google/protobuf/empty.proto&amp;quot;;
// 引入protobuf官方提供的Field_Mask用于支持修改操作. 
import &amp;quot;google/protobuf/field_mask.proto&amp;quot;;
// 引入上级目录的apple文件以复用定义
import &amp;quot;api/apple.proto&amp;quot;;

service AppleService{
  rpc DescribeApple(DescribeAppleRequest) returns (api.Apple) {}
  rpc CreateApple(CreateAppleRequest) returns (api.Apple) {}
  rpc UpdateApple(UpdateAppleRequest) returns (api.Apple) {}
  rpc ModifyApple(ModifyAppleRequest) returns (api.Apple) {}
  rpc DestroyApple(DestroyAppleRequest) returns (google.protobuf.Empty) {}
}

// 为了提供调用接口, 我们新声明了五个消息类型, 需要定义. 
message DescribeAppleRequest{
  int32 number = 1;
}
message CreateAppleRequest{
  string name = 2;
  api.Apple.Size size = 3;
}
// 更新操作: 必须指定对象全部的属性, 
// 对于未指定的属性, 应该将其设定为空或默认值; 
message UpdateAppleRequest{
  int32 number = 1;
  string name = 2;
  api.Apple.Size size = 3;
}
// 修改操作: 只需要设定对象需要变更的属性, 
// 对于未指定的属性, 会保留原来的值. 
// grpc中为了支持修改操作, 需要添加额外的FieldMask字段. 
// 不过好在该字段的值不需要用户设定, grpc会自动生成. 
message ModifyAppleRequest{
  int32 number = 1;
  string name = 2;
  api.Apple.Size size = 3;
  google.protobuf.FieldMask mask = 4;
}

message DestroyAppleRequest{
  string name = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载protoc插件-protoc-gen-go-grpc&#34;&gt;下载protoc插件: protoc-gen-go-grpc&lt;/h3&gt;

&lt;p&gt;同 protoc-gen-go 一样, 生成grpc代码也需要对应的插件: protoc-gen-go-grpc. 在&lt;code&gt;github.com/golang/protobuf&lt;/code&gt;将protoc-gen-go代码的归属权托管给了&lt;code&gt;golang.google.org/grpc-go&lt;/code&gt;(参考&lt;a href=&#34;https://github.com/golang/protobuf/issues/903&#34;&gt;golang/protobuf #903&lt;/a&gt;), 从此作为grpc-go的一个工具, 生成grpc桩代码的方式也发生了巨大的变化.&lt;br /&gt;
在protoc-go v1.4 版本之前, 也就是旧项目中, protoc-grpc是作为 protoc-gen-go的插件存在的, 也就是protoc的插件的插件.&lt;br /&gt;
而在 protoc-go v1.20 之后, 也就是新项目中, protoc-grpc是作为protoc的插件存在, 也就是“升级”了, 从插件的插件变成了独立的插件.&lt;br /&gt;
proto-gen-go-grpc 目前还没有发布预编译的新插件, 想要使用的话必须自行编译安装:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 直接安装:
go get -u google.golang.org/grpc

# 或者这样:
git clone git@github.com:grpc/grpc-go.git
cd grpc-go &amp;amp;&amp;amp; go install .
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译-1&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;由于存在新旧两种插件, 因此编译命令也有了两种.&lt;br /&gt;
值得一提的是, protoc 不支持一次性编译多个包, 如果指定了多个包, 会造成错误.&lt;br /&gt;
旧版命令:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
    --go_out=plugins=grpc,paths=source_relative:. \
    api/apple.proto 

protoc \
  -Iapi
  --go_out=plugins=grpc,paths=source_relative:. \
  api/operation/operations.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新版命令:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
  --go_out=paths=source_relative:. \
  --go-grpc_out=paths=source_relative:. \
  api/apple.proto

protoc \
  --go_out=paths=source_relative:. \
  --go-grpc_out=paths=source_relative:. \
  api/operation/operations.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显然新版命令比旧版的更长了 -,-!&lt;/p&gt;

&lt;p&gt;编译之后可以看到proto文件所在目录下多了生成的桩代码.
&lt;code&gt;apple.pb.go&lt;/code&gt;是为api/apple.proto生成的; &lt;code&gt;operations.pb.go&lt;/code&gt; 是为operations.proto中的message生成的; &lt;code&gt;operations_grpc.pb.go&lt;/code&gt; 是为operations.proto中service的部分生成的. 为什么message和service要分别生成两个文件, 我也不知道.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── README.md
├── api
│   ├── apple.pb.go
│   ├── apple.proto
│   └── operation
│       ├── operations.pb.go
│       ├── operations.proto
│       └── operations_grpc.pb.go
├── go.mod
└── main.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;实现接口&#34;&gt;实现接口&lt;/h3&gt;

&lt;p&gt;新建一个service 包, 将几个接口的具体实现放在里面:&lt;br /&gt;
service/service.go:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package service

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
)

// protoc-gen-go-grpc v1.20 之后, 实现服务的时候必须嵌入 UnimplementedAppleServiceServer 以保证能够向后兼容.
type AppleService struct {
	UnimplementedAppleServiceServer
}

func (*AppleService) DescribeApple(ctx context.Context, req *DescribeAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) CreateApple(ctx context.Context, req *CreateAppleRequest) (*Apple, error) {
	log.Println(req)
	return &amp;amp;Apple{}, nil
}
func (*AppleService) UpdateApple(ctx context.Context, req *UpdateAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) ModifyApple(ctx context.Context, req *ModifyAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) DestroyApple(ctx context.Context, req *DestroyAppleRequest) (*empty.Empty, error) {
	return &amp;amp;empty.Empty{}, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用-1&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;代码位于&lt;code&gt;simple-grpc&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	&amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
)


func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;AppleService{})
	reflection.Register(grpcServer)

	if l, err := net.Listen(`tcp`, `:9000`); err != nil {
		log.Fatal(`cannot listen to port 9000: `, err)
	} else if err = grpcServer.Serve(l); err != nil {
		log.Fatal(`cannot start service:`, err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使用grpc-gateway&#34;&gt;使用grpc-gateway&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/grpc-gateway&#34;&gt;grpc-gateway&lt;/a&gt; 是grpc-ecosystem 的子项目, 用于提供grpc的反向代理, 实现开发GRPC, 提供RestAPI的目的.&lt;br /&gt;
grpc-gateway 同样也是 protoc 的插件, 并且仅支持生成Golang语言的桩代码.&lt;br /&gt;
但是, 生成的反向代理可以作为独立的进程, 因此实际可以支持各种语言的grpc服务.  只不过作为Golang语言可以实现更多的特性, 比如复用端口同时提供grpc和http两种接口.&lt;/p&gt;

&lt;h3 id=&#34;修改operations-proto&#34;&gt;修改operations.proto&lt;/h3&gt;

&lt;p&gt;为了使用grpc-gateway, 需要在 operations.proto 中引入grpc-gateway的proto文件, 并在每个rpc中添加配置.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package operation;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/operation/api&amp;quot;;
// 引入protobuf官方提供的Empty结构作为部分接口的空返回值. 
import &amp;quot;google/protobuf/empty.proto&amp;quot;;
// 引入protobuf官方提供的Field_Mask用于支持修改操作. 
import &amp;quot;google/protobuf/field_mask.proto&amp;quot;;
// 引入annotation用于定义gateway
import &amp;quot;google/api/annotations.proto&amp;quot;;
// 引入上级目录的apple文件以复用定义
import &amp;quot;apple.proto&amp;quot;;

service AppleService{
  rpc DescribeApple(DescribeAppleRequest) returns (Apple) {
    option (google.api.http).get = &amp;quot;/apples/{number}&amp;quot;;
  }
  rpc CreateApple(CreateAppleRequest) returns (Apple) {
    option (google.api.http) = {
      post: &amp;quot;/apples&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc UpdateApple(UpdateAppleRequest) returns (Apple) {
    option (google.api.http) = {
      put: &amp;quot;/apples/{number}&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc ModifyApple(ModifyAppleRequest) returns (Apple) {
    option (google.api.http) = {
      patch: &amp;quot;/apples/{number}&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc DestroyApple(DestroyAppleRequest) returns (google.protobuf.Empty) {
    option (google.api.http).delete = &amp;quot;/apples/{number}&amp;quot;;
  }
}

// 为了提供调用接口, 我们新声明了五个消息类型, 需要定义. 
message DescribeAppleRequest{
  int32 number = 1;
}
message CreateAppleRequest{
  string name = 2;
  Apple.Size size = 3;
}
// 更新操作: 必须指定对象全部的属性, 
// 对于未指定的属性, 应该将其设定为空或默认值; 
message UpdateAppleRequest{
  int32 number = 1;
  string name = 2;
  Apple.Size size = 3;
}
// 修改操作: 只需要设定对象需要变更的属性, 
// 对于未指定的属性, 会保留原来的值. 
// grpc中为了支持修改操作, 需要添加额外的FieldMask字段. 
// 不过好在该字段的值不需要用户设定, grpc会自动生成. 
message ModifyAppleRequest{
  int32 number = 1;
  string name = 2;
  Apple.Size size = 3;
  google.protobuf.FieldMask mask = 4;
}

message DestroyAppleRequest{
  int32 number = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载-protoc-gen-grpc-gateway&#34;&gt;下载 protoc-gen-grpc-gateway&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get github.com/grpc-ecosystem/grpc-gateway
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译-2&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;apple.proto 我们已经编译过了并且没有修改过, 因此可以直接编译 operations.proto&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
    -I. \
    -I$GOPATH/pkg/mod/github.com/grpc-ecosystem/grpc-gateway@v1.14.8/third_party/googleapis  \
    --go_out=paths=source_relative:. \
    --go-grpc_out=paths=source_relative:. \
    --grpc-gateway_out=paths=source_relative:. \
    api/operation/*.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用-2&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;由于grpcServer监听端口会把线程Hang住, 因此需要通过&lt;code&gt;go&lt;/code&gt;操作符创建额外的goroutine用于运行监听函数.&lt;br /&gt;
程序运行起来之后会监听两个端口: grpc服务监听本地8000端口, http服务监听本地9000端口, 并把请求转发到8000端口的grpc服务上.&lt;br /&gt;
此时可以使用 curl localhost:8000 通过http方式访问, 也可以使用 grpcurl -plaintext localhost:9000 通过grpc方式访问.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
)

// protoc-gen-go-grpc v1.20 之后, 实现服务的时候必须嵌入 UnimplementedAppleServiceServer 以保证能够向后兼容.
type AppleService struct {
	UnimplementedAppleServiceServer
}

func (*AppleService) DescribeApple(ctx context.Context, req *DescribeAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) CreateApple(ctx context.Context, req *CreateAppleRequest) (*Apple, error) {
	log.Println(req)
	return &amp;amp;Apple{}, nil
}
func (*AppleService) UpdateApple(ctx context.Context, req *UpdateAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) ModifyApple(ctx context.Context, req *ModifyAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) DestroyApple(ctx context.Context, req *DestroyAppleRequest) (*empty.Empty, error) {
	return &amp;amp;empty.Empty{}, nil
}

func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;AppleService{})
	reflection.Register(grpcServer)
	l, _ := net.Listen(`tcp`, `:8000`)
	go grpcServer.Serve(l)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithInsecure()},
	)

	if err := http.ListenAndServe(`:9000`, httpServer); err != nil {
		log.Fatal(`cannot start service: `, err)
	}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway-与-grpc-使用相同的端口-使用tls&#34;&gt;gateway 与 grpc 使用相同的端口(使用TLS)&lt;/h2&gt;

&lt;p&gt;基本思路是通过判断 Content-Type 字段来分辨入请求是基于HTTP还是GRPC, 然后分别转发到对应的server handler上.&lt;br /&gt;
代码位于 reuse-port-tls/server.go&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;strings&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/credentials&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	&amp;quot;github.com/violin0622/grpc-apple/service&amp;quot;
)

func main() {
	serverCred, err := credentials.NewServerTLSFromFile(`./server.pem`, `./server.key`)
	if err != nil {
		log.Fatal(err)
	}
	clientCred, err := credentials.NewClientTLSFromFile(`./server.pem`, `localhost`)
	if err != nil {
		log.Fatal(err)
	}

	grpcServer := grpc.NewServer(grpc.Creds(serverCred))
	RegisterAppleServiceServer(grpcServer, &amp;amp;service.AppleService{})
	reflection.Register(grpcServer)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithTransportCredentials(clientCred)},
	)

	http.ListenAndServeTLS(`:8000`, `./server.pem`, `./server.key`,
		http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {

			if r.ProtoMajor == 2 &amp;amp;&amp;amp;
				strings.Contains(r.Header.Get(`Content-Type`), `application/grpc`) {
				log.Println(`grpc`)
				grpcServer.ServeHTTP(w, r)
			} else {
				log.Println(`http`)
				httpServer.ServeHTTP(w, r)
			}
		}),
	)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway-与-grpc-使用相同的端口-不使用tls&#34;&gt;gateway 与 grpc 使用相同的端口(不使用TLS)&lt;/h2&gt;

&lt;p&gt;代码位于 reuse-port-insecure/server.go.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;strings&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;golang.org/x/net/http2&amp;quot;
	&amp;quot;golang.org/x/net/http2/h2c&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	&amp;quot;github.com/violin0622/grpc-apple/service&amp;quot;
)

func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;service.AppleService{})
	reflection.Register(grpcServer)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithInsecure()},
	)

	http.ListenAndServe(
		`:8000`,
		h2c.NewHandler(
			http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {

				if r.ProtoMajor == 2 &amp;amp;&amp;amp;
					strings.Contains(r.Header.Get(`Content-Type`), `application/grpc`) {
					log.Println(`grpc`)
					grpcServer.ServeHTTP(w, r)
				} else {
					log.Println(`http`)
					httpServer.ServeHTTP(w, r)
				}
			}),
			&amp;amp;http2.Server{}),
	)
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Golang使用私有仓库</title>
      <link>https://violinsonata.site/2020/use-private-repo-in-golang/</link>
      <pubDate>Mon, 31 Aug 2020 14:51:20 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/use-private-repo-in-golang/</guid>
      <description>

&lt;p&gt;本文基于&lt;code&gt;go 1.13&lt;/code&gt;即以上进行演示。&lt;br /&gt;
将go代码推送到私有仓库之后， 如果想要在其他项目引用， 需要做以下设置。&lt;/p&gt;

&lt;h2 id=&#34;设置go-env&#34;&gt;设置go env&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 设置代理， 多个用逗号分隔， 最后direct是直接从项目地址拉取。 
# 这一步不是使用私有仓库必须设置的. 但是考虑到国内的网络情况, 应该大部分gopher都设置了该项吧. 
go env -w GOPROXY=&amp;quot;https://goproxy.cn,direct&amp;quot;

# 设置不使用代理的域名, 用逗号分开多个。 可以设置通配符*，或者指定路径
go env -w GOPRIVATE=&amp;quot;*.gitlab.com,private.gitlab.com/myrepo&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;设置git-token&#34;&gt;设置git token&lt;/h2&gt;

&lt;p&gt;只设置了 go env 还不够。 无论 go mod 也好， go get 也好， 都是依赖git来拉取项目代码的， 如果git没有访问仓库的权限依然不能正确拉取。&lt;br /&gt;
以 Gitlab 为例， 需要创建一个访问Token， go 控制 git 拉取代码时使用该token进行认证， 才可以拉取代码。&lt;br /&gt;
&lt;img src=&#34;https://violinsonata.site/post/resources/_gen/images/申请gitlab的token.png&#34; alt=&#34;申请token&#34; /&gt;&lt;/p&gt;

&lt;p&gt;创建token之后， 对git进行全局设置:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git config --global url.&amp;quot;https://{username}:{token}@private.gitlab.com/myrepo&amp;quot;.insteadOf &amp;quot;https://private.gitlab.com/myrepo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以正常拉取私有仓库的代码了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;note&lt;/code&gt; Coding的设置和Gitlab不太一样。 首先Coding的代码仓库网页URI和Git地址并不一样。&lt;br /&gt;
例如我的项目访问网页时地址是&lt;code&gt;https://mlt.coding.net/p/riverrun/gogfapi&lt;/code&gt;， 而git地址是&lt;code&gt;https://e.coding.net/mlt/riverrun/gogfapi.git&lt;/code&gt;。&lt;br /&gt;
在设置GOPRIVATE和git时， 应使用git地址， 且最后需要附带&lt;code&gt;.git&lt;/code&gt;。 在项目中引用模块时， &lt;code&gt;import&lt;/code&gt; 语句也需要写git地址， 同样需要带着&lt;code&gt;.git&lt;/code&gt;后缀。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basic Concept of Rabbitmq</title>
      <link>https://violinsonata.site/2020/basic-concept-of-rabbitmq/</link>
      <pubDate>Mon, 24 Aug 2020 15:25:07 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/basic-concept-of-rabbitmq/</guid>
      <description>

&lt;h2 id=&#34;message-消息&#34;&gt;Message 消息&lt;/h2&gt;

&lt;p&gt;消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;从消息的属性可以看出， RabbitMQ支持至少三个特性：
1. 同一个消息路由分发至不同的队列中。&lt;br /&gt;
2. 不同的消息之间有优先级。
3. 消息可以进行有选择的持久化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;publisher-生产者&#34;&gt;Publisher 生产者&lt;/h2&gt;

&lt;p&gt;一个向交换器发布消息的客户端应用程序。 生产者并不会直接将消息发送到队列中， 而是发送到服务端的交换器上， 再由交换器按预设条件将消息分发到各个队列上， 或者直接将消息丢弃。&lt;/p&gt;

&lt;h2 id=&#34;exchange-交换器&#34;&gt;Exchange 交换器&lt;/h2&gt;

&lt;p&gt;用来接收生产者发送的消息并将这些消息路由给服务器中的队列。&lt;br /&gt;
&amp;gt; 在RabbitMQ中， 消息并不是由生产者直接写入队列中的。 而是每条消息发到一个指定的交换器中， 再由交换器根据绑定的交换规则分发到队列中。 如果路由不到，或返回给生产者，或直接丢弃，或做其它处理。&lt;/p&gt;

&lt;p&gt;Exchange 具有四种类型，&lt;code&gt;direct&lt;/code&gt;, &lt;code&gt;fanout&lt;/code&gt;, &lt;code&gt;header&lt;/code&gt;, &lt;code&gt;topic&lt;/code&gt;。 &lt;code&gt;header&lt;/code&gt; 和&lt;code&gt;topic&lt;/code&gt;功能一样， 但性能较差， 不推荐使用。&lt;/p&gt;

&lt;h3 id=&#34;fanout&#34;&gt;Fanout&lt;/h3&gt;

&lt;p&gt;通过队列名进行绑定。 可以绑定多个队列， 每个消息都会发送到所有绑定的队列上。&lt;br /&gt;
扇形交换器不受RoutingKey和BindingKey的限制。&lt;br /&gt;
&amp;gt; 使用Fanout就相当于将消息广播到所有绑定的队列上。&lt;/p&gt;

&lt;h3 id=&#34;direct&#34;&gt;Direct&lt;/h3&gt;

&lt;p&gt;交换器通过BindingKey和队列进行绑定， 生产者每条发送的消息都要带有一个RoutingKey。 交换器通过BindingKey和RoutingKey的匹配进行分发。 只有完全匹配（即RoutingKey == BindingKey）的才可以分发到对应的队列中。 如果一条消息不满足任意一个绑定键， 那么它将会被丢弃。&lt;br /&gt;
绑定时有如下几个特点：&lt;br /&gt;
- 不同的队列可以通过不同的BindingKey绑定到同一个交换器上， 此时交换器会根据消息的RoutingKey选择发送到哪个队列。
- 多个不同的队列可以通过相同的BindingKey绑定到同一个交换器上， 交换器会将匹配的消息发送到通过该BindingKey绑定的所有队列上。
- 单个队列可以使用多个BindingKey绑定到同一个交换器上， 当交换器收到满足任意一个BindingKey的消息时， 都会将消息发送到该队列上。&lt;/p&gt;

&lt;h3 id=&#34;topic&#34;&gt;Topic&lt;/h3&gt;

&lt;p&gt;主题交换器只能接受特定格式的路由键——必须是使用点&lt;code&gt;.&lt;/code&gt;分隔开的若干个单词， 整个字符串最多255个字节。 与直连交换器类似， 主题交换器同样根据绑定队列时的绑定键和收到消息时的路由键来决定将消息分发到哪些队列上。 不同的是， 主题交换器允许在&lt;strong&gt;绑定键&lt;/strong&gt;中使用两种通配符：&lt;br /&gt;
1. &lt;code&gt;*&lt;/code&gt;， 代表一个由点分隔开的单词
2. &lt;code&gt;#&lt;/code&gt;， 代表0个或多个单词&lt;/p&gt;

&lt;p&gt;主题交换器同样支持直连交换器那样的复杂绑定。 当一个队列同时通过多个带有通配符的绑定键绑定到一个交换器上， 如果交换器发现一条消息的路由键同时匹配该队列的多个绑定键， 那么这条消息只会向该队列写入一次。&lt;/p&gt;

&lt;h3 id=&#34;默认交换器&#34;&gt;默认交换器&lt;/h3&gt;

&lt;p&gt;如果生产者在发送消息时不指定交换器， 可以使用空字符串指定默认交换器。 默认交换器会使用&lt;code&gt;RoutingKey&lt;/code&gt;作为分发消息的依据。&lt;/p&gt;

&lt;h2 id=&#34;routingkey-bindingkey-路由键-绑定键&#34;&gt;RoutingKey/BindingKey 路由键/绑定键&lt;/h2&gt;

&lt;p&gt;将交换器与队列绑定到一起时指定的绑定规则叫做绑定键。 生产者发送消息时指定的分发规则叫做路由键。 不过在实际编程时，这两个参数可能使用相同的名称。 例如在python代码中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 虽然参数叫 routing_key, 但实际是指定了绑定键
channel.queue_bind(exchange=&#39;topic_logs&#39;, queue=queue_name, routing_key=&#39;*.topic&#39;)

# 发送消息时指定了路由键
channel.basic_publish(exchange=&#39;topic_logs&#39;, routing_key=&#39;log.topic&#39;, body=&#39;hello world&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;binding-绑定&#34;&gt;Binding 绑定&lt;/h2&gt;

&lt;p&gt;绑定用于将服务器上的特定队列和交换器关联起来。 但是绑定操作并不是由服务器管理员执行的， 而是由客户端在生产时或消费时自行指定的。
如果一个交换器没有绑定任何队列， 那么发到这个交换器的消息就会被丢弃。&lt;/p&gt;

&lt;h2 id=&#34;queue-队列&#34;&gt;Queue 队列&lt;/h2&gt;

&lt;p&gt;用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 消息默认保存在内存中， 除非在创建队列时声明其支持持久化，  并且发送消息时声明该消息需要持久化， 这样该消息就会被刷写到磁盘中。&lt;/p&gt;

&lt;h3 id=&#34;临时队列&#34;&gt;临时队列&lt;/h3&gt;

&lt;p&gt;如果客户端在创建队列的时候使用了空字符串作为队列名， 则服务器会使用随机名称创建一个临时队列。 当消费者断开链接时， 临时队列就会被删除。 临时队列适用于消费者不关心队列中的“旧”数据， 而是希望每次连接到服务器时即可消费到最新数据的场景。&lt;br /&gt;
生产者生产消息时不需要知道队列的名字——它们只是将消息发送到交换器上。 但是消费者需要知道队列的名称。 因此临时队列需要由消费者来创建， 并且由消费者绑定到与生产者约定好的交换器上。&lt;/p&gt;

&lt;h2 id=&#34;channel-信道&#34;&gt;Channel 信道&lt;/h2&gt;

&lt;p&gt;由于创建销毁TCP链接是很昂贵的操作， 因此RabbitMQ提出了信道这一概念以复用TCP链接。 一个TCP链接中可以包含多个信道， 每个信道用于生产/消费不同的队列。&lt;/p&gt;

&lt;h2 id=&#34;vhost-虚拟机&#34;&gt;VHost 虚拟机&lt;/h2&gt;

&lt;p&gt;RabbitMQ使用vhost 进行资源隔离。 每个vhost内部可以创建独立的交换器，绑定， 队列， 信道， 不同vhost内的各项资源互不可见。 通过为不同用户分配不同vhost的访问权限， 实现用户隔离。&lt;/p&gt;

&lt;h2 id=&#34;consumer-消费者&#34;&gt;Consumer 消费者&lt;/h2&gt;

&lt;p&gt;一个从消息队列中取得消息的客户端应用程序。 在RabbitMQ中， 同一个队列可以由多个客户端同时消费。 此时RabbitMQ会按顺序将消息一个个分发给客户端， 每个客户端拿到的数据各不相同， 称为Round-Robin。 因此同一队列中的一条消息只能在全局被消费一次。&lt;/p&gt;

&lt;h2 id=&#34;消息ack&#34;&gt;消息ACK&lt;/h2&gt;

&lt;p&gt;当RabbitMQ认为消费者已经成功消费到消息之后， 就会将消息删除。 并且由于其不同客户端遵循Round-Robin机制，  这就意味着如果有一个客户端在拿到消息之后还没来得及处理就挂掉了， 则这条消息也不会被其他客户端处理到。&lt;br /&gt;
为了解决这个问题， RabbitMQ引入了ACK机制并默认开启。 开启此参数意味着只有当客户端收到并处理完了消息， 向服务器发送了ACK之后， 服务器才会将该消息标记为已消费并将其删除。 如果客户端因为种种原因未能响应ACK（如客户端挂掉， 网络超时等因素）， 则服务器会将该消息重新发送给其他消费此队列的客户端。&lt;br /&gt;
&amp;gt; 在使用ack机制时， 客户端一定要在处理完消息之后向服务器发送ACK， 否则服务器永远不知道客户端已经处理过了该消息。 它只能将消息一遍遍地发送到其他客户端上， 并且将数据一直保存在内存中。 随着堆积的消息增多，服务端内存会爆掉。&lt;/p&gt;

&lt;h2 id=&#34;持久化&#34;&gt;持久化&lt;/h2&gt;

&lt;p&gt;RabbitMQ 默认不会对消息进行持久化，其将数据存放于内存中, 宕机即会丢数。 如果需要持久化， 则需要创建一个带持久化参数的队列， 并在发送消息时指定持久化参数为True。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;channel.queue_declare(queue=&#39;task_queue&#39;, durable=True)

channel.basic_publish(exchange=&#39;&#39;,
                      routing_key=&amp;quot;task_queue&amp;quot;,
                      body=message,
                      properties=pika.BasicProperties(
                         delivery_mode = 2, # make message persistent
                      ))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>SSL/TLS的工作原理</title>
      <link>https://violinsonata.site/2020/detail-of-ssl-and-tls/</link>
      <pubDate>Thu, 13 Aug 2020 15:26:47 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/detail-of-ssl-and-tls/</guid>
      <description>

&lt;h2 id=&#34;网络通信过程中可能遇到的风险与应对&#34;&gt;网络通信过程中可能遇到的风险与应对&lt;/h2&gt;

&lt;p&gt;网络通信过程中的数据安全将要面临三个风险:
1. 窃听风险(eavesdropping)
2. 篡改风险(tampering)
3. 冒充风险(pretending)&lt;/p&gt;

&lt;p&gt;为了应对这三个风险， SSL/TLS 协议包含如下机制：&lt;/p&gt;

&lt;h3 id=&#34;1-信息使用密钥加密-使第三方无法窃听&#34;&gt;1. 信息使用密钥加密， 使第三方无法窃听。&lt;/h3&gt;

&lt;p&gt;但是通信双方加密传播数据， 就需要在通信之前先交换密钥， 而交换密钥的过程如果使用明文， 则密钥本身有可能被窃听， 从而导致通信数据也有了被窃听的风险。&lt;/p&gt;

&lt;p&gt;解决方案是借助非对称加密来交换通信密钥。 令服务器拥有私钥和公钥， 服务器把自己公钥明文地发给客户端， 客户端接着生成一个密钥， 然后拿公钥加密这个密钥， 将加密后的密钥返回给服务器， 此时该密钥只有服务器端的私钥能够解密，从而完成了通信密钥的加密传输。  公钥一般放在证书中。&lt;/p&gt;

&lt;p&gt;在实际应用中， 通常是在TLS握手阶段由客户端和服务端共同生成并交换两个明文的随机数， 再由客户端生成一个密文随机数并使用公钥加密传递给服务端， 最后双方使用相同的摘要算法对三个数计算出真正的通信密钥。&lt;/p&gt;

&lt;h3 id=&#34;2-具有校验机制-第三方无法篡改-或已经篡改立刻发现&#34;&gt;2. 具有校验机制， 第三方无法篡改， 或已经篡改立刻发现。&lt;/h3&gt;

&lt;p&gt;一般来说， 通过在发送数据时附带摘要， 即可令接收方辨别数据被篡改。&lt;/p&gt;

&lt;p&gt;但是摘要本身也是可以被篡改的， 因此摘要本身也需要被加密， 可以将摘要附在数据的后面一起被加密， 接收端解密之后再次将数据计算摘要并与发送端附带的摘要进行比对， 即可知道数据是否被篡改过。&lt;/p&gt;

&lt;h3 id=&#34;3-身份验证-第三方无法冒充&#34;&gt;3. 身份验证， 第三方无法冒充。&lt;/h3&gt;

&lt;p&gt;身份验证使用的就是证书机制， 而颁发证书的机构就是CA机构。&lt;br /&gt;
证书的工作机制比较复杂， 基本思想是引入一个权威的第三方为通信双方的身份做担保。（这个第三方不是指窃听数据的第三方。）&lt;br /&gt;
如果客户端需要保证服务器没有被冒充， 那么服务器需要向客户端提供证书以供其验证， 这种模式叫做单向验证； 如果通信双方都需要保证对方没有被冒充， 则需要互换证书各自验证， 称为双向验证。&lt;br /&gt;
证书中有几个基本信息:&lt;br /&gt;
- 颁发者。 也就是上一级CA
- 受发者。 也就是申请证书的人， 通常是一个域名或通配符域名。
- 有效期。
- 公钥。 公钥是服务端密钥对的其中之一， 客户端收到证书并验证成功后， 用此公钥加密&lt;code&gt;第三个随机数&lt;/code&gt;以交换通信密钥。
- 摘要算法。 用于指示证书签名使用的摘要算法。&lt;/p&gt;

&lt;h4 id=&#34;申请证书&#34;&gt;申请证书&lt;/h4&gt;

&lt;p&gt;假设有一个权威的认证机构CA， 服务端想要让客户端认证自己的身份， 需要将自己的证书名和公钥提交给CA供其审核。 CA自身带有一对公钥和私钥， 审核通过后， 会使用自身的私钥加密服务端提交证书的摘要（称为&lt;code&gt;签名&lt;/code&gt;）， 将签过名的证书发还给服务端。&lt;/p&gt;

&lt;h4 id=&#34;交换-验证证书&#34;&gt;交换、验证证书&lt;/h4&gt;

&lt;p&gt;既然CA是权威的， 那么客户端可以信任该CA， 并保存CA的公钥(例如， 浏览器会内置很多可信的CA机构的证书)。 在TLS握手阶段， 服务端会将证书发送给客户端， 客户端拿到证书检查颁发人， 找出本地保存的对应CA的公钥， 使用该公钥对证书的签名进行解密， 比对证书的明文内容和签名解密出的摘要是否一致。 如果一致则认为验证通过。 如果是双向认证， 则客户端也会将自身证书发向服务端， 服务端执行同样的验证。&lt;/p&gt;

&lt;h4 id=&#34;证书链&#34;&gt;证书链&lt;/h4&gt;

&lt;p&gt;世界公认权威的CA（根证书的拥有者）是有限的， 而需要验证的客户端是无限的， 如果要一一审核太慢了。 因此基于“我信任你， 你信任他， 因此我信任他”的信任传递， 有了证书链。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://violinsonata.site/post/resources/_gen/images/证书链.png&#34; alt=&#34;浏览器中的证书链&#34; /&gt;
&lt;center style=&#34;font-size:14px;color:#C0C0C0;text-decoration:underline&#34;&gt;本站的证书链&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;假设客户端添加了权威CA的根证书， 权威CA签发了二级CA， 二级CA签发了三级网站。 客户端与服务端网站通信时， 如果服务端只发送自身的网站证书， 则客户端只能找到颁发者二级CA， 而由于其没有信任二级CA（没有保存二级CA的公钥）， 从而无法完成验证。 因此客户端需要发送自身的证书， 以及签发者二级CA的证书。 客户端先验证网站证书是否由二级CA签发， 再验证二级CA的签发人， 直到发现某一级证书的签发人是自己信任的， 从而完成了证书验证。 如果走完证书连也没有发现可信任的签发人， 则认为该证书是不可信的[1]。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;防伪造： 未经过CA验证的不法网站可以使用假的证书， 但由于客户端没有信任假证书的CA， 因此无法通过验证。&lt;/li&gt;
&lt;li&gt;防篡改： 签名比对机制杜绝了证书交换过程中被第三方篡改。&lt;/li&gt;
&lt;li&gt;防冒充： 钓鱼网站可以使用服务端公开的证书冒名顶替， 但是因为没有私钥， 因此无法解密客户端发送的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ssl-tls-基本的运行过程&#34;&gt;SSL/TLS 基本的运行过程&lt;/h2&gt;

&lt;p&gt;在建立链接阶段总体的流程如下：&lt;br /&gt;
1. 客户端向服务器索要并验证公钥
2. 双方协商生成“对话密钥”
3. 双方采用“对话密钥”进行加密通信&lt;/p&gt;

&lt;p&gt;TLS 报文的格式
TLS报文自身分为两层: &lt;code&gt;Record层&lt;/code&gt;和&lt;code&gt;负载层&lt;/code&gt;. Record层的结构比较简单, 就是TVL格式:
- Content Type: 用于声明负载层的类型. 对于握手报文, 就是&lt;code&gt;Handshake(22)&lt;/code&gt;, 对于数据报文, 就是&lt;code&gt;Application Data(23)&lt;/code&gt;, 对于加密变更声明, 就是&lt;code&gt;Change Cipher Spec(20)&lt;/code&gt;, 对于报警, 就是&lt;code&gt;Alert(21)&lt;/code&gt;.
- Version: 协议的版本, 现在比较常用的就是 &lt;code&gt;TLS 1.0&lt;/code&gt;, &lt;code&gt;TLS 1.1&lt;/code&gt;, &lt;code&gt;TLS 1.2&lt;/code&gt;, &lt;code&gt;TLS 1.3&lt;/code&gt;.
- Length: 负载层的长度, 字节为单位.&lt;/p&gt;

&lt;p&gt;对于一个典型的TLS握手过程, 双方总共会按顺序通信如下请求:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Client Hello&lt;/li&gt;
&lt;li&gt;Server Hello&lt;/li&gt;
&lt;li&gt;Server Certificate&lt;/li&gt;
&lt;li&gt;Server Key Exchange&lt;/li&gt;
&lt;li&gt;Certificate Request&lt;/li&gt;
&lt;li&gt;Server Hello Done&lt;/li&gt;
&lt;li&gt;Client Certificate&lt;/li&gt;
&lt;li&gt;Client Key Exchange&lt;/li&gt;
&lt;li&gt;Change Cipher Spec&lt;/li&gt;
&lt;li&gt;Encrypted Handshake Message&lt;/li&gt;
&lt;li&gt;Change Cipher Spec&lt;/li&gt;
&lt;li&gt;Encrypted Handshake Message&lt;/li&gt;
&lt;li&gt;Application Data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在没有回话复用, 单TCP包仅承载单个TLS请求的情况下, 双方的通信过程是这样的:&lt;/p&gt;

&lt;div class=&#34;mermaid&#34; align=&#34; 
                                center
                            &#34;&gt; 
    

sequenceDiagram
  participant client
  participant server

  client -&gt;&gt; + server: Client Hello
  server --&gt;&gt; - client: TCP Ack
  server -&gt;&gt; + client: Server Hello
  client --&gt;&gt; - server: TCP Ack
  server -&gt;&gt; + client: Server Certificate
  client --&gt;&gt; - server: TCP Ack
  opt RSA/DN/ECHD/ 等算法不会发送
    server -&gt;&gt; + client: Server Key Exchange
    client --&gt;&gt; - server: Tcp Ack
  end
  client -&gt;&gt; client: 验证服务端的证书/证书链
  alt 双向认证
    server -&gt;&gt; + client: Certificate Request
    client --&gt;&gt; - server: Tcp Ack
    server -&gt;&gt; + client: Server Hello Done
    client --&gt;&gt; - server: Tcp Ack
    client -&gt;&gt; + server: Client Certificate
    server --&gt;&gt; - client: TCP Ack
    server -&gt;&gt; server: 验证客户端的证书/证书链
  else 单向认证
    server -&gt;&gt; + client: Server Hello Done
    client --&gt;&gt; - server: Tcp Ack
  end
  client -&gt;&gt; + server: Client Key Exchange
  server --&gt;&gt; - client: TCP Ack
  client -&gt;&gt; + server: Change Cipher Message
  server --&gt;&gt; - client: TCP Ack
  client -&gt;&gt; + server: Encrypted Handshake Message
  server --&gt;&gt; - client: TCP Ack
  server -&gt;&gt; + client: Change Cipher Message
  client --&gt;&gt; - server: TCP Ack
  server -&gt;&gt; + client: Encrypted Handshake Message
  client --&gt;&gt; - server: TCP Ack

  loop 开始传输数据
    server -&gt;&gt; + client: Application Data
    client --&gt;&gt; - server: TCP Ack
  end


&lt;/div&gt;


&lt;script async src=&#34;https://unpkg.com/mermaid@8.2.3/dist/mermaid.min.js&#34;&gt;&lt;/script&gt;



&lt;p&gt;实际上, TLS握手的时候, 客户端与服务端双方会根据情况将多个TLS报文压缩到一个TCP数据包中, 因此在使用Wireshark抓包时经常看到一个数据包中有多个TLS报文.&lt;/p&gt;

&lt;h3 id=&#34;client-hello&#34;&gt;Client Hello&lt;/h3&gt;

&lt;p&gt;客户端向服务端发送加密通信的请求，称作 &lt;code&gt;ClientHello请求&lt;/code&gt; 。该请求使用明文传输。&lt;br /&gt;
ClientHello请求将向服务端提供以下信息：&lt;br /&gt;
- Version:&lt;br /&gt;
  客户端支持的最高加密协议版本
- Random:&lt;br /&gt;
  客户端生成的随机数random_C， 用作&lt;code&gt;对话密钥&lt;/code&gt;.
- Session Id &amp;amp; Session Length:
  会话ID. 会话ID由服务端生成, 并在Server Hello中告知客户端. 如果是第一次建立链接, 会话ID为0; 如果是短时间内再次建立连接, 会使用上次的会话ID.
- Cipher Suites &amp;amp; Cipher Suites Length:&lt;br /&gt;
  客户端支持的加密套件列表, 服务端会从中选出一个用于之后协商过程使用的套件.
- Compression Methods &amp;amp; Compression Methods Length:&lt;br /&gt;
  客户端支持的压缩方法. 目前没有用上, 一般留作空.&lt;br /&gt;
- Extention &amp;amp; Extentions Length:&lt;br /&gt;
  扩展字段. 包括会话复用在内的很多TLS的高级功能通过扩展字段来实现.  Extentions Length 是倒数第二个字段, 标识了扩展字段列表的长度(字节). 然后就是连续若干项Extention字段的列表.&lt;/p&gt;

&lt;p&gt;客户端发送的信息之中不包括服务器的域名。 也就是说， 理论上服务器只能包含一个网站， 否则会分不清应该向客户端提供哪一个网站的数字证书。 这就是为什么通常一台服务器只能有一张数字证书的原因。&lt;/p&gt;

&lt;h3 id=&#34;server-hello&#34;&gt;Server Hello&lt;/h3&gt;

&lt;p&gt;服务端使用明文向客户端发送请求，内容包括:&lt;br /&gt;
- Version:&lt;br /&gt;
  服务端选择的双方协商使用的加密协议版本. 一般会选择客户端服务端都支持的最高的版本.
- Random:&lt;br /&gt;
  服务端生成的随机数 random_S, 用于生成&lt;code&gt;对话密钥&lt;/code&gt;.
- Session ID &amp;amp; Session ID Length:&lt;br /&gt;
  服务端生成的会话ID, 或上一次链接时使用的会话ID.&lt;br /&gt;
- Cipher Suite:&lt;br /&gt;
  服务端从客户端提供的加密套件列表中选择一个, 告知客户端.&lt;br /&gt;
- Compression Method:&lt;br /&gt;
  服务端从客户端提供的压缩算法中选择一个告知客户端. 不过现在客户端一般留空, 服务端没得选, 也只能返回空.&lt;br /&gt;
- Extention &amp;amp; Extention Length:&lt;br /&gt;
  具体作用未知.&lt;/p&gt;

&lt;h3 id=&#34;server-certificate&#34;&gt;Server Certificate&lt;/h3&gt;

&lt;p&gt;服务端向客户端发送自身的证书, 明文传输.
- Certificate Length:&lt;br /&gt;
  证书长度(字节).
- Certificates:&lt;br /&gt;
  证书链.&lt;/p&gt;

&lt;h3 id=&#34;server-hello-done&#34;&gt;Server Hello Done&lt;/h3&gt;

&lt;p&gt;没有信息, 负载为空&lt;/p&gt;

&lt;h3 id=&#34;client-key-exchange&#34;&gt;Client Key Exchange&lt;/h3&gt;

&lt;p&gt;客户端收到证书后会验证证书。 如果证书不是可信机构颁布、 或者证书中的域名与实际域名不一致、 或者证书已经过期， 就会向访问者显示一个警告， 由其选择是否还要继续通信。
如果证书没有问题， 客户端就会从证书中取出服务器的公钥。 然后， 向服务器发送Client Key Exchange. 这个请求使用单独的类型, Content-Type是&lt;code&gt;Client Key Exchange(16)&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PubKey:&lt;br /&gt;
随机数 Pre-Master. 这个数字是使用服务端的公钥加密过的. 是协商密钥过程中唯一真正加密通信的数据.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;客户端会根据通信过程中双方生成的三个随机数， 使用约定的加密方法生成真正的会话密钥。
服务端收到报文后, 通过之前通信过程中生成的三个随机数 random_C, random_S, Pre-Master, 生成真正的会话密钥。&lt;/p&gt;

&lt;h3 id=&#34;encrypted-handshake-message-change-cipher-spec&#34;&gt;Encrypted Handshake Message &amp;amp; Change Cipher Spec&lt;/h3&gt;

&lt;p&gt;服务端和客户端在各自计算出真正的会话密钥后, 会向对方发送一个 Change Cipher Spec 报文, 该报文没有负载信息, 只是告知对方自己接下来要发送的报文都将使用密钥加密.&lt;br /&gt;
然后再向对方发送一个 Encrypted Handshake Message, 里面的负载是之前双方协商过的信息的哈希值, 但此次使用密钥加密负载. 双方收到对方发来的加密报文后, 解密并比对自身数据作为最后验证. 如果比对不一致则报错停止此次握手, 如果一致则TLS链接成功建立.&lt;/p&gt;

&lt;h3 id=&#34;application-data&#34;&gt;Application Data&lt;/h3&gt;

&lt;p&gt;TLS链接建立后双方通信的TLS报文都是Application Data.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参考:
&lt;a href=&#34;https://blog.csdn.net/mrpre/article/details/77867063&#34;&gt;https://blog.csdn.net/mrpre/article/details/77867063&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用Golang创建守护进程</title>
      <link>https://violinsonata.site/2020/create-daemon-process-in-golang/</link>
      <pubDate>Thu, 13 Aug 2020 15:07:00 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/create-daemon-process-in-golang/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main
 
import (
    &amp;quot;os&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;os/signal&amp;quot;
    &amp;quot;syscall&amp;quot;
    &amp;quot;time&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;os/exec&amp;quot;
)
func init() {
    // 如果本进程的父进程不是init进程, 则
    // 创建与本进程相同的子进程, 然后退出, 使
    // 子进程被init进程接管, 从而创建了守护进程. 
    if os.Getppid() != 1{
        cmd := exec.Command(os.Args[0], os.Args[1:]...)
        cmd.Start()
        os.Exit(0)
    }
 
    // 监听系统信号
    go func() {
        _c := make(chan os.Signal, 1)
        signal.Notify(_c, 
            os.Interrupt, 
            syscall.SIGHUP, 
            syscall.SIGINT, 
            syscall.SIGTERM, 
            syscall.SIGQUIT, 
            syscall.SIGKILL, 
            syscall.SIGTSTP
        )
        msg := &amp;lt;- _c
        log.Println(msg)
        os.Exit(0)
    }()
}
 
func main()  {
 
    go func(){
        fp, _ := os.OpenFile(&amp;quot;log&amp;quot;, os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0644)
        log.SetOutput(fp)
        for{
            log.Println(fmt.Sprint(&amp;quot;hello &amp;quot;, os.Getpid()))
            time.Sleep(time.Second * 5)
        }
    }()
    
    for{
        time.Sleep(time.Second * 1000)
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>网络安全基本概念</title>
      <link>https://violinsonata.site/2020/basic-concepts-of-network-security/</link>
      <pubDate>Wed, 12 Aug 2020 16:30:09 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/basic-concepts-of-network-security/</guid>
      <description>

&lt;h2 id=&#34;对称加密&#34;&gt;对称加密&lt;/h2&gt;

&lt;p&gt;对称加密很简单， 就是消息传递的双方共享同一个密码。 消息发送人用密码对消息进行加密， 然后将密文发给给消息接收人， 消息接受人使用此密码对密文进行解密， 然后阅读。&lt;br /&gt;
优点： 计算量小， 加密效率高。&lt;br /&gt;
缺点： 密码安全系数并不是特别高 （知道密码的人比较多）。&lt;/p&gt;

&lt;h2 id=&#34;非对称加密&#34;&gt;非对称加密&lt;/h2&gt;

&lt;p&gt;非对称加密是指消息传递双发使用不同的密码， 两个密码分别被称为私钥和公钥。 私钥和公钥之间具备一定的数学关系： 私钥加密的内容只有对应的公钥才能解密， 公钥加密的内容只有对应的私钥才能解密。&lt;br /&gt;
需要使用此加密方式的人会具备私钥和公钥， 私钥只有自己知道， 公钥则对特定群体或者所有人公开。&lt;br /&gt;
优点： 安全， 私钥只有自己一个人知道， 不用担心被窃听。&lt;br /&gt;
缺点： 计算量较大， 效率低， 不适合对大量内容进行加密。&lt;/p&gt;

&lt;h2 id=&#34;消息摘要-简称摘要&#34;&gt;消息摘要(简称摘要)&lt;/h2&gt;

&lt;p&gt;使用单向哈希算法， 以任意长度的报文计算得到的固定长度的哈希值。 所谓单向是指改算法是不可逆的， 根据消息摘要无法计算出输入报文。&lt;br /&gt;
消息摘要的另一个特点是： 对输入报文的任何改动， 都会导致最终的计算结果 （也就是消息摘要本身） 发生巨大的变化。 因此，消息摘要可以认为是数字信息的指纹。&lt;br /&gt;
&amp;gt; 常见的消息摘要算法有SHA， MD5等。&lt;/p&gt;

&lt;h2 id=&#34;数字签名-简称签名&#34;&gt;数字签名(简称签名)&lt;/h2&gt;

&lt;p&gt;数字签名与在纸上的物理签名效果类似——保证消息的真实性与不可伪造。 签名过程通常是消息的发送方首先生成消息报文的消息摘要， 然后使用自己的私钥对消息摘要进行加密， 加密之后的消息摘要就是消息报文的签名， 将和消息报文一起发送给消息接收方。&lt;br /&gt;
如果消息接受方需要验证真伪， 首先使用消息发送方的公钥对数字签名进行解密从而得到报文消息摘要 （如果解密失败，则签名肯定有问题）。 然后使用相同的消息摘要算法重新计算接受到的消息报文的消息摘要， 如果计算得到的消息摘要与解密得到的消息摘要不一致， 则消息报文被人篡改。&lt;/p&gt;

&lt;h2 id=&#34;数字证书-简称证书&#34;&gt;数字证书(简称证书)&lt;/h2&gt;

&lt;p&gt;数字证书类似网上身份证， 由第三方权威机构签发， 用于鉴别证书持有人的身份的真实性。 数字证书上包含了证书持有人的基本信息 （如：网站域名、 邮箱地址等）、 证书持有人的公钥、 证书颁发机构信息、 证书颁发机构的数字签名以及证书有效期。&lt;br /&gt;
数字证书的申请过程通常是： 证书申请人向证书签发机构提交申请， 申请中包含申请人身份的基本信息以及申请人公钥。 证书签发机构通过各种手段核实申请来源以及申请信息的真实性。 核实通过之后， 真实签发机构向申请人签发数字证书。&lt;br /&gt;
证书签发机构也有一个证书， 其中包含了证书签发机构的公钥。 任何人都可以获得该证书， 并使用此证书来验证该机构签发的所有证书的真伪。 默认情况下， 大多数操作系统内已经内置了全球知名证书签发单位的根证书。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker容器中访问宿主机网络</title>
      <link>https://violinsonata.site/2020/access-host-network-in-docker/</link>
      <pubDate>Wed, 08 Apr 2020 14:41:12 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/access-host-network-in-docker/</guid>
      <description>

&lt;h2 id=&#34;docker容器监听宿主机端口&#34;&gt;Docker容器监听宿主机端口&lt;/h2&gt;

&lt;h3 id=&#34;使用端口映射&#34;&gt;使用端口映射&lt;/h3&gt;

&lt;p&gt;现在假设有一个Docker容器nginx， 它运行时将监听docker内的80端口， 此时宿主机的80端口并没有被占用， 也无法将请求传入容器中。&lt;br /&gt;
如果需要容器监听宿主机的80端口， 那么需要在启动容器时进行端口映射。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 由于映射了宿主机的80和443端口， 低于1024， 因此需要使用root用户启动docker. 
docker run -d \
    --name nginx \
    -p 80:80 -p 443:443 \
    nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-p&lt;/code&gt;选项接收&lt;code&gt;{宿主机端口}:{容器端口}&lt;/code&gt;格式的参数， 可以多次指定以指定多个端口映射。&lt;/p&gt;

&lt;h3 id=&#34;使用host网络模式&#34;&gt;使用host网络模式&lt;/h3&gt;

&lt;p&gt;Docker容器启动时有&lt;code&gt;host&lt;/code&gt;, &lt;code&gt;bridge&lt;/code&gt;, &lt;code&gt;none&lt;/code&gt; 三种网络模式， 默认是使用&lt;code&gt;bridge&lt;/code&gt;桥接模式， 这种模式下可以使用端口映射的方式监听宿主机端口。
不过也可以使用&lt;code&gt;--network&lt;/code&gt;选项指定&lt;code&gt;host&lt;/code&gt;模式， 这种模式下容器与宿主机共享网络， 因此可以直接监听与请求宿主机上的网络端口。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 使用host模式可以直接监听宿主机网络端口，不必使用-p进行端口映射。 
docker run -d \
    --network host \
    --name nginx-docker \
    nginx:latest

# 也可以直接访问宿主机端口。  
docker run --rm \
    --network host \
    --name curl-docker \
    alpine curl localhost:80 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker容器访问宿主机端口&#34;&gt;Docker容器访问宿主机端口&lt;/h2&gt;

&lt;p&gt;从Docker容器中访问宿主机的端口有两种方式&lt;/p&gt;

&lt;h3 id=&#34;指定宿主机ip-linux&#34;&gt;指定宿主机IP (Linux)&lt;/h3&gt;

&lt;p&gt;在安装Docker的时候，会在宿主机安装一个虚拟网卡docker0, docker0对应的地址就是容器访问宿主机的地址。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ ip addr show docker0
4: docker0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:73:74:56:03 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:73ff:fe74:5603/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到docker0对应的地址为 &lt;code&gt;172.17.0.1&lt;/code&gt;, 那么启动docker时可以这样:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm \
    --name curl-docker \
    alpine curl 172.17.0.1:80
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;指定宿主机ip-mac&#34;&gt;指定宿主机IP (mac)&lt;/h3&gt;

&lt;p&gt;macOS的情况与Linux系统不同， Docker原生不支持macOS， mac上安装的Docker程序实质上是一个带着Docker的Linux虚拟机,  因此macOS上不会有 docker0 网卡。&lt;br /&gt;
不过这种情况也有专门的解决方案， 那就是使用特殊的地址 &lt;code&gt;docker.for.mac.localhost&lt;/code&gt; 代替。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm \
    --name curl-docker \
    alpine curl docker.for.mac.localhost:80
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>MySQL常用操作</title>
      <link>https://violinsonata.site/2020/useful-operates-in-mysql/</link>
      <pubDate>Wed, 19 Feb 2020 15:14:38 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/useful-operates-in-mysql/</guid>
      <description>

&lt;h2 id=&#34;数据库概念关系&#34;&gt;数据库概念关系&lt;/h2&gt;

&lt;p&gt;服务器 -&amp;gt; 实例 -&amp;gt; 数据库 -&amp;gt; 表 -&amp;gt; 记录&lt;/p&gt;

&lt;h2 id=&#34;登录数据库实例&#34;&gt;登录数据库实例&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysql  \
    -u{用户名}  \   #如果不指定-u， 则使用 root 用户。
    -p{密码} \      #如果指定-p而不输入密码， 则会在交互式界面中询问密码。 这样可以避免密码泄漏。 
    -h{主机地址} \
    -P{服务端口}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;常用信息查看&#34;&gt;常用信息查看&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select user();      -- 当前用户
select database();  -- 当前数据库
select version();   -- 当前版本
select now();       -- 当前时间
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;数据库管理&#34;&gt;数据库管理&lt;/h2&gt;

&lt;h3 id=&#34;创建数据库&#34;&gt;创建数据库&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create database {数据库名}
    character set {字符集}      -- 可选参数
    collate {检查名}            -- 可选参数
    default encryption {Y/N};   -- 可选参数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;charactor set&lt;/code&gt; 用于指定数据库级别的字符集。 从MySQL8.0开始， 默认字符集是&lt;code&gt;utf8mb4&lt;/code&gt;, 这是一种支持 emoji 表情的utf8字符集。 🎉&lt;br /&gt;
&lt;code&gt;collate&lt;/code&gt; 用于指定数据库级别的字符型数据排序规则。 从8.0之后， 排序规则默认为&lt;code&gt;utf8mb4_0900_ai_ci&lt;/code&gt;。 一般不用改。&lt;br /&gt;
&lt;code&gt;encryption&lt;/code&gt; 用于指定数据库的加密算法。 默认为不使用加密。&lt;/p&gt;

&lt;h3 id=&#34;查看-删除数据库&#34;&gt;查看/删除数据库&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show databases;              -- 查看所有数据库
drop database {数据库名};   -- 删除指定名称的数据库
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导出数据&#34;&gt;导出数据&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;：如果在命令行指定了-p， 则导出的sql文件第一行会有个warnning：&lt;br /&gt;
&amp;gt; mysqldump: [Warning] Using a password on the command line interface can be insecure.&lt;/p&gt;

&lt;p&gt;这行warining不是注释，因此在其他数据库导入时会报语法错误。 解决办法有两个:&lt;br /&gt;
1. 在导出命令中不指定&lt;code&gt;-p&lt;/code&gt;参数， 使用交互方式输入密码。【推荐】
2. 在导出的sql文件中将这一行删除或注释掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysqldump -u{用户名} -p{密码} \
  -h{主机地址} -P{端口} \
  {数据库名}            #如果要导出所有数据库， 则库名表名都不用指定。 \
  {数据表名}            #如果要导出单个数据库所有表，则表名不用指定。 \
   &amp;gt; backup.sql         #重定向到备份文件中。 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导入数据&#34;&gt;导入数据&lt;/h3&gt;

&lt;p&gt;首先登陆数据库， 创建数据库与用户， 并为用户分配权限。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysql -u{用户名} -p{密码} -h{主机地址} -P{端口} {数据库名} &amp;lt; backup.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导出数据-docker内&#34;&gt;导出数据（docker内）&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker exec -it mysql-instance mysqldump -u{user} -p{password} &amp;gt; backup.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导入数据-docker内&#34;&gt;导入数据（docker内）&lt;/h3&gt;

&lt;p&gt;首先将文件拷贝到docker内， 然后在容器内的命令行执行导入命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker cp ./backup.sql mysql-instance:/tmp/backup.sql
docker exec mysql-instance &#39;mysql -u{user} -p{password} source /tmp/backup.sql&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用户管理&#34;&gt;用户管理&lt;/h2&gt;

&lt;h3 id=&#34;查看系统内所有用户及登录地址&#34;&gt;查看系统内所有用户及登录地址&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select distinct 
    concat(&#39;user: &#39;&#39;&#39;,user,&#39;&#39;&#39;@&#39;&#39;&#39;,host,&#39;&#39;&#39;;&#39;) as query 
    from mysql.user;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查看某个用户的所有权限&#34;&gt;查看某个用户的所有权限&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select * from mysql.user where user={用户名};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;mysql.user&lt;/code&gt;中， user和host两个字段共同构成主键。&lt;/p&gt;

&lt;h3 id=&#34;创建用户与授权&#34;&gt;创建用户与授权&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 创建与授权分两步
create user &#39;{用户名}&#39;@&#39;{主机域}&#39; identified by &#39;{密码}&#39;;
grant {权限列表} on {数据库名}.{数据表名} to &#39;{用户名}&#39;@&#39;{主机域}&#39;;
-- 分配所有权限
grant all on *.* to &#39;admin&#39;@&#39;localhost&#39;;
-- 查看用户的权限
show grants for &#39;{用户名}&#39;@&#39;{主机域}&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建用户时需要同时指定用户名和主机域， 因为它们共同构成&lt;code&gt;mysql.user&lt;/code&gt;的主键。 如果不限制该用户可以在哪台主机访问， 则主机域可以设定为&lt;code&gt;%&lt;/code&gt;， 代表任意主机。 如果不指定主机域， 同样使用&lt;code&gt;%&lt;/code&gt;作为默认值。&lt;/p&gt;

&lt;h2 id=&#34;数据表管理&#34;&gt;数据表管理&lt;/h2&gt;

&lt;h3 id=&#34;建表&#34;&gt;建表&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table 表名(
    -- not null, default, auto_increment, comment 都是可选参数
    id int not null  auto_increment comment &#39;主键&#39;,   
    name varchar(10) not null default &#39;&#39; comment &#39;名字&#39;,
    primary key(`id`),
    unique key `k索引名` (`name`) -- 最后一行不能以逗号结尾
)charset=utf8mb4;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;修改表&#34;&gt;修改表&lt;/h3&gt;

&lt;h4 id=&#34;新加字段&#34;&gt;新加字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 后一个列名用于指定新列的位置
alter table 表名 add column 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null after 列名;
-- 将新字段设置为第一列
alter table 表名 add column 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null first;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;删除字段&#34;&gt;删除字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 drop 字段名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更新字段&#34;&gt;更新字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 change 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null ;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;修改字段数据类型&#34;&gt;修改字段数据类型&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 modify 字段名 enum(&#39;M&#39;,&#39;F&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改字段数据类型之后， 其他的配置如 not null 等不会变。&lt;/p&gt;

&lt;h4 id=&#34;添加-删除字段默认值&#34;&gt;添加/删除字段默认值&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 alter 字段名 set default 默认值;
alter table 表名 alter 字段名 drop default;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;重命名表名&#34;&gt;重命名表名&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 rename to 新表名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;索引管理&#34;&gt;索引管理&lt;/h2&gt;

&lt;p&gt;除了可以在创建数据表等时候指定索引之外， 还可以单独对索引进行管理。&lt;/p&gt;

&lt;h3 id=&#34;查看索引&#34;&gt;查看索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show table from 表名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建索引&#34;&gt;创建索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create index 索引名 on 表名(字段名);
-- 创建唯一索引
create unique index 索引名 on 表名(字段名);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;删除索引&#34;&gt;删除索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop index 索引名 on 表名;
alter table  表名 drop index 索引名;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes中的容器配置管理：ConfigMap</title>
      <link>https://violinsonata.site/2019/configmap/</link>
      <pubDate>Mon, 16 Sep 2019 10:51:55 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/configmap/</guid>
      <description>

&lt;h2 id=&#34;什么是configmap&#34;&gt;什么是ConfigMap&lt;/h2&gt;

&lt;p&gt;ConfigMap ，即配置字典， 是Kubernetes提供的用于管理容器中程序运行所需配置的解决方案。 它是一种持久化的机制， 不会随着容器的创建销毁而变化。 容器启动时从ConfigMap中读取配置， 并且多个容器可以共享同一个ConfigMap。&lt;/p&gt;

&lt;h2 id=&#34;软件配置常见的几种形式&#34;&gt;软件配置常见的几种形式:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;环境变量&lt;br /&gt;
比如许多运行在Java虚拟机上的程序在启动时会读取&lt;code&gt;JAVA_HOME&lt;/code&gt;环境变量， 配置不同的环境变量值， 也就使用了不同的Java虚拟机。&lt;br /&gt;
再比如许多项目会使用环境变量来区分当前环境是&lt;code&gt;product&lt;/code&gt;,&lt;code&gt;develop&lt;/code&gt;,&lt;code&gt;test&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置文件&lt;br /&gt;
配置文件是最普及，最常用的一类配置形式。 无论是服务端程序还是客户端程序， 都会使用这种形式。&lt;br /&gt;
常见的配置文件格式有 &lt;code&gt;*.ini&lt;/code&gt;, &lt;code&gt;*.json&lt;/code&gt;, &lt;code&gt;*.xml&lt;/code&gt;, &lt;code&gt;*.conf&lt;/code&gt;, &lt;code&gt;*.yaml&lt;/code&gt;, &lt;code&gt;*.toml&lt;/code&gt;等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;命令行参数&lt;br /&gt;
这种形式用于命令行启动的程序， 并且常常会和配置文件，环境变量等形式搭配使用。 其优点在于灵活， 可以方便地对每次程序运行时指定不同的配置项， 因此很适合执行时间较短的程序， 例如压缩解压， 缺点在于总是会让整条命令变得又长又臭。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;远程配置中心&lt;br /&gt;
随着微服务架构的盛行， 配置不再需要存储在本地了， 程序启动之后会到远程的服务去读取配置， 用户启动时只需要“告诉”程序去哪里读取配置。  这种配置方式极大地简化了本地部署的步骤， 适用于在多台服务器上大量部署的程序， 是未来的发展趋势。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;插件&lt;br /&gt;
严格来说， 插件并不能算是一种配置形式。 因为它不像其他几种形式， 必须在程序刚刚启动时读取， 也不像其他几种形式， 通过用户编辑其内容来改变程序的行为。 插件更多的是在程序运行时根据需要或配置进行加载， 用以扩充程序的功能。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;创建配置字典的几种形式&#34;&gt;创建配置字典的几种形式&lt;/h2&gt;

&lt;p&gt;配置字典是一个键值对形式Map。 键是由用户随意指定的， 而值才是Pod中的进程期望读取的配置。 很多应用的配置格式本身就是键值对形式的， 比如Java提供的&lt;code&gt;*.properties&lt;/code&gt;文件就是键值对的列表。 在使用配置文件时应该将这个文件的内容整个作为配置字典中的&lt;code&gt;值&lt;/code&gt;, 而不是每个配置文件中的键值对对应一个配置字典中的键值对。&lt;/p&gt;

&lt;h3 id=&#34;在命令行直接通过键值对创建&#34;&gt;在命令行直接通过键值对创建&lt;/h3&gt;

&lt;p&gt;可以直接在命令行中指定键值对， 每个键值对都是一项配置。 就像这样:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Config 
      --from-literal=key1=value1 
      --from-literal=loglevel=&#39;INFO, stdout&#39; 
      --from-literal=java_home_env=/usr/lib/jre_1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过单个配置文件创建&#34;&gt;通过单个配置文件创建&lt;/h3&gt;

&lt;p&gt;也可以将一个本地的配置文件上传形成一个配置字典。 指定文件可以使用绝对路径， 也可以使用相对路径。&lt;br /&gt;
  &lt;code&gt;--from-file&lt;/code&gt;参数的key是可选的， 如果不指定的话， 默认使用文件名作为key。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-File-Config 
    --from-file=/home/app/config.properties 
    --from-file=config=/home/app/config.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过目录创建&#34;&gt;通过目录创建&lt;/h3&gt;

&lt;p&gt;很多应用都会同时使用多个配置文件， 而这些配置文件常常在同一个目录下。 因此当然也可以把一整个目录都创建成配置字典。&lt;br /&gt;
  &amp;gt; 从目录创建配置字典实际上是针对目录内的每个文件， 创建以文件名为key的配置项。 因此这种用法有两个注意点：&lt;br /&gt;
  &amp;gt; 1. 可以在一个配置字典中指定多个目录， 但是要保证所有这些目录中不能存在重名的文件。&lt;br /&gt;
  &amp;gt; 2. 不能指定key, 此时key只能是文件名。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Dir-Config 
    --from-file=/home/app 
    --from-file=config=/home/anothor
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过二进制文件创建&#34;&gt;通过二进制文件创建&lt;/h3&gt;

&lt;p&gt;二进制文件同样也可以用来创建配置字典。 不过并不是直接存储在配置字典中， 而是先对文件进行base64编码， 再把编码后的字符串存储在配置字典中。&lt;br /&gt;
  这是一种非常规用法， 一般不推荐。 如果文件太大的话， 会对k8s集群内的etcd造成压力。 另外上传时还可能会因为超时而中断请求。 仅适用于个别奇葩应用使用非文本形式的配置文件，或者一些程序会使用&lt;code&gt;.so&lt;/code&gt;或&lt;code&gt;.dill&lt;/code&gt;文件作为插件时使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Binary-Config 
    --from-file=/home/app/config.tar 
    --from-file=/home/app/plugin.so
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用命令行创建配置字典的缺陷&#34;&gt;使用命令行创建配置字典的缺陷&lt;/h3&gt;

&lt;p&gt;使用命令行直接创建配置字典的优点是方便直接。 但是缺点也有：
  - 除非使用 &amp;ndash;namespace 指定， 或者.kube/config文件中指定了命名空间， 否则该配置字典会在default命名空间内。&lt;br /&gt;
  - 能够指定配置字典的名称， 但是不能指定配置字典的Label(当然可以在创建之后再用 kubectl lable命令添加)。&lt;br /&gt;
  - 对于大量的配置， 使用命令行显然不方便。 好在&amp;ndash;from-file选项弥补了这一点。&lt;br /&gt;
  - 这是前面说到的&amp;rdquo;又长又臭的命令&amp;rdquo;的完美诠释。&lt;/p&gt;

&lt;p&gt;如果想要添加配置字典的Label， 需要两条命令。 首先创建一个配置字典， 然后使用&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl lable configmap My-ConfigMap key=value key2=value2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用yaml文件创建配置字典&#34;&gt;使用yaml文件创建配置字典&lt;/h3&gt;

&lt;p&gt;其实就是把想要配置的内容一股脑写到&lt;code&gt;data&lt;/code&gt;字段下面就好啦。 示例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion:  v1
kind: ConfigMap
metadata:
  labels:
    app: flume
  namespace: flume-namespace
  name: flume-config
data:
  flume.properties: |
    agent.sources = a1
    agent.channels = a1
    agent.sinks = a1
  log4j.properties: |
    flume.root.logger=INFO,console
    log4j.rootLogger=${flume.root.logger}
  java_home_env:
    /usr/lib/jre_1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;事实上， 当想要在命令行查看已创建的配置字典内容， 使用&lt;code&gt;kubectl get config flume-config -o yaml&lt;/code&gt;时， 看到的也是上面的形式。&lt;/p&gt;

&lt;h2 id=&#34;在pod内使用configmap的几种方式&#34;&gt;在Pod内使用ConfigMap的几种方式&lt;/h2&gt;

&lt;h3 id=&#34;用于容器内的环境变量&#34;&gt;用于容器内的环境变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: java
spec:
  containers:
  - name: test-container
    image: alpine
    command: [ &amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;echo $JAVA_HOME&amp;quot; ]
    env:
    - name: JAVA_HOME
      valueFrom:
        configMapKeyRef:
          name: My-Config
          key: java_home_env
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的目录&#34;&gt;用于容器内的目录&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ &amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;ls /etc/config/&amp;quot; ]
      volumeMounts:
      - name: configDir
        mountPath: /etc/config
  volumes:
    - name: configDir
      configMap:
        # Provide the name of the ConfigMap containing the files you want
        # to add to the container
        name: My-Dir-ConfigMap
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的文件&#34;&gt;用于容器内的文件&lt;/h3&gt;

&lt;p&gt;要注意， 当使用配置字典作为容器内的配置文件时， 会将目标目录整个覆盖， 只保留配置字典中存在的&amp;rdquo;key&amp;rdquo;, 也就是对应的配置文件。&lt;br /&gt;
这样造成的后果就是不能够仅更新某个目录下面的单个文件。 例如如果想要用配置字典更新 &lt;code&gt;/etc/hosts&lt;/code&gt;文件， 那么会导致 &lt;code&gt;/etc&lt;/code&gt; 目录下的其他文件都被抹除。 因此使用时一定要小心。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
  - name: test-container
    image: k8s.gcr.io/busybox
    command: [ &amp;quot;/bin/sh&amp;quot;,&amp;quot;-c&amp;quot;,&amp;quot;cat /etc/config/keys&amp;quot; ]
    volumeMounts:
    - name: config-volume
      mountPath: /etc/config
  volumes:
  - name: config-volume
    configMap:
      name: special-config
      items:
      - key: SPECIAL_LEVEL
        path: keys
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的命令行&#34;&gt;用于容器内的命令行&lt;/h3&gt;

&lt;p&gt;配置字典对于命令行形式的配置没有直接的支持， 不过可以通过设置环境变量， 然后在命令行中使用环境变量来间接地实现。&lt;/p&gt;

&lt;h3 id=&#34;用于容器内的插件&#34;&gt;用于容器内的插件&lt;/h3&gt;

&lt;p&gt;配置字典用作容器内的文件时， 会将base64编码还原， 因此容器内进程看到的是一个完整的二进制文件， 而不是奇怪的编码。&lt;/p&gt;

&lt;h2 id=&#34;配置字典的更新&#34;&gt;配置字典的更新&lt;/h2&gt;

&lt;p&gt;当Pod已经运行， 此时再更新其挂载的配置字典， 那么容器内是否能够感知到配置的变更呢？ 这要取决于Pod使用配置字典的方式：
1. 如果是使用配置文件或者配置目录的形式， 那么当k8s集群的配置字典更新， 容器内挂载的文件也会同步更新。 因此对于一些能够监听配置文件变更并自动加载新配置的程序(如Apache Flume)来说， 不需要重启Pod就可以立刻应用新的配置。&lt;br /&gt;
2. 如果是使用命令行参数或环境变量的方式进行配置的， 由于环境变量是在创建容器的时候指定的， 因此无法随着配置字典的变更而变更。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>管理Kubernetes中的对象</title>
      <link>https://violinsonata.site/2019/lables/</link>
      <pubDate>Sat, 14 Sep 2019 10:51:55 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/lables/</guid>
      <description>

&lt;h2 id=&#34;namespace&#34;&gt;Namespace&lt;/h2&gt;

&lt;p&gt;Kubernetes 使用命名空间来进行隔离， 每个对象只能属于其中一个命名空间， 不通的命名空间之间相互隔离。&lt;/p&gt;

&lt;p&gt;值得一提的是， 命名空间也会影响到&lt;code&gt;Service&lt;/code&gt;的行为。 比如说， 当你在Kubernetes中的&amp;rdquo;Proxy&amp;rdquo;命名空间中创建了一个名为&amp;rdquo;Nginx&amp;rdquo;的服务， 那么此时它的全名将是&lt;code&gt;Nginx.Proxy.svc.cluster.local&lt;/code&gt;， 如果一个容器仅声明了&amp;rdquo;Nginx&amp;rdquo;, 那么kubernetes会将其分配在该容器所属的命名空间中。 这样一来， 你在开发，测试，生产环境中就不必一一更改环境配置了。&lt;/p&gt;

&lt;p&gt;然而， Kubernetes命名空间不允许嵌套， 因此这注定只能进行较粗粒度的隔离工作。 官方也不推荐使用命名空间进行细粒度的划分， 如相同应用的不同版本。&lt;/p&gt;

&lt;p&gt;说到底， 命名空间的设计初衷只是在多个团队使用同一个大规模的集群时， 提供一种互不打扰的方式。 而对于同一命名空间中的对象进行更细粒度的划分， Kubernetes官方推荐使用&lt;code&gt;Label&lt;/code&gt;进行管理。&lt;/p&gt;

&lt;h2 id=&#34;树形划分-vs-维度划分&#34;&gt;树形划分 vs 维度划分&lt;/h2&gt;

&lt;p&gt;分类一直是人类理解处理大量复杂事务的利器。 这其中有两个典型的分类方式： 按树形划分和按维度划分。&lt;/p&gt;

&lt;p&gt;树形划分就如同一棵树一样， 将所有物体分为若干大类， 每个大类内的物体又分为若干小类&amp;hellip;一直这样划分下去， 每个类别都有层次， 一个物体在同一层次只能属于一个类别。 整体看来就如同目录一样清晰分明。 科学界对生物的划分就属于这种分类， 界门纲目科属种， 层次分明， 清晰严谨。&lt;/p&gt;

&lt;p&gt;还有一种分类方式则不分层级， 而是给每个物体依据其特点打上不同的标签。 例如， 我们可以对一群人中的每个个体打上标签， 然后就可以通过标签方便的筛选出其中的&amp;rdquo;父亲&amp;rdquo;， &amp;ldquo;女性&amp;rdquo;, &amp;ldquo;5-10岁&amp;rdquo;等不同的子集。 这种分类方式弥补了树形分类只能以物体单一属性进行分类的缺陷， 可以关注物体不同的属性，因此我将其称为&amp;rdquo;按维度划分&amp;rdquo;。&lt;/p&gt;

&lt;h2 id=&#34;label&#34;&gt;Label&lt;/h2&gt;

&lt;p&gt;Kubernetes提供的&lt;code&gt;Label&lt;/code&gt;就是要求用户以维度划分的思想来管理统一命名空间内的多个对象, 乃至跨命名空间的对象。 为什么要用这种方式呢？ 因为设计者认为这种方式更加灵活， 可以从多个角度对目标进行管理， 减少操作次数， 从而简化管理。&lt;/p&gt;

&lt;p&gt;不过我个人认为， 标签虽然强大， 但是对于使用者提出了较高的要求。 如果想要如同理想情况那样管理对象， 团队成员还需要协商一套可以严格执行的标签规范， 以区分各自负责的对象而不会造成混乱 —— 也就是说， 这其实反而加大了管理的负担。&lt;/p&gt;

&lt;p&gt;Kubernetes的标签以键值对的形式存在。 &lt;code&gt;键&lt;/code&gt;是使用/分割的前缀和键名， 二者都可以随意设定， 且前缀可以省略， 但是支持的字符集仅为[a-z,0-9 A-Z.-_]。 &lt;code&gt;值&lt;/code&gt;没有前缀，其他要求和键一样。&lt;/p&gt;

&lt;p&gt;一个对象的标签可以在对象的&lt;code&gt;metadata&lt;/code&gt;属性中指定，就像下面这样。 换句话说， 任何拥有&lt;code&gt;metadata&lt;/code&gt;属性的Kubernetes对象， 都可以用标签来进行管理。 这几乎囊括了Kubernets中所有的对象。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  labels:
    this-is-a-key: this-is-a-value
    another_key:  another_value
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;selector&#34;&gt;Selector&lt;/h2&gt;

&lt;p&gt;那么为对象设定了标签之后， 要怎样通过它来实现管理呢？ 这就要用到Kubernetes提供的另一个功能：&lt;code&gt;标签选择器(Label Selector)&lt;/code&gt;。 每当我们要做出一个操作， 都可以在yaml文件中设置标签选择器， Kubernetes只会对那些通过了选择器筛选的对象执行操作。&lt;/p&gt;

&lt;p&gt;选择器也是一个键值对的列表， 每一行都是一个匹配规则， 各个规则之间是&lt;code&gt;AND&lt;/code&gt;关系。 也即是说，Kubernetes会对该命名空间内所有对象的标签进行匹配， 找出满足了选择器中声明的所有匹配规则的对象。 任何一个规则不匹配， 那么就不会对该对象执行操作。&lt;/p&gt;

&lt;p&gt;在进行匹配时， Kubernetes会选出键相同的对象，然后再比较值。 如果都相等，则算是匹配成功。 而具体到值的指定， 有两种方案：&lt;code&gt;Equality-based&lt;/code&gt;和&lt;code&gt;Set-based&lt;/code&gt;, 基于相等的选择器和基于集合的选择器。 基于相等的选择器只能指定一个值， 而基于集合的选择器可以指定多个值组成一个集合， 只要对象的相同的键所对应的值位于该集合中， 就算是匹配成功。 当然， 除了相等之外， 同样也允许反向匹配， 也就是”不等于该值&amp;rdquo;或&amp;rdquo;不属于该集合&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;说实话我个人觉得在设计方面此处的标签匹配功能强大灵活， 但是在语法设计方面有些糟糕。 没必要专门设计两个选择器， 所有的都用集合选择器就好了。 如果需要匹配单个值， 那么只需声明一个单值的集合就好。 而且既然标签不允许特殊字符， 那么使用特殊字符在选择器的值作为分隔符不是更好么而且既然标签不允许特殊字符， 那么使用特殊字符在选择器的值作为分隔符, 以这种形式声明列表不是更好么。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;selector:
- 0-key: 0-value
- a-key: value1, value2, value3
- b-key: !value
- !c-key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等价于:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;selector:
  matchLabels:
  - 0-key: 0-value
  matchExpressions:
  - key: a-key
    operator: In
    values:
    - value1
    - value2
    - value3
  - key: b-key
    operator: NotIn
    values:
    - value
  - key: c-key
    operator: DoesNotExist
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Flume: 日志收集、聚合、归档工具</title>
      <link>https://violinsonata.site/2019/flume/</link>
      <pubDate>Sun, 24 Mar 2019 16:24:47 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/flume/</guid>
      <description>&lt;p&gt;在大数据时代， 计算机技术已经不是阻碍各大互联网公司发展的壁垒——在开源浪潮下， 所有的技术都是共享的。 甚至初创公司的技术栈会比大公司的更新更先进。 在这样的背景下， 只有数据是最珍贵的， 所有的公司都将自己搜集到的用户数据视若珍宝， 从中进行大数据分析以更好的抓住用户。&lt;/p&gt;

&lt;p&gt;那么数据是从哪里来的呢？毫无疑问日志是用户数据最好的来源。 以前的日志只是用来记录服务本身的运行状态， 只要服务不出问题， 那么没有人会去查看日志， 最多为了避免单个文件过大难以查阅， 写个定时任务将日志拆分成多个小文件。 即便服务出了故障， 查看一个月以前的日志也没什么帮助(除了少数特殊情况)， 因此 为了避免日志无限堆积占用磁盘空间， 通常还会有另一个定时任务负责把太久远的日志文件删除。&lt;/p&gt;

&lt;p&gt;然而自从各大互联网公司发现了用户数据的价值之后， 一切都变了：日志不再单纯记录服务本身的信息， 也开始记录用户的基本信息与行为记录， 服务器接受的每一次请求都将记录下至少一条信息， 虽然通常这两类日志不会记录到同一个文件里， 但依然无法阻挡后一种日志文件的容量增长急速上升；为了应对增长更快的文件尺寸， 也为了能更快地分析即时用户数据， 日志文件拆分的频率越来越高， 从每周， 每天， 到每小时甚至每分钟；而那些从前的日志文件也不能随便删除了：那可都是有价值的用户数据呢！可是面对这样大量的数据， 不能把他们一直存在服务器上吧， 这样既会给服务器带来巨大的负担， 而且也难以访问从而分析这些数据。 因此， OLAP出现了， Hadoop出现了， 这些分析专用的系统正是为了存储分析大量日志及用户数据而设计的。&lt;/p&gt;

&lt;p&gt;但是随之而来了新的问题：怎样将日志数据存储到这些分析数据库呢？&lt;/p&gt;

&lt;p&gt;Flume， 一个专为转运日志数据的系统应运而生。 Flume是一个用于收集、过滤、聚合、转运大量日志数据的工具， 其具有分布式， 高可靠， 高可用等特点。  而其运行却可以不依赖任何第三方服务， 只要有 JRE1.8 以上的Java运行环境即可。 整体可以说是简洁轻便， 灵活轻量。&lt;/p&gt;

&lt;p&gt;配置方面， 为了易于理解， 它使用一个简洁的数据模型来定义线上服务的配置：&lt;br /&gt;
&lt;img src=&#34;https://flume.apache.org/_images/DevGuide_image00.png&#34; alt=&#34;image&#34; /&gt;&lt;br /&gt;
其中一些基本概念如下：&lt;br /&gt;
- &lt;strong&gt;Source&lt;/strong&gt;： 收集数据——从数据源处读取数据， 封装成一个个的Events后发送到Channel。&lt;br /&gt;
- &lt;strong&gt;Channel&lt;/strong&gt;： 传输数据——负责以Event形式暂存数据。 之所以存在Channel而不是直接由Source端向Sink端发送数据是因为Source端读取数据的速度通常不是恒定的， 毕竟日志数据产生的快慢谁也无法掌握， 所以将数据存入Channel用于做个缓冲， 起到削峰填谷的作用。&lt;br /&gt;
- &lt;strong&gt;Sink&lt;/strong&gt;： 存储数据——数据的写入端。 负责从Channel端取出Event， 解封成原始数据， 存入目标位置。&lt;br /&gt;
- &lt;strong&gt;Agent&lt;/strong&gt;： 一个完整的Flume配置的最小单位。 一个Agent代表把数据从原始位置转移至目标位置的过程。 一个典型的Agent包含一个Source, 一个Channel， 一个Sink。 不过这并不是说想要启动一个Flume进程就必须凑齐这三个组件， 其实Source， Sink， Channel三部分可以部署在不同的服务器上， 例如在生成日志的服务器上配置一个Source用于收集日志， 然后配置一个远程服务如Kafka作为Channel， 以无Sink的形式启动一个Flume进程， 而在数据库服务器上， 同样配置一个Kafka Channel用于接收Kafka中的日志数据， 然后配置一个SQL Sink用于将日志存入数据库， 从而实现分布式配置。&lt;br /&gt;
- &lt;strong&gt;Event&lt;/strong&gt;：以字节形式按行封装数据， 除此之外每个Event还包含一个数据头， 可以以Key-Value形式存储了一些用户自定义的元数据。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&lt;译&gt;并发模型</title>
      <link>https://violinsonata.site/2019/concurrency-model/</link>
      <pubDate>Sat, 02 Mar 2019 19:23:36 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/concurrency-model/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;本文翻译自 &lt;a href=&#34;http://tutorials.jenkov.com/java-concurrency/index.html&#34;&gt;http://tutorials.jenkov.com/java-concurrency/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;并发系统可以使用不同的并发模型来实现。&lt;code&gt;并发模型&lt;/code&gt;阐述了系统中的多个线程怎样合作来完成给定的任务。不同的并发模型把任务按照不同的方式拆分，且线程之间或许通过不同的方式来通信和协作。这篇文章比较深入地介绍了截至当前(2015年)最流行的几个并发模型。&lt;/p&gt;

&lt;h2 id=&#34;并发模型和分布式系统的相似性&#34;&gt;并发模型和分布式系统的相似性&lt;/h2&gt;

&lt;p&gt;这篇文章中介绍的几种并发模型和不同的分布式系统架构十分相似。在一个并发的操作系统中，不同的线程之间会互相通信；在分布式系统中，不同的进程会互相通信(或许它们位于不同的计算机):进程和线程实际上非常相似。这就是不同的并发模型看起来和不同的分布式系统架构十分相似的原因。&lt;/p&gt;

&lt;p&gt;当然，分布式系统还会面临更多额外的挑战比如网络失败，或者远端计算机宕机等。不过运行在大型服务器上的并发操作系统也有可能会面临相似的问题，比如某个CPU、网卡、磁盘挂掉了之类的。遇到这种事的可能性会很低，但在理论上依然会发生。(译注:现在的服务器上确实会配备多个CPU，网卡及磁盘。这样的设计一方面是为了提高服务器性能，另一方面也是出于可用性考虑。也就是说，某个硬件坏掉并不只是理论上的可能，它确实会发生。)&lt;/p&gt;

&lt;p&gt;正因为并发模型和分布式系统架构如此相似，它们经常可以互相借鉴经验。例如，在多个线程之间分派任务的模型通常与分布式系统的负载均衡模型相似。还有错误处理技术如日志，故障切换(fail-over), 幂等也都相同。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&#34;并行执行模型&#34;&gt;并行执行模型&lt;/h2&gt;

&lt;p&gt;第一个并发模型被称为&lt;code&gt;并行执行&lt;/code&gt;。输入的任务被分派给不同的执行者。如下图所示:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/02/kq1Uzj.png&#34; alt=&#34;image&#34; /&gt;
在并行执行模型中，分派者把任务拆分并分派给不同的执行者。每个执行者都可以完成分派下来的整个任务。所有的执行者在不同的线程中并行地执行，这些线程或许是在不同的CPU上。&lt;/p&gt;

&lt;p&gt;想象一家汽车厂实现了并行工作模型，每个执行者都将会生产一辆汽车。单个执行者将会从头到尾地生产分派给他的那辆特定的汽车。&lt;/p&gt;

&lt;p&gt;并行执行模型是在Java应用中最常用的并发模型(尽管现在正渐渐改变)。&lt;code&gt;Java.util.concurrent&lt;/code&gt; 包中有许多并发工具都是为了这个模型准备的。&lt;/p&gt;

&lt;h2 id=&#34;并行执行的优点&#34;&gt;并行执行的优点&lt;/h2&gt;

&lt;p&gt;并行执行模型的优点就是易于理解。如果要提高并发程度，只需要增加执行者的数量就可以了。&lt;/p&gt;

&lt;p&gt;例如，你要实现实现一个网络爬虫，你可以利用不同数量的执行者线程来爬取相同总数量的页面，然后比较使用多少执行者可以在最短时间内完成任务(也就是性能最高)。因为网络爬虫是一个对IO敏感的任务，因此或许你会发现每个CPU执行少量线程是个最好的选择。每个CPU一个线程就太少了，因为这将会花费大量的时间在等待数据下载。&lt;/p&gt;

&lt;h2 id=&#34;并行执行的缺点&#34;&gt;并行执行的缺点&lt;/h2&gt;

&lt;p&gt;在简单易于理解的外表下，并行执行模型也有一些缺点，下面将介绍其中最显著的几个。&lt;/p&gt;

&lt;h3 id=&#34;分享状态会带来复杂度&#34;&gt;分享状态会带来复杂度&lt;/h3&gt;

&lt;p&gt;在现实中并行执行模型比上面阐述的要复杂一些。每个执行者常常需要访问一些公共的数据，可能在内存，也可能在数据库。如下图所示:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/02/kq1NWQ.png&#34; alt=&#34;image&#34; /&gt;
这些状态有时候通过一些通信机制来共享，如任务队列。但有些状态是业务数据，数据缓存，数据库连接池等等。&lt;/p&gt;

&lt;p&gt;一旦引入了共享的状态，那么事情就变得复杂了。线程之间需要一种机制来保证某一个线程对共享数据做出的变更对于其他线程来说是可见的(需要将新的数据直接推到主存中而不是缓存在某个CPU自己的cache中)。线程之间要避免竞态条件，死锁，以及其他许多共享状态的并发问题。&lt;/p&gt;

&lt;p&gt;另外，当线程在访问共享数据时的互相等待行为也会造成并发性的丢失。许多并发的数据结构是阻塞性的，意味着任何时间只能由一个或一小部分线程能同时访问它们，这将导致在访问这类数据结构时会发生竞争。激烈的竞争将导致访问这类数据结构的那部分代码在一定程度上变成串行执行的。&lt;/p&gt;

&lt;p&gt;现代的&lt;code&gt;非阻塞并发算法&lt;/code&gt;在一定程度上可以降低竞争以提升性能，但非阻塞算法的实现非常复杂。&lt;/p&gt;

&lt;p&gt;另一个选择是使用持久数据结构。它在修改时始终保留自身的先前版本。这样一来，如果多个线程指向了同一个持久数据结构并且其中某个线程修改了数据，这个线程将获取一个指向新数据结构的引用。所有其他的线程依然持有指向旧版本数据结构的引用。Scala语言包含了几个这样的持久数据结构。&lt;/p&gt;

&lt;p&gt;持久数据结构是并发修改状态的一个优雅的解决方案，但也不是万能的。&lt;/p&gt;

&lt;p&gt;例如，一个持久的链表会将所有的新节点插入链表头部，并返回一个指向新节点的引用。当一个线程插入新数据之后，所有其他线程仍将持有指向前一个版本的头节点的引用，然而如今那已经是事实上的第二个节点了。也就是对于其他线程来说，这个链表的变更是不可见的。&lt;/p&gt;

&lt;p&gt;持久链表的底层实现是链表，然而链表在现代硬件上的性能并不太好。链表中的每个元素都是分离开的，这些元素的分布甚至可能跨越整个内存区域。现代CPU在顺序访问数据的时候是非常快的，所以在现代的硬件上用数组的性能比用链表快得多，因为数组就是按顺序存放数据的。CPU缓存可以一次载入数组中的一大块数据，然后这部分数据就可以直接在CPU缓存中读取了。同样的事在使用链表存放数据时几乎不可能发生。&lt;/p&gt;

&lt;h3 id=&#34;无状态执行者&#34;&gt;无状态执行者&lt;/h3&gt;

&lt;p&gt;共享的状态或许会被操作系统中的其他线程更改，因此每次需要该状态的时候都不得不重新读入，以此来保证自己持有的状态是最新的。无论共享的状态是在内存中，还是数据库中都必须如此。一个本身不持有状态，但是每次需要都重新去读取状态的执行者，被称为&lt;code&gt;无状态的&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;每次都重新读取状态信息是很慢的，尤其是状态被存储在外部数据库的时候。&lt;/p&gt;

&lt;h3 id=&#34;任务的执行顺序是不确定的&#34;&gt;任务的执行顺序是不确定的&lt;/h3&gt;

&lt;p&gt;并行执行模型的另一个缺陷是任务的执行顺序是不可知的。没有什么手段可以保证哪个任务先执行，哪个任务后执行。&lt;/p&gt;

&lt;p&gt;非确定的执行顺序带来的后果就是很难确定某一个时间点整个系统的状态。同样也很难保证一个特定任务在另一特定任务之前执行。&lt;/p&gt;

&lt;h2 id=&#34;流水线&#34;&gt;流水线&lt;/h2&gt;

&lt;p&gt;第二个并发模型我将其称为&lt;code&gt;流水线模型&lt;/code&gt;。其他开发者根据其社区或平台的不同会使用不同的名称(例如交互式系统/事件驱动系统)。下图解释了流水线模型的模式。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9pcG9.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;多个执行者的组织方式就像是工厂里面流水线旁边的工人们一样。每个执行者仅仅处理自己的一部分任务。这一个执行者做完了，下一个执行者接上。&lt;/p&gt;

&lt;p&gt;每个执行者都是一个单独的线程，且每个执行者之间没有共享的状态。因此有时该模型也被称为&lt;code&gt;无共享并发模型&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;使用流水线模型的系统通常是被设计用来*无阻塞*地进行IO。无阻塞地IO的意思是当一个执行者开始一个IO操作的时候(例如从网络中读取一个文件或一些数据)，这个执行者不必阻塞地等待这个IO操作结束。IO操作是很耗时的，所以阻塞地等待IO操作是对于CPU资源的浪费。CPU这个时候可以分配给其他的 执行者，当IO操作完成的时候，操作结果(例如读取到的数据或文件)再传递给那个执行者。&lt;/p&gt;

&lt;p&gt;得益于无阻塞IO的特性，可以将IO操作作为多个执行者之间切换的边界。一个执行者可以尽情地占用CPU资源来执行任务，直到它不得不开始一次IO操作，此时它将交出CPU资源。当IO操作完成之后，流水线上的下一个执行者将继续工作，直到它也遇到了一次IO操作。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9CRHK.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;事实上，整个任务或许不会仅仅由一条流水线组成。大多数系统都可以同时运行多个任务，从执行者到执行者之间的任务流取决于任务本身。事实上，一个任务或许会同时有多个不同的虚拟流水线。因此看起来将是下面这样:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9Pwrt.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一个任务甚至可以传递给多个执行者来并发的进行处理。例如，一个任务可以同时传递给给一个excutor和一个Logger。下图展示了三条流水线将它们的任务传递给同一个执行者来结束各自的任务:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9PIaT.png&#34; alt=&#34;image&#34; /&gt;
当然流水线模型可以做得比这复杂得多。&lt;/p&gt;

&lt;h3 id=&#34;交互与事件驱动的系统&#34;&gt;交互与事件驱动的系统&lt;/h3&gt;

&lt;p&gt;使用流水线模型的系统有时也被称为交互式系统或事件驱动的系统。系统内的执行者们对于系统内发生的事件做出响应，无论是事件是来自系统之外还是来自于系统内其他的执行者。所谓事件的典型例子是HTTP请求，或者将一个文件载入内存完成。&lt;/p&gt;

&lt;p&gt;在写这篇文章时已经有一些有趣的交互式/事件驱动的平台，未来还会有更多。这些平台包括:
- Vert.x
- Akka
- Node.Js&lt;/p&gt;

&lt;h3 id=&#34;actors-vs-channels&#34;&gt;Actors vs. Channels&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Actors模型&lt;/code&gt;和&lt;code&gt;Channels模型&lt;/code&gt;是流水线模型的两个相似的案例。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;Actors模型&lt;/code&gt;中每个执行者被叫做&lt;code&gt;Actor&lt;/code&gt;。Actor相互之间可以直接发送消息。这些消息会被异步地发送和处理。Actor可以用来实现一个或多个上面讨论的流水线,如下图所示。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A91xcq.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;Channel模型&lt;/code&gt;中，执行者之间不会直接通信。相反他们会通过不同的channel来发布消息(或事件)，而不关心谁会订阅到这些消息；其他执行者可以订阅这些channel来接收消息，也不关心是谁发布了这些消息。该模型如下图所示。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A93B5Q.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一个执行者不必知道哪一个执行者接下来会继续执行任务。它只需要关心应该将任务或消息传递给哪个channel。接收消息的执行者可以订阅或取消订阅channels而不会对发布者造成任何影响。这可以降低执行者之间的耦合度。&lt;/p&gt;

&lt;h2 id=&#34;流水线模型的优势&#34;&gt;流水线模型的优势&lt;/h2&gt;

&lt;p&gt;与并行执行模型相比，流水线模型有如下几个优势。&lt;/p&gt;

&lt;h3 id=&#34;没有共享的状态&#34;&gt;没有共享的状态&lt;/h3&gt;

&lt;p&gt;各个执行者之间没有共享的状态，这意味着实现每个执行者的时候，不需要考虑那些在并行执行模型中很常见的并发问题。这使得实现更加简洁，你实现一个执行者的时候可以假装它就是一个唯一的线程。&lt;/p&gt;

&lt;h3 id=&#34;有状态的执行&#34;&gt;有状态的执行&lt;/h3&gt;

&lt;p&gt;既然每个执行者都确认不会有其他执行者来修改它自己的数据，那么一个执行者就可以是有状态的了。在这里&amp;rdquo;有状态&amp;rdquo;的意思是一个执行者可以在内存中持有它需要的数据，只把修改了的部分写回外部存储之中。因此一个有状态的执行者比无状态的执行者的执行效率要高一些。&lt;/p&gt;

&lt;h3 id=&#34;更好的硬件适配性&#34;&gt;更好的硬件适配性&lt;/h3&gt;

&lt;p&gt;单线程的代码还有个优势就是它通常更适配底层硬件的工作方式。&lt;/p&gt;

&lt;p&gt;首先，当你确认代码在单线程环境下工作室，你通常可以设计更强大的数据结构和算法。&lt;/p&gt;

&lt;p&gt;其次，单线程的有状态执行者可以向上面提到的那样在内存中持有数据。如果一段数据保存在内存中，那么同样很有可能会缓存在CPU的cache中。这可以进一步提高访问数据的速度。&lt;/p&gt;

&lt;p&gt;我将这种更适应底层硬件工作机制的代码组织方式称为&lt;code&gt;硬件适配性&lt;/code&gt;(hardware confirmity)。有些开发者将其称为&lt;code&gt;mechanical sympathy&lt;/code&gt;。我更喜欢前者因为计算机很少有固定的部分，并且&amp;rdquo;sympathy&amp;rdquo;这个词在这里所暗示的&amp;rdquo;更加匹配&amp;rdquo;的意思，我觉得使用&amp;rdquo;confirm&amp;rdquo;这个词会表达地更加贴切。好吧，这都不重要，随你喜欢用哪个都行。&lt;/p&gt;

&lt;h3 id=&#34;安排任务顺序是可行的&#34;&gt;安排任务顺序是可行的&lt;/h3&gt;

&lt;p&gt;在使用流水线模型的并发系统中安排每个执行者的先后顺序是可行的。执行顺序可以确定，那么在任意时间点确认整个系统的状态也就成为了可能。此外，你可以把所有的任务都记下日志。而这份日志可以在日后系统崩溃时用于重建整个系统的状态。所有任务以一种确定的顺序写入日志，这也就是执行者顺序的保证。&lt;/p&gt;

&lt;p&gt;保证任务的执行顺序不是一件容易的事，但是却经常会有这样的需求。如果可以，这能够大幅简化类似备份，数据恢复，数据主从复制之类的任务——所有这些同可以通过日志实现。&lt;/p&gt;

&lt;h2 id=&#34;流水线模型的缺陷&#34;&gt;流水线模型的缺陷&lt;/h2&gt;

&lt;p&gt;流水线模型的一个缺陷在于，一个任务经常会在项目中的多个执行者以及类之间传播，因此对于一个给定的任务，很难去观察当前正在执行的究竟是哪段代码。&lt;/p&gt;

&lt;p&gt;另外写代码或许也会更难。执行者的代码有时候会被写成回调(callback handler)形式。多层嵌套的回调被开发者们称为&lt;code&gt;回调深渊&lt;/code&gt;。回调深渊很直白地说明横跨整个回调流程去追踪代码的执行位置是极其困难的。确认是否每个回调流程代码都访问了它需要的数据同样是极难的。&lt;/p&gt;

&lt;p&gt;在并发执行模型中，做到这一点或许还简单点。你可以找到执行者的代码，从头到尾读下来。当然，并行执行模型的代码同样会使任务横跨许多不同的类，但是通常顺序执行的代码可读性更高一些。&lt;/p&gt;

&lt;h2 id=&#34;函数式编程&#34;&gt;函数式编程&lt;/h2&gt;

&lt;p&gt;函数式并行是近几年(2015)经常被讨论的并发模型。&lt;/p&gt;

&lt;p&gt;该模型的基本思路是你可以通过函数调用的方式来实现程序。函数可以视为可以互相发送消息的&amp;rdquo;代理(agents)&amp;ldquo;或&amp;rdquo;参与者(actors)&amp;ldquo;,就像是流水线模型中的那样。当一个函数调用其它函数时，就如同发送了一个消息一样。&lt;/p&gt;

&lt;p&gt;传递给函数的所有参数都是拷贝值，所以一个函数无法修改该函数之外的实体的数据。这种必要的拷贝可以避免共享数据上的竞态条件。这使得函数式的执行过程就像是原子操作一样。每个函数调用相互之间都是相互独立的。&lt;/p&gt;

&lt;p&gt;既然每次函数调用之间是互相独立的，那么它们当然可以分配给不同的CPU来并行地执行。这意味着如果一个算法是用函数式的方式实现的，那么它就可以同时在多个CPU上并行地执行。&lt;/p&gt;

&lt;p&gt;在Java7的&lt;code&gt;java.util.concurrent&lt;/code&gt;包中有一个&lt;code&gt;ForkAndJoinPool&lt;/code&gt;可以帮你实现类似于函数式编程的机制。而在Java8中我们有了&lt;code&gt;streams&lt;/code&gt;机制可以帮助你并行地迭代大的集合。要注意有些开发者对于&lt;code&gt;ForkAndJoinPool&lt;/code&gt;持批评的态度。&lt;/p&gt;

&lt;p&gt;函数式编程并行的难点在于确定将哪个函数并行地执行。跨多个CPU进行合作的函数会带来开销。并行执行的函数所完成的那部分任务量应该值得花费这些开销。如果一个函数很小，尝试将它们并行或许反而会比单线程单CPU执行更慢。&lt;/p&gt;

&lt;p&gt;按照我的理解，如果你可以用函数式编程实现一个算法，那么同样也可以用流水线模型来相似的实现。使用事件驱动模型，你可以更多地控制哪些需要并行，需要什么程度的并行。&lt;/p&gt;

&lt;p&gt;另外，只有当将被拆分的任务是程序中当前正在执行的唯一一个任务时，考虑将任务拆分并分派到多个CPU并行执行才有意义。而如果系统此时正在执行多个不同的任务(例如Web服务器，数据库服务以及其他各种任务),将一个任务拆分成并行执行是没有意义的。因为计算机内的其他CPU此时正忙于处理系统内其他的任务，所以没有理由将任务分布式的方式更低效地执行。此时你更应该考虑用流水线模型来处理，因为它的开销更小(在单线程环境下顺序地执行)并且有更好的硬件适配性。&lt;/p&gt;

&lt;h2 id=&#34;哪个并发模型最好&#34;&gt;哪个并发模型最好？&lt;/h2&gt;

&lt;p&gt;那么，哪个并发模型是最好的呢？&lt;/p&gt;

&lt;p&gt;通常来说，这取决于你希望用你的系统做什么。如果你的任务天然就是并行的，每一部分都是独立的且没有共享状态，那么你或许可以使用并行执行模型。&lt;/p&gt;

&lt;p&gt;许多任务并不是天然并行和独立的。在这种情况下我认为相比于并行模型，流水线模型可能更合适。&lt;/p&gt;

&lt;p&gt;你不需要从底层实现流水线模型，许多现代的平台比如&lt;code&gt;Vert.x&lt;/code&gt;已经帮你做了很多。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>通过channel模拟信号</title>
      <link>https://violinsonata.site/2019/broadcast-signals-using-channel/</link>
      <pubDate>Tue, 29 Jan 2019 12:52:36 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/broadcast-signals-using-channel/</guid>
      <description>&lt;p&gt;众所周知，在Golang中创建多个goroutine后，可以使用&lt;code&gt;sync.WaitGroup&lt;/code&gt;来等待多个协程全部完成。&lt;br /&gt;
那么是否有一种方法，不使用这个组件也能完成相同的功能呢？&lt;br /&gt;
有，那就是使用无缓存的&lt;code&gt;channel&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;channel&lt;/code&gt;有一个特点就是，当关闭之后，不能再向内写入数据，否则会造成panic,但是依然可以从中读出数据，此时读出的数据是&lt;code&gt;channel&lt;/code&gt;类型的默认值。比如&lt;code&gt;chan int&lt;/code&gt;读出的就是0， &lt;code&gt;chan bool&lt;/code&gt; 读出的就是false。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main(){
    chInt := make(chan int)
    chBool := make(chan bool)
    close(chInt)
    close(chBool)
    fmt.Println(&amp;lt;-chInt, &amp;lt;-chBool)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果
&amp;gt; 0 false&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;注意，如果声明的是有缓存的channel，那么关闭之后会首先读出缓存里面的数据，然后才是该类型的默认值&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main(){
    chInt := make(chan int, 5)
    chInt &amp;lt;- 1
    chInt &amp;lt;- 2
    close(chInt)
    fmt.Println(&amp;lt;-chInt, &amp;lt;-chInt, &amp;lt;-chInt)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果:
&amp;gt; 1 2 0&lt;/p&gt;

&lt;p&gt;既然如此，那么我们可以想到使用无缓存的&lt;code&gt;channel&lt;/code&gt;来同步地控制多个协程共同启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main(){
    start := make(chan int)
    
    for i:=0; i&amp;lt;10; i++{
        go func(){
            &amp;lt;-start:
                fmt.Println(&amp;quot;do something concurrently !&amp;quot;)
        }()
    }
    
    close(start)
    time.Sleep(time.Second)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果，多个协程是共同启动的:
&amp;gt; do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
do something concurrently !&lt;br /&gt;
&amp;gt;&lt;/p&gt;

&lt;p&gt;当然，并不只是启动信号，也可以利用这个特性发送任何你想要广播的信号，比如休眠，退出，等等。&lt;br /&gt;
另外，这个channel也可以用来作数据传输。那么如何区分读出来的是数据还是关闭信号呢？ 答案是在读出的时候判断一下第二个返回值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main(){
   ch := make(chan int)
    for i:=0; i&amp;lt;10; i++{
        go func(){
            for{
                select{
                case n, ok:=&amp;lt;-ch:
                    if ok{
                        fmt.Println(&amp;quot;data&amp;quot;, n)
                    }else{
                        fmt.Println(&amp;quot;signal&amp;quot;,n)
                        return
                    }
                }
            }
        }()
    }
    
    ch&amp;lt;-0
    ch&amp;lt;-1
    ch&amp;lt;-2
    time.Sleep(time.Second)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果，打印顺序是乱序的，但可以看到协程能够区分“信号”和“数据” 的区别：
&amp;gt; data 0&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
data 1&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
data 2&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
signal 0&lt;br /&gt;
&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;当然，这个特性也并不是万能的，主要的缺陷在于，
- 只能发送一个特定的信号。如果想要发送多个信号，需要使用多个&lt;code&gt;channel&lt;/code&gt;。
- 只能以类似广播的方式发送信号，一次close，所有监听的goroutine都会响应。&lt;br /&gt;
  例如，你创建了十个阻塞的goroutine,而只想启动其中的三个（无论是特定的三个还是任意三个），这是无法实现的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Even主题的小吐槽</title>
      <link>https://violinsonata.site/2019/disadvance-on-even/</link>
      <pubDate>Mon, 28 Jan 2019 13:40:16 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/disadvance-on-even/</guid>
      <description>&lt;p&gt;搭建博客时横向对比了几个喜欢的Hexo主题，最终选定了&lt;a href=&#34;https://github.com/ahonn/hexo-theme-even&#34;&gt;Even&lt;/a&gt; 。&lt;br /&gt;
不过依然对&lt;code&gt;Even&lt;/code&gt;有几个不太满意的地方，在这里记录下来，日后有时间就自己修改一下。&lt;/p&gt;

&lt;h2 id=&#34;主题颜色不好看&#34;&gt;主题颜色不好看。&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Even&lt;/code&gt;默认自带的几个主题颜色都不太好看，好在作者在Wiki中介绍了自定义颜色的方法，想要修改不难。&lt;/p&gt;

&lt;h2 id=&#34;没有分享链接按钮&#34;&gt;没有分享链接按钮&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Even&lt;/code&gt;没有设置&lt;code&gt;分享到&lt;/code&gt;这类的按钮，这有点不太方便。&lt;/p&gt;

&lt;h2 id=&#34;版权信息需要完善&#34;&gt;版权信息需要完善&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Even&lt;/code&gt;的版权信息放在每篇文章的底部， 注明了&lt;code&gt;作者&lt;/code&gt;,&lt;code&gt;本文链接&lt;/code&gt;,&lt;code&gt;许可协议&lt;/code&gt;。不过美中不足的是，这些信息的字体太大了，当阅读到底部的时候，有点喧宾夺主的感觉。
另外，相比于摆出跳转链接，我觉得更好的方案是&lt;code&gt;普通文字+复制链接按钮&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;分类系统需要完善&#34;&gt;分类系统需要完善&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Even&lt;/code&gt;作者本身的博客并没有在导航栏上添加&lt;code&gt;分类&lt;/code&gt;页面，通常要在文章中点击分类链接，跳转到相同分类的索引页面。&lt;/p&gt;

&lt;p&gt;不过如果添加了&lt;code&gt;分类&lt;/code&gt;导航，点进去会发现该页面的布局和跳转逻辑竟然和标签是一样的！ 或许是作者没有搞清楚在Hexo中目录和标签的区别吧，这方面我觉得&lt;a href=&#34;https://github.com/probberechts/hexo-theme-cactus&#34;&gt;Cactus&lt;/a&gt;做的更好一些。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;Cactus&lt;/code&gt;中，标签的跳转逻辑与&lt;code&gt;Even&lt;/code&gt;是一样的，但是在分类页面， &lt;code&gt;Cactus&lt;/code&gt;会直接将所有的目录列出来，点击相对应的目录，可以显示该目录下所有的文章标题。
如果对于多级目录没有需求，所有文章都只在一级目录下的话，那可以考虑另一种逻辑：直接显示所有的目录及其下的文章标题。这种的展示方式就像是归档一样了，更加简单直接一些。&lt;/p&gt;

&lt;p&gt;另外，&lt;code&gt;分类&lt;/code&gt;的计数功能似乎有点小问题：计数只增不减，删除一个目录，计数不会减小。&lt;/p&gt;

&lt;p&gt;顺带一提，&lt;code&gt;Cactus&lt;/code&gt;也是一个非常优秀的Hexo主题，上面说到的几点不足在&lt;code&gt;Cactus&lt;/code&gt;中都很完善。不过这个主题也有硬伤，就是markdown的渲染太丑了，而且目录对于多级标题的支持有点小问题，所以只能忍痛割爱了。&lt;/p&gt;

&lt;h2 id=&#34;seo优化&#34;&gt;SEO优化&lt;/h2&gt;

&lt;p&gt;虽然不清楚是怎么回事，不过&lt;code&gt;Even&lt;/code&gt;的SEO优化似乎做的不如&lt;code&gt;Cactus&lt;/code&gt;呢&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;阅读更多-需要完善&#34;&gt;&amp;ldquo;阅读更多&amp;rdquo;需要完善&lt;/h2&gt;

&lt;p&gt;在&lt;code&gt;Even&lt;/code&gt;中，想要在首页显示部分文章内容，需要手动在文章中添加一个标签:&lt;code&gt;&amp;lt;!-- more --&amp;gt;&lt;/code&gt;。 这样相当于强行手动将markdown内容割裂了，以后如果需要拷贝、迁移到其他地方的话可能有点不方便。 这方面的实现也应该参考一下&lt;code&gt;Cactus&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Python虚拟环境指南</title>
      <link>https://violinsonata.site/2019/virtualenvwrapper/</link>
      <pubDate>Sun, 27 Jan 2019 23:39:34 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/virtualenvwrapper/</guid>
      <description>&lt;h2 id=&#34;安装-virtualenv&#34;&gt;安装&lt;code&gt;virtualenv&lt;/code&gt;:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$pip install virtualenv
$virtualenv --version
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;安装-virtualenvwrapper&#34;&gt;安装 &lt;code&gt;virtualenvwrapper&lt;/code&gt;:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;如果想要使用 virtualenvwrapper的话， 不必事先手动安装 virtualenv,  pip会自动解决该依赖。&lt;/li&gt;
&lt;li&gt;在windows环境下,应该安装其对应的windows版本 : &lt;code&gt;virtualenvwrapper-win&lt;/code&gt;。该版本仅能在 cmd 下工作， 如果在windows上使用
模拟Linux命令行的工具， 如 git bash , cmder 等， 则可能会造成无法正常工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下载包:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$pip install virtualenvwrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建虚拟环境目录：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$mkdir .pythonenv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改&lt;code&gt;.bashrc&lt;/code&gt;来添加环境变量:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/bash
WORKON_HOME=$HOME/.pythonenv
source /usr/local/bin/virtualenvwrapper.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ps：如果不创建并指定&lt;code&gt;WORKON_HOME&lt;/code&gt;目录的话， 加载&lt;code&gt;virtualenvwrapper.sh&lt;/code&gt;时会默认创建在 &lt;code&gt;$HOME/.virtualenv&lt;/code&gt;目录。&lt;/p&gt;

&lt;p&gt;验证是否安装成功:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$virtualenvwrapper

virtualenvwrapper is a set of extensions to Ian Bicking&#39;s virtualenv
tool. The extensions include wrappers for creating and deleting
virtual environments and otherwise managing your development workflow,
making it easier to work on more than one project at a time without
introducing conflicts in their dependencies.
···
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;在虚拟环境中设置环境变量&#34;&gt;在虚拟环境中设置环境变量&lt;/h2&gt;

&lt;p&gt;使用 &lt;strong&gt;virtualenvwrapper&lt;/strong&gt; 时， 会自动生成 &lt;code&gt;$VIRTUAL_ENV/bin/&lt;/code&gt; 目录，可以利用里面的脚本定义特定于该虚拟环境的动作，例如设定环境变量。
虚拟环境中设置的环境变量不会影响到虚拟环境外部，即使同一用户从其他终端登录并启用了另一个虚拟环境，那么在两边看到的环境变量也不会相互冲突。
对于使用环境变量来管理开发，测试，生产等多个配置的项目来说， 可以使用这种方式来来管理项目配置 —— 甚至可以在同一台服务器上同时部署开发和测试等多个环境！&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$workon app
...
$vim $VIRTUAL_ENV/bin/postactivate
#!/bin/bash
# This hook is sourced after this virtualenv is activated.
export ENV=dev

$vim $VIRTUAL_ENV/bin/postactivate
#!/bin/bash
# This hook is sourced before this virtualenv is deactivated.
unset ENV
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新进入虚拟环境进行验证：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$deactivate
$echo $ENV

$workon app
$echo $ENV
dev
$deactivate
$echo $ENV

$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除了每个虚拟环境特定的设置，还可以针对用户级别的全局配置——对于该用户的所有虚拟环境生效。
方法就是编辑 &lt;strong&gt;$WORKON_HOME/&lt;/strong&gt; 目录下的一系列脚本文件。
更多详情可见官方文档:
&lt;a href=&#34;https://virtualenvwrapper.readthedocs.io/en/latest/scripts.html#scripts&#34;&gt;https://virtualenvwrapper.readthedocs.io/en/latest/scripts.html#scripts&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>