<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sonata for solo Violin on Sonata for solo Violin</title>
    <link>https://violinsonata.site/</link>
    <description>Recent content in Sonata for solo Violin on Sonata for solo Violin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 14 May 2021 17:14:19 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>JVM的JMX机制</title>
      <link>https://violinsonata.site/2021/jvm%E7%9A%84jmx%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Fri, 14 May 2021 17:14:19 +0800</pubDate>
      
      <guid>https://violinsonata.site/2021/jvm%E7%9A%84jmx%E6%9C%BA%E5%88%B6/</guid>
      <description>

&lt;p&gt;[toc]&lt;/p&gt;

&lt;h1 id=&#34;什么是-jmx&#34;&gt;什么是 JMX&lt;/h1&gt;

&lt;p&gt;JMX 全称是 The Java Management Extensions ，是一种继承到 JVM 中的标准化功能。&lt;/p&gt;

&lt;p&gt;JMX 的作用是在 JVM 运行过程中，实现对进程内变量的访问与控制。
这个「进程内变量」，既可以是 JVM 的运行参数，也可以是用户程序自定义的变量。&lt;/p&gt;

&lt;p&gt;由于 JMX 的灵活性， 因此该技术经常被用于在运行时修改 JVM 运行参数、不停机修改应用的配置、监控指标导出等功能。&lt;/p&gt;

&lt;p&gt;更方便的是， JMX 支持一些远程访问协议，典型的如 RMI 与 HTTP 协议。
因此不必登陆到 JVM 进程所在的服务器，即可实现对进程的访问。&lt;/p&gt;

&lt;p&gt;JMX 整体的架构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ascii&#34;&gt;                  ┌─────────┐  ┌─────────┐                  
                  │jconsole │  │   Web   │              
                  └─────────┘  └─────────┘              
              	      rmi          http              
                       │            │              
              ┌────────│────────────│────────┐              
              │JVM     ▼            ▼        │              
              │   ┌─────────┐  ┌─────────┐   │              
              │ ┌─┤Connector├──┤ Adaptor ├─┐ │              
              │ │ └─────────┘  └─────────┘ │ │              
              │ │       MBeanServer        │ │              
              │ │ ┌──────┐┌──────┐┌──────┐ │ │              
              │ │ │MBean1││MBean2││MBean3│ │ │              
              │ │ └──────┘└──────┘└──────┘ │ │                 
              │ └──────────────────────────┘ │   
              └──────────────────────────────┘              
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JMX 的主体是与 JVM 嵌合在一起的 MBeanServer， 对于需要管理访问的数据，通过 MBean 的方式注册到 MBeanServer 中。
另外，MBeanServer 通过各种接口供外部访问。&lt;/p&gt;

&lt;h1 id=&#34;使用-jmx&#34;&gt;使用 JMX&lt;/h1&gt;

&lt;p&gt;如果想要通过 JMX 技术在进程外部对进程数据进行访问，那么必须要将该数据封装在 MBean 中，并将 MBean 注册给 MBeanServer 。&lt;/p&gt;

&lt;p&gt;MBean 是一种遵循 JMX 要求而设计的类和对象 ，不过本质上和普通的对象并没有什么区别。
当通过 JMX 访问一个 MBean 时， MBean 将暴露三类信息：
1. 一些属性
2. 一些方法
3. 自述信息&lt;/p&gt;

&lt;h2 id=&#34;定义-mbean-接口&#34;&gt;定义 MBean 接口&lt;/h2&gt;

&lt;p&gt;要注意， MBean 的接口名称必须要以 &lt;code&gt;MBean&lt;/code&gt; 结尾。&lt;br /&gt;
在 MBean 接口 中，需要读写的属性将以 getter/setter 的方式定义。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.example; 
 
public interface HelloMBean { 
 
    public void sayHello(); 
    public int add(int x, int y); 
    
    public String getName(); 
     
    public int getCacheSize(); 
    public void setCacheSize(int size); 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;实现-mbean-接口&#34;&gt;实现 MBean 接口&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.example; 
 
public class Hello implements HelloMBean { 
    public void sayHello() { 
        System.out.println(&amp;quot;hello, world&amp;quot;); 
    } 
     
    public int add(int x, int y) { 
        return x + y; 
    } 
     
    public String getName() { 
        return this.name; 
    }  
     
    public int getCacheSize() { 
        return this.cacheSize; 
    } 
     
    public synchronized void setCacheSize(int size) {
        this.cacheSize = size; 
        System.out.println(&amp;quot;Cache size now &amp;quot; + this.cacheSize); 
    } 
     
    private final String name = &amp;quot;Reginald&amp;quot;; 
    private int cacheSize = DEFAULT_CACHE_SIZE; 
    private static final int DEFAULT_CACHE_SIZE = 200; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;注册-mbean-对象&#34;&gt;注册 MBean 对象&lt;/h2&gt;

&lt;p&gt;在注册 MBean 到 MBeanServer 时， 需要为每个 MBean 对象指定一个名称。&lt;br /&gt;
名称必须是 &lt;code&gt;javax.management.ObjectName&lt;/code&gt; 类型，并且名称必须按照 ObjectName 类规定的格式。&lt;/p&gt;

&lt;p&gt;简单来说，ObjectName 规定的 MBean 的名称分成两部分， 中间由冒号分割:
- 一个域名
- 一组键值对&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.example; 
import java.lang.management.*; 
import javax.management.*; 
 
public class Main { 
    public static void main(String[] args)  throws Exception { 
     
        MBeanServer mbs = ManagementFactory.getPlatformMBeanServer(); 
        ObjectName name = new ObjectName(&amp;quot;com.example:type=Hello&amp;quot;); 
        Hello mbean = new Hello(); 
        mbs.registerMBean(mbean, name); 
          
     
        System.out.println(&amp;quot;Waiting forever...&amp;quot;); 
        Thread.sleep(Long.MAX_VALUE); 
    } 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;启用-jmx&#34;&gt;启用 JMX&lt;/h1&gt;

&lt;p&gt;在启动 JVM 进程时，添加如下参数以启用 JMX :&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;java \
  -Dcom.sun.management.jmxremote \  
  -Dcom.sun.management.jmxremote.port=9999
  -Dcom.sun.management.jmxremote.authenticate=false \  
  -Dcom.sun.management.jmxremote.ssl=false \  
  -jar App.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样便让 JVM 进程监听了 9999 端口作为 JMX 的入口。&lt;/p&gt;

&lt;p&gt;上面的例子没有开启 TLS 验证与通信加密，如果需要开启的话，只需修改对应的
&lt;code&gt;com.sun.management.jmxremote.authenticate&lt;/code&gt;和&lt;code&gt;com.sun.management.jmxremote.ssl&lt;/code&gt;参数即可。&lt;/p&gt;

&lt;p&gt;启动进程之后会发现， JVM 除了监听指定的 JMX 端口之外，还额外监听了两个随机端口。 这两个端口一个是供 RMI 使用的， 一个是供 Jconsole 等监控工具访问本地 JVM 进程时使用的。&lt;/p&gt;

&lt;p&gt;对于部分应用环境中， 通过防火墙限制了端口访问的范围， 那么还需要额外添加两个参数，以使 RMI 通信的端口复用 JMX 端口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;java \
  -Dcom.sun.management.jmxremote \  
  -Dcom.sun.management.jmxremote.port=9999
  -Dcom.sun.management.jmxremote.authenticate=false \  
  -Dcom.sun.management.jmxremote.ssl=false \  
  -Dcom.sun.management.jmxremote.rmi.port=9999
  -Djava.rmi.server.hostname=$(ip route get 8.8.8.8 | awk &#39;{print $NF; exit}&#39;) \  
  -jar App.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果想要关闭最后一个监听的随机端口， 那么只需在启动参数中加上这一项:
&lt;code&gt;-XX:+DisableAttachMechanism&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&#34;访问-jmx&#34;&gt;访问 JMX&lt;/h1&gt;

&lt;p&gt;在 JDK 中自带了一个 GUI 工具用以通过 JMX 访问进程， 也就是上面提到的 &lt;code&gt;Jconsole&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;不过这是一个 GUI 工具，在 CLI 环境中无法使用。 如果想要在命令行中访问 JMX 的话， 那么 &lt;a href=&#34;https://docs.cyclopsgroup.org/jmxterm&#34;&gt;Jmxterm&lt;/a&gt; 是一个不错的选择。&lt;/p&gt;

&lt;h2 id=&#34;jmx-与监控&#34;&gt;JMX 与监控&lt;/h2&gt;

&lt;p&gt;JMX 需要通过 RMI 协议去访问， 如果想要通过 JMX 暴露一些监控指标到 Prometheus 的话， 那么还需要搭配 &lt;a href=&#34;https://github.com/prometheus/jmx_exporter&#34;&gt;JMX Exporter&lt;/a&gt;，在启动 JVM 时添加 java agent，并指定 HTTP 端口和指标转换配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java \
  -javaagent:./jmx_prometheus_javaagent-0.15.0.jar=8080:config.yaml \
  -jar App.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jmx-性能调优&#34;&gt;JMX 性能调优&lt;/h2&gt;

&lt;p&gt;有一个强大的 JVM 分析工具， &lt;a href=&#34;https://visualvm.github.io/&#34;&gt;VisualVM&lt;/a&gt;， 可用通过 JMX 方式查看进程的运行状态， 堪称性能调优利器 ！&lt;/p&gt;

&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;官方对于 JMX 技术的介绍:
&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/jmx/overview/index.html&#34;&gt; Overview of the JMX Technology &lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;StackOverflow 上关于 JMX 端口的讨论:
&lt;a href=&#34;https://stackoverflow.com/questions/20884353/why-java-opens-3-ports-when-jmx-is-configured/21552812#21552812&#34;&gt;Why Java opens 3 ports when JMX is configured? &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Java的Synchronized关键字</title>
      <link>https://violinsonata.site/2021/java%E7%9A%84synchronized%E5%85%B3%E9%94%AE%E5%AD%97/</link>
      <pubDate>Mon, 01 Mar 2021 09:55:21 +0800</pubDate>
      
      <guid>https://violinsonata.site/2021/java%E7%9A%84synchronized%E5%85%B3%E9%94%AE%E5%AD%97/</guid>
      <description>

&lt;p&gt;[toc]&lt;/p&gt;

&lt;p&gt;Synchronized 关键字是 Java 中进行并发控制的基础。通过 Synchronized 修饰一段代码块，从而将这段代码标记为临界区，以便控制其中代码互斥地执行。&lt;/p&gt;

&lt;p&gt;Synchronized 关键字的用法很多，既可以用来修饰一个函数，也可以单独修饰一段代码块；既可以在静态函数中使用，也可以在普通函数中使用。 但是无论怎么使用，其机制却都是一样的。理解 synchronized 作用的重点是要知道它需要指定一个对象作为锁，使用相同对象作为锁的所有 synchronized 代码，都会互斥地执行，使用不同对象的作为锁的 synchronized 代码，可以并发地执行。&lt;/p&gt;

&lt;h2 id=&#34;基本用法&#34;&gt;基本用法&lt;/h2&gt;

&lt;p&gt;Synchronized 最基本的用法是这样：
![[basic-java-synchronized-usage]]&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  private Object lock = new Object(); 
  void foo(){
    synchronized(lock){
      System.out.println(&amp;quot;Hello world&amp;quot;);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;synchronized 通过括号指定一个对象作为锁，将内部的代码块锁定，不能被多个线程同时执行。&lt;/p&gt;

&lt;h2 id=&#34;synchronized-使用对象作为锁&#34;&gt;synchronized 使用对象作为锁&lt;/h2&gt;

&lt;p&gt;要注意， synchronized 关键字后跟的括号内，必须是一个已经初始化的对象，相当于将这个对象当作是一个锁。 如果多个不同的代码块关联到同一个对象上， 那么这多个代码块共享一个锁，也就是多个代码块不能同时执行，同一时刻只能执行其中一段，直到这段代码退出，其他线程才能再次执行相同的代码块或其他使用相同对象锁定的代码块。&lt;br /&gt;
看这个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 使用 java 11 编写。
// 两个线程分别执行 foo bar，而这两个函数都
// 用 synchronized 关键字关联到同一个 lock 对象。
public class SyncDemo {
  private static Object lock = new Object();

  static void foo(){
    System.out.println(&amp;quot;Foo started.&amp;quot;);
    synchronized(lock){
      System.out.println(&amp;quot;Foo in&amp;quot;);
      try{
        Thread.sleep(1000);
      }catch(InterruptedException e){
          e.printStackTrace();
      }
      System.out.println(&amp;quot;Foo out&amp;quot;);
    }
  }

  static void bar() {
    System.out.println(&amp;quot;Bar started.&amp;quot;);
    synchronized(lock){
      System.out.println(&amp;quot;Bar in&amp;quot;);
      try{
        Thread.sleep(1000);
      }catch(InterruptedException e){
          e.printStackTrace();
      }
      System.out.println(&amp;quot;Boo out&amp;quot;);
    }
  }

  public static void main(String[] args){
    var t1 = new Thread(SyncDemo::foo);
    var t2 = new Thread(SyncDemo::bar);
    t1.start();
    t2.start();

    while(t1.isAlive() || t2.isAlive());
  }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行会产生如下结果:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$java SyncDemo.java
Foo started.
Foo in
Bar started.
Foo out
Bar in
Boo out      
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见 Foo，Bar 在两个线程中近乎同时启动，Foo 抢到了锁，先执行同步代码块， 而 Bar 只能等 Foo 执行完了之后再执行。 可见虽然是不同的代码块，但因为 synchronized 关联到同一个对象作为锁，因此也只能串行执行。&lt;/p&gt;

&lt;h2 id=&#34;使用当前对象作为锁&#34;&gt;使用当前对象作为锁&lt;/h2&gt;

&lt;p&gt;有时候，synchronized 关键字可以直接以对象自身作为锁：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  void foo(){
    synchronized(this) {
      System.out.println(&amp;quot;Hello world&amp;quot;);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不用专门创建一个对象作为锁，看起来方便了很多。不过要注意的是，这样的方式声明的 foo 函数并不是全局同步的，而是每个 SyncDemo 对象各自同步。如果有两个 SyncDemo 分别在两个线程中调用 foo，那么不会发生互斥，而是会各自执行。
比如下面的代码:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  void foo(){
    synchronized(this){
      System.out.println(&amp;quot;sleep: &amp;quot; + Thread.currentThread().getName());
      try{
        Thread.sleep(1000);
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.println(&amp;quot;awake: &amp;quot; + Thread.currentThread().getName());
    }
  }
  public static void main(String[] args){
    var sd1 = new SyncDemo();
    var sd2 = new SyncDemo();
    var t1 = new Thread(sd1::foo, &amp;quot;t1&amp;quot;);
    var t2 = new Thread(sd2::foo, &amp;quot;t2&amp;quot;);
    t1.start();
    t2.start();

    while(t1.isAlive() || t2.isAlive());
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行结果是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sleep: t1
sleep: t2
awake: t1
awake: t2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;两个线程 t1 t2 是同时陷入休眠，同时苏醒，说明两个线程的 foo 是并发执行的。&lt;/p&gt;

&lt;h2 id=&#34;使用类对象作为锁&#34;&gt;使用类对象作为锁&lt;/h2&gt;

&lt;p&gt;如果想要全局同步的话，可以这样写:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  void foo(){
    synchronized(SyncDemo.class) {
      System.out.println(&amp;quot;Hello world&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JVM 在加载 SyncDemo 类的时候，会为这个类创建一个 java.lang.Class 的对象，我们假设该对象名为 SyncDemoClassObject（实际上不是）。SyncDemoClassObject 可以通过 SyncDemo 类型的 &lt;code&gt;.class&lt;/code&gt; 属性，或者将 SyncDemo 类实例化之后通过实例对象的 &lt;code&gt;.getClass()&lt;/code&gt;方法访问。这样以来， &lt;code&gt;synchronized(SyncDemo.class)&lt;/code&gt; 实际上是以 SyncDemoClassObject 作为锁。 SyncDemoClassObject 是全局唯一的， 从而以此为锁的 foo() 方法也可以做到全局互斥。&lt;/p&gt;

&lt;h2 id=&#34;直接作为函数修饰符&#34;&gt;直接作为函数修饰符&lt;/h2&gt;

&lt;p&gt;有时候，如果整个函数都需要互斥执行，那么可以这样写:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  synchronized void foo(){
    System.out.println(&amp;quot;Hello world&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这实际上算是一种语法糖，此时该函数会以对象本身作为锁。也就是和下面的代码等价:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  void foo(){
    synchronized(this) {
      System.out.println(&amp;quot;Hello world&amp;quot;);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;与-static-关键字配合使用&#34;&gt;与 static 关键字配合使用&lt;/h2&gt;

&lt;p&gt;synchronized 与 static 关键字可以配合使用，并且其机制依然不变：一定需要关联一个实例对象作为锁。
当 synchronized 修饰静态函数时，由于类尚未实例化，this指针没有指向具体对象，因此不会使用 this 作为锁，而是转而使用 SyncDemoClassObject 作为锁。此时全局的 foo 函数都互斥执行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SyncDemo{
  static synchronized void foo(){
    System.out.println(&amp;quot;Hello world&amp;quot;);
  }
  // foo bar 两种方式是等价的
  static void bar(){
    synchronized(SyncDemo.class){
      System.out.println(&amp;quot;Hello world&amp;quot;);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;不要将-synchronized-绑定在基础类型上&#34;&gt;不要将 synchronized 绑定在基础类型上&lt;/h2&gt;

&lt;p&gt;鉴于 JVM 对于基础类型的实现方式，不同基础类型的对象如果其值相同，那么很有可能指向相同的内存对象。因此看起来互不相关的两段同步代码，可能会使用同一个对象而互斥执行，进而影响其性能。
例如下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import static com.pivovarit.function.ThrowingRunnable.unchecked;

public class SyncDemo {
  Integer i1 = Integer.valueOf(1);
  Integer i2 = Integer.valueOf(1);
  void foo() throws InterruptedException{
    synchronized(i1) {
      System.out.println(&amp;quot;sleep: &amp;quot; + Thread.currentThread().getName());
      Thread.sleep(1000);
      System.out.println(&amp;quot;awake: &amp;quot; + Thread.currentThread().getName());
    }
  }
  void bar() throws InterruptedException{
    synchronized(i2){
    System.out.println(&amp;quot;sleep: &amp;quot; + Thread.currentThread().getName());
    Thread.sleep(1000);
    System.out.println(&amp;quot;awake: &amp;quot; + Thread.currentThread().getName());
    }
  }

  public static void main(String[] args){
    var sd1 = new SyncDemo();
    var sd2 = new SyncDemo();
    var t1 = new Thread(unchecked(sd1::foo), &amp;quot;t1&amp;quot;);
    var t2 = new Thread(unchecked(sd2::foo), &amp;quot;t2&amp;quot;);
    t1.start();
    t2.start();

    while(t1.isAlive() || t2.isAlive());
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行后的结果是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$java -cp ./throwing-function-1.5.1.jar SyncDemo.java
sleep: t1
awake: t1
sleep: t2
awake: t2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到两个线程实际是串行执行的。 这是因为 i1 和 i2 因为其值相同， 而指向了相同的对象。有这种情况的还有其他基本类型的封装类型，以及String类型。&lt;/p&gt;

&lt;h2 id=&#34;synchronized-是可重入锁&#34;&gt;synchronized 是可重入锁&lt;/h2&gt;

&lt;p&gt;可重入锁的含义是当一个线程内的调用链上有多个函数尝试获取同一把锁时， 可以不用再次抢占。最典型的应用场景是在递归函数中，如果不用重入锁，当父函数获取了锁并调用子函数，子函数再次尝试获取锁，于是造成死锁。 而 Java 的 synchronized 关键字修饰的代码块使用重入锁，从而避免了死锁。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import static com.pivovarit.function.ThrowingRunnable.unchecked;

public class SyncDemo {
  void foo() throws InterruptedException{
    var name = Thread.currentThread().getName();
    synchronized(SyncDemo.class) {
      System.out.println(&amp;quot;sleep: foo &amp;quot; + name); 
      Thread.sleep(1000);
      bar();
      System.out.println(&amp;quot;awake: foo &amp;quot; + name);
    }
  }

  void bar() throws InterruptedException{
    var name = Thread.currentThread().getName();
    synchronized(SyncDemo.class){
      System.out.println(&amp;quot;sleep: bar &amp;quot; + name);
      Thread.sleep(1000);
      System.out.println(&amp;quot;awake: bar &amp;quot; + name);
    }
  }

  public static void main(String[] args){
    var sd1 = new SyncDemo();
    var sd2 = new SyncDemo();
    var t1 = new Thread(unchecked(sd1::foo), &amp;quot;t1&amp;quot;);
    var t2 = new Thread(unchecked(sd2::bar), &amp;quot;t2&amp;quot;);
    t1.start();
    t2.start();

    unchecked(t1::join);
    unchecked(t2::join);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行结果如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$java -cp ./throwing-function-1.5.1.jar SyncDemo.java
sleep: foo t1
sleep: bar t1
awake: bar t1
awake: foo t1
sleep: bar t2
awake: bar t2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出 t1 内的 foo 函数先抢占了锁，然后调用 bar ，由于在同一个线程内， bar 可以直接执行，此时相当于 t1 内的 foo 和 bar 都持有该锁。不过由于两个函数在同一个线程内，线程内的代码串行执行，因此不会出现「竞态条件」。 当 t1 的 bar 执行完成后返回， t1 内的 foo 继续执行到结束退出。 直到此时 t1 才释放了锁，从而 t2 开始执行 bar。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Java的synchronized内部原理</title>
      <link>https://violinsonata.site/2021/java%E7%9A%84synchronized%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 28 Feb 2021 09:51:46 +0800</pubDate>
      
      <guid>https://violinsonata.site/2021/java%E7%9A%84synchronized%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/</guid>
      <description>

&lt;p&gt;[toc]&lt;/p&gt;

&lt;p&gt;$\qquad$在 Java 提供 &lt;code&gt;synchronized&lt;/code&gt; 的早期，JVM 会统一为所有用关键字修饰的代码块加上重量级的互斥锁。但是实际大部分情况并发抢占不是那么严重，用互斥锁显得有些繁重从而拖慢了性能。 在 JDK 1.6 中，开发组对 &lt;code&gt;synchronized&lt;/code&gt; 进行了大幅度的优化，引入了诸多机制来提升同步代码块的性能。
比较重要的机制有 &lt;code&gt;偏向锁&lt;/code&gt;、&lt;code&gt;轻量级锁&lt;/code&gt;、&lt;code&gt;自旋锁&lt;/code&gt;、&lt;code&gt;重量级锁&lt;/code&gt;四种锁，以及&lt;code&gt;锁消除&lt;/code&gt;、&lt;code&gt;锁粗化&lt;/code&gt;两种策略。&lt;/p&gt;

&lt;h2 id=&#34;关于-lock-record&#34;&gt;关于 Lock Record&lt;/h2&gt;

&lt;p&gt;$\qquad$Lock Record 在 JVM 1.6 的锁优化中扮演了重要的角色，在偏向锁和轻量锁中都有用到。
每当线程试图进入同步代码块时，都会初始化一个 Lock Record 对象（这个 Lock Record 是扫描线程栈找到一个空闲的 Lock Record 得到的，如果线程栈中没有空闲的则再创建一些），并且将其指针指向锁对象。
每当线程离开同步代码块，便会将 Lock Record 释放掉。&lt;/p&gt;

&lt;p&gt;$\qquad$不过在偏向锁和轻量锁中，Lock Record 对象的作用并不完全相同：在偏向锁中，Lock Record 仅仅用做重入计数；而在轻量锁中，Lock Record 还要负责保存锁对象原本的 Mark Word。&lt;/p&gt;

&lt;h2 id=&#34;关于-mark-word&#34;&gt;关于 Mark Word&lt;/h2&gt;

&lt;p&gt;$\qquad$在 JVM 中，任何对象在内存中除了自身属性数据外，还有一个「对象头」。对象头中分两部分：&lt;code&gt;MarkWord&lt;/code&gt; 和 &lt;code&gt;KlassWord&lt;/code&gt; 。
MarkWord 的格式非常复杂，在不同的情况下存储不同的数据，因此有不同的格式。与锁相关的信息都存储在对象的元信息，即对象的 &lt;code&gt;MarkWord&lt;/code&gt; 中。
有些信息数据超过了 MarkWord 承载的范围，也会在 MarkWord 中存储指针，通过指针指向实际数据的位置。偏向锁需要存储的数据比较少，因此直接存储在 MarkWord 中。&lt;/p&gt;

&lt;h2 id=&#34;偏向锁&#34;&gt;偏向锁&lt;/h2&gt;

&lt;h3 id=&#34;偏向锁的特点&#34;&gt;偏向锁的特点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;适用于单线程访问互斥代码段的场景。&lt;br /&gt;
例如在单线程中使用 ConcurrentHashMap，对于 ConccurrentHashMap 中的同步代码块来说，其实一直都是同一个线程抢占锁、释放锁，因此没必要每次都使用重量级锁，乃至使用轻量级锁都是多余的。&lt;br /&gt;
实际上在这种情况下，如果锁是可重入的，那即使抢占了锁的线程不再释放也是可以的，甚至可以避免多次获取、释放锁的开销从而提升性能。&lt;br /&gt;
偏向锁就是基于这样的设计思想而实现的。因此可以说偏向锁是一种可重入锁。当多次抢占锁当是同一个线程时，使用偏向锁可以提升性能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;由于偏向锁假设每次执行同步代码块的都是同一个线程，从而没必要释放锁，因此当发现进入同步代码段的线程与当前持有偏向锁的线程不相同时，偏向锁不再适用，将膨胀为轻量锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;偏向锁的原理&#34;&gt;偏向锁的原理&lt;/h3&gt;

&lt;p&gt;对象初次创建时，如果没有特别指定，则 MarkWord 低三位为 0b101，例如在 64 位 JVM 上其初始值为 0x0000_0005，即匿名偏向状态。匿名偏向状态是指后三位为 0b101，且线程 ID 的部分为0。注意即使是匿名偏向状态，也会保存 GC 代数等信息，因此不全是 0 。&lt;/p&gt;

&lt;p&gt;当线程尝试获取偏向锁时，有四种可能：&lt;br /&gt;
1. 第一次获取锁，锁对象尚未使用过，MarkWord 此时为匿名偏向。线程会构造一个 MarkWord（通过各种位运算），该 MarkWord 中保存了当前线程的 ID，然后通过 CAS 操作将自身构建的 MarkWord 替换掉锁对象的初始 MarkWord。如果此时 CAS 操作失败，说明有其他线程在此期间抢先修改了锁对象的 MarkWord，线程多于一个，偏向锁不再适用，需要把偏向锁撤销，并膨胀为轻量锁。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;再次获取锁，或者是重入获取锁，锁对象 MarkWord 内的线程 ID 与当前线程相同，则可以直接执行同步代码。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;获取锁时发现锁对象 MarkWord 内 Epoch 已过期，相当于偏向锁已释放，则可以重新抢得锁使其偏向于自己。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;获取锁时锁对象 MarkWord 内的线程 ID 不是当前线程且锁 Epoch 未过期，则说明有其他线程持有偏向锁，当前有一个以上的线程抢占，偏向锁已不再适用，因此需要膨胀为轻量锁。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt; 在偏向锁中，获取锁的 CAS 操作并不会在 Lock Record 中保留锁对象原先的 MarkWord。
因为偏向锁只是将自己的线程 ID 和 Epoch 存储在 MarkWord 中的前 25 位（ 64 位为 56 位），后面的分代年龄保留在原地，因此不必单独保存原先的 MarkWord。
但是在计算过 HashCode 之后，哈希值占用了线程 ID 和 Epoch 的位置，之后再获取锁时必须要保留原 MarkWord，此时便不能再使用偏向锁了。&lt;/p&gt;

&lt;h3 id=&#34;偏向锁的释放&#34;&gt;偏向锁的释放&lt;/h3&gt;

&lt;p&gt;$\qquad$偏向锁在释放时十分简单，只需要将本次进入同步代码块时初始化的 Lock Record 重置即可。
由于进入代码块时找的 Lock Record 是最近的空闲代码块，因此释放锁时也是寻找线程栈中最近的一个指向锁对象的 Lock Record 将其重置。&lt;/p&gt;

&lt;h3 id=&#34;偏向锁的撤销&#34;&gt;偏向锁的撤销&lt;/h3&gt;

&lt;p&gt;$\qquad$偏向锁的释放与撤销是两个不同的概念。释放操作仅在自身线程栈中，锁对象在其他线程看来依然属于其偏向的线程。
但是在多线程环境中，一个线程事实上不能无限期的占用锁。因此需要引入偏向锁的撤销机制，将偏向锁还原为匿名偏向的状态。这样当持有锁的线程结束退出之后，其他线程可以再次获取锁使其偏向自己；或者当多个线程交替获取锁时，可以顺利升级为轻量锁。&lt;/p&gt;

&lt;p&gt;$\qquad$在 CAS 操作获取锁失败时，说明有多于一个线程&lt;strong&gt;使用过&lt;/strong&gt;该锁。这时需要先把当前的偏向锁撤销。
撤销偏向锁需要等待一个全局安全点，此时所有线程都已挂起，然后检查当前持有偏向锁的线程。此时有两种可能：
1. 如果该线程已经退出了同步代码块，或者线程已经不存在了，则偏向锁可以安全撤销，变回无锁状态，然后再次偏向为当前线程。这个过程称为&lt;code&gt;重偏向(rebias)&lt;/code&gt;。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果该线程还在同步代码块内，则需要将锁膨胀为轻量锁。&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;偏向锁的膨胀&#34;&gt;偏向锁的膨胀&lt;/h3&gt;

&lt;p&gt;所谓「膨胀」只是个逻辑上的概念。实际在代码中，只不过是偏向锁获取失败时，撤销锁并使用轻量锁重新获取锁而已。&lt;/p&gt;

&lt;h3 id=&#34;批量重偏向与-epoch&#34;&gt;批量重偏向与 Epoch&lt;/h3&gt;

&lt;h2 id=&#34;轻量锁&#34;&gt;轻量锁&lt;/h2&gt;

&lt;h3 id=&#34;轻量锁的适用场景&#34;&gt;轻量锁的适用场景&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;适用于多个线程&lt;strong&gt;无抢占&lt;/strong&gt;地先后执行互斥代码段的场景。即上一个线程释放锁一段时间之后，下一个线程才开始获取锁。在并发量较低时使用轻量锁可以提升性能。&lt;/li&gt;
&lt;li&gt;当发现上一个线程还未释放锁，下一个线程已经开始获取锁，说明此时发生了抢占，将膨胀为重量锁。
但还有一个问题是， MarkWord 中原本就存储了对象的元信息，例如对象的哈希值，对象的 GC 存活次数等，如果在 MarkWord 中存储了偏向锁信息，那么原先的信息被挤到哪里去了？答案是那些信息在栈中创建单独的对象来保存，也就是 Lock Record。Lock Record 中会保留两部分信息，一部分是被转移过来的对象的 MarkWord，另一部分是指向该对象的指针。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;轻量锁的原理&#34;&gt;轻量锁的原理&lt;/h3&gt;

&lt;p&gt;即使线程通过偏向锁的方式获取锁失败时，依然有可能锁是为锁定状态：偏向锁已撤销，或者锁对象已经计算了哈希值，不再支持偏向锁。
如果在启动 JVM 时禁用了偏向锁，那么线程会直接以轻量锁的方式获取锁。&lt;br /&gt;
1. 当第一次获取锁时，锁对象的 MarkWord 为 后三位为 0b001，因此会构建一个未锁定状态的 MarkWord (后三位值为 0b001) 保存于线程栈最近的一个 Lock Record 中。然后试图通过 CAS 操作将锁对象的 MarkWord 和 LockRecord 的地址交换，如果交换成功，那么 Lock Record 中会保存锁对象的 MarkWord，而锁对象的 MarkWord 中保存的是 LockRecord 的地址，相当于锁对象的 MarkWord 变成了指向 Lock Record 的指针。&lt;br /&gt;
2. 当第 N 次获取锁时，有可能是其他线程在竞争锁，或者同一个线程以重入的方式获取锁。 无论哪种方式，CAS 一定会失败，因为此时锁对象的 MarkWord 后三位不再是 0b001 ，而是指向某个线程栈中的 Lock Record 的指针(0b000)。此时便需要判断是否为同一个线程，如果是则说明是重入，否则说明发生了多线程竞争锁，需要膨胀为重量锁。&lt;br /&gt;
当同一个线程重入时，会在线程栈中创建一个新的 Lock Record ，但不用再 CAS 保存 MarkWord 了——此时 MarkWord 中保存的是同线程中另一个 Lock Record 的地址。
由于内存对齐的缘故，Lock Record 的地址一定是 4 的倍数，即二进制后两位一定是 00 。此时便可以判断 MarkWord 的后两位判断是否为指向了一个 Lock Record，即是否为轻量锁状态。&lt;/p&gt;

&lt;h3 id=&#34;轻量锁的膨胀&#34;&gt;轻量锁的膨胀&lt;/h3&gt;

&lt;p&gt;当发现多个线程竞争同一个锁时，有三种可能：
- 锁还没有分配，此时按轻量锁逻辑重新获得锁。如果失败了就需要膨胀。
- 同一个线程重入获得锁，此时创建 Lock Record 计数，并继续执行同步代码。不需要膨胀。
- 不同的线程同时竞争，如果等不到其他线程释放锁，那么便需要膨胀为重量锁。&lt;/p&gt;

&lt;h2 id=&#34;重量锁&#34;&gt;重量锁&lt;/h2&gt;

&lt;p&gt;重量锁就是传统的互斥锁。偏向锁不需要额外的对象，轻量锁需要 Lock Record 以保存锁对象的 MarkWord，而重量级锁需要更复杂的机制——JVM 中称之为 ObjectMonitor。&lt;br /&gt;
ObjectMonitor 是一个基于 MESA 模型实现的一种管程。管程的特点是可以通过若干个条件变量实现等待。不过 synchronized 做了简化，只有一个条件变量，也就只有一个等待队列。&lt;/p&gt;

&lt;h3 id=&#34;重量锁的原理&#34;&gt;重量锁的原理&lt;/h3&gt;

&lt;p&gt;重量锁与轻量锁相比，是个十足的“大家伙”。其内部有多个队列用于存储不同状态的线程。&lt;br /&gt;
另外，Java 中的 &lt;code&gt;wait()&lt;/code&gt;, &lt;code&gt;notify()&lt;/code&gt;, &lt;code&gt;notifyAll()&lt;/code&gt; 三个方法也是重量锁提供的机制。换句话说，如果线程要使用这三个方法，那么必须要膨胀为重量锁。
重量锁中有这样几个集合，线程经过封装后以 WaiterObject 的形式在几个集合中流转：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;cxq&lt;/strong&gt;: 只能用 CAS 操作更改头指针的方式修改的单链表结构。
用于存储试图获取锁，但是获取失败的线程。这些线程会使用 &lt;code&gt;pthread_cond_wait&lt;/code&gt; 系统调用将自身挂起。
每次有新的线程试图获取锁失败时，会用头插法加入该链表；因此线程会遵循&lt;code&gt;后入先出&lt;/code&gt;的原则。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;EntryList&lt;/strong&gt;: cxq 队列中有资格成为候选资源的线程会被移动到该队列中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;WaitSet&lt;/strong&gt;: 当线程主动调用 &lt;code&gt;Object::wait()&lt;/code&gt;时，会进入该集合，挂起并释放掉锁。 这个集合就对应着管程模型中的等待队列。
当有线程调用 &lt;code&gt;notify()&lt;/code&gt;或&lt;code&gt;notifyAll()&lt;/code&gt;时，会从该集合中将线程移动到 cxq 或 EntryList 中等待下一次获得锁并继续执行。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，ObjectMonitor 还有 owner 属性用于表示当前持有锁的线程， recursive 计数器用于保存同一线程的重入次数等。&lt;/p&gt;

&lt;h3 id=&#34;获取重量锁&#34;&gt;获取重量锁&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;如果当前是无锁状态、锁重入、当前线程是之前持有轻量级锁的线程则只需更新一下 owner 和 重入计数即可继续执行同步代码。&lt;/li&gt;
&lt;li&gt;如果已经有其他线程持有了锁，便先自旋尝试等待锁释放，这样做的目的是为了减少执行操作系统同步操作带来的开销。&lt;/li&gt;
&lt;li&gt;如果还是没有获取到锁，就将自己作为头节点插入到 cxq 中，然后调用 &lt;code&gt;pthread_cond_wait&lt;/code&gt; 将自己挂起。直到被其他线程释放锁时唤醒后再次尝试获取锁。&lt;/li&gt;
&lt;li&gt;如果线程在获取到锁之后调用了 &lt;code&gt;wait()&lt;/code&gt; 主动休眠，就会释放掉锁，然后该线程会进入 WaitSet 等待唤醒。进入 WaitSet 的线程也会调用 &lt;code&gt;pthread_cond_wait&lt;/code&gt; 将自己挂起。与 cxq 中的挂起不同的是，这些线程只有当其他线程调用 &lt;code&gt;notify()&lt;/code&gt;,&lt;code&gt;notifyAll()&lt;/code&gt; 时才会被唤醒。&lt;/li&gt;
&lt;li&gt;如果线程调用了 &lt;code&gt;notify()&lt;/code&gt;，&lt;code&gt;notifyAll()&lt;/code&gt; 方法，那么会从 WaitSet 中选取一个线程，放入 cxq 或 EntryList 中，使其可以参与后续的锁竞争。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当获取到锁之后需要将当前线程从 cxq 或 EntryList 移除。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang使用gRPC指南</title>
      <link>https://violinsonata.site/2020/use-grpc-in-golang/</link>
      <pubDate>Fri, 04 Sep 2020 15:05:10 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/use-grpc-in-golang/</guid>
      <description>

&lt;p&gt;本文以一个简单的CURD服务为例演示了如果一步步使用grpc的接口.&lt;/p&gt;

&lt;h2 id=&#34;使用protobuf&#34;&gt;使用protobuf&lt;/h2&gt;

&lt;h3 id=&#34;编写proto文件&#34;&gt;编写proto文件&lt;/h3&gt;

&lt;p&gt;proto文件是定义整个protobuf生态的基石, protobuf,grpc, grpc-gateway等代码都是通过proto文件来生成桩代码的.&lt;br /&gt;
proto文件主要包含 syntax, package, option, import, message, service 等几部分.&lt;br /&gt;
- syntax&lt;br /&gt;
  用于指定proto文件使用了protobuf协议的版本. 可以选择proto2或proto3, 推荐使用较新的版本proto3;
- package&lt;br /&gt;
  用于指定当前proto文件所在的包名称, 只需要声明完整包名的最后一部分即可. 例如某个文件&lt;code&gt;A.proto&lt;/code&gt;位于&lt;code&gt;github.com/someproject/api/Apple.proto&lt;/code&gt;, 那么这个文件的package只需要指定some_apis即可.&lt;br /&gt;
- option&lt;br /&gt;
  用于针对特定场景设定一些选项. 例如在v1.20以后的版本中, 用户如果想要将proto编译成Golang代码, 就需要指定&lt;code&gt;go_package&lt;/code&gt;选项.
- import&lt;br /&gt;
  proto文件可以分成多个, 不同的proto文件之间可以使用import字段互相引用, 达到代码复用的目的. import声明的路径可以是相对路径, 例如如果引入同一个目录下的其他proto文件, 则可以直接写文件名. 如果引入其他目录的文件, 也不必从文件系统根目录或项目根目录开始写起, 但是在编译的时候必须通过&lt;code&gt;-I&lt;/code&gt;参数指明找到被引入文件的起始路径, 换句话说 &lt;code&gt;-I&lt;/code&gt;+&lt;code&gt;import&lt;/code&gt; 需要指向proto文件的路径.
- message&lt;br /&gt;
  message用于定义数据结构.  如果不使用grpc远程调用, 而只是用protobuf作为数据传输的格式的话,  那么只需要定义message即可, 不需要定义service.
- service&lt;br /&gt;
  用于定义API服务的通信接口.&lt;/p&gt;

&lt;p&gt;我们先只用protobuf, 因此只需要不需要声明service, 只需要定义message就够了.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package api;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;;

message Apple{
  int32 number = 1;
  string name = 2;
  Size size = 3;

  enum Size{
    SIZE_UNDEFINED = 0;
    BIG = 4;
    MID = 5;
    SMALL = 6;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载protoc工具&#34;&gt;下载protoc工具&lt;/h3&gt;

&lt;p&gt;protoc 是用于编译proto文件生成对应桩代码的命令行工具. protoc工具使用C++编写, 其项目地址位于&lt;a href=&#34;https://github.com/protocolbuffers/protobuf&#34;&gt;https://github.com/protocolbuffers/protobuf &lt;/a&gt; .&lt;br /&gt;
对于非C++的用户, 可以直接下载预先编译好的二进制文件: &lt;a href=&#34;https://github.com/protocolbuffers/protobuf/releases&#34;&gt;https://github.com/protocolbuffers/protobuf/releases &lt;/a&gt;, 例如对于macOS用户, 选择 &lt;code&gt;protobuf-3.13.0-osx-x86_64.tar.gz&lt;/code&gt;下载解压, 并放在$PATH下面.&lt;/p&gt;

&lt;h3 id=&#34;下载protoc插件-protoc-gen-go&#34;&gt;下载protoc插件: protoc-gen-go&lt;/h3&gt;

&lt;p&gt;protoc编译proto文件时, 根据生成不同语言的桩代码的需求, 需要指定不同的插件. 例如需要生成Golang的桩代码, 便需要指定go语言的插件: &lt;code&gt;protoc-gen-go&lt;/code&gt;.&lt;br /&gt;
值得一提的是, golang的插件在2020年初经历了比较大的变更: 原来其项目地址位于&lt;a href=&#34;https://github.com/golang/protobuf&#34;&gt;github.com/golang/protobuf&lt;/a&gt;, 代码中的导入地址是 &lt;code&gt;github.com/golang/protobuf/proto&lt;/code&gt;, 其版本迭代到 v1.4,  2020年三月份由新的项目取代: &lt;a href=&#34;https://github.com/protocolbuffers/protobuf-go&#34;&gt;google.golang.org/protobuf&lt;/a&gt;, 版本从 v1.20 开始迭代. v1.20相对于v1.4作出了许多重大的变更, 包括部分API变更, 以及原有的部分可导出模块不再导出. 对于中国开发者来说比较重要的变更在于修复了打印结构体内的非ASCII字符会乱码的bug( &lt;a href=&#34;https://github.com/golang/protobuf/issues/572&#34;&gt;Issue #572&lt;/a&gt; ).&lt;br /&gt;
插件可以直接在项目的Github Release页面下载编译好的版本, 或者 git clone 然后自行安装:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone -b v1.31 git@github.com:protocolbuffers/protobuf-go.git
cd protobuf-go
# go install 会将项目编译生产的二进制文件放入 $GOPATH/bin. 
# 需要把 $GOPATH/bin 加入 $PATH 以使protoc能够找到. 
go install .
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;编译使用的命令参数可以见另一篇文章.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
  --go_out=paths=source_relative:. \
  api/apple.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以在api目录下看到生成的桩代码 &lt;code&gt;apple.pb.go&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── README.md
├── api
│   ├── apple.pb.go
│   └── apple.proto
├── go.mod
└── main.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;为了使用 apple.pb.go, 我们还需要在Golang代码中导入protobuf的运行库 &lt;code&gt;google.golang.org/protobuf/proto&lt;/code&gt;, 然后利用其中的&lt;code&gt;Marshal&lt;/code&gt;和&lt;code&gt;Unmashal&lt;/code&gt; 两个API 进行消息的编码解码.
&lt;a href=&#34;https://github.com/protocolbuffers/protobuf/blob/master/examples/add_person.go&#34;&gt;examples&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main
import(
	&amp;quot;bufio&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;strings&amp;quot;

  `google.golang.org/protobuf/proto`

  `github.com/grpc-apple/api`
)

func main(){
	if len(os.Args) != 2 {
		log.Fatalf(&amp;quot;Usage:  %s ADDRESS_BOOK_FILE\n&amp;quot;, os.Args[0])
	}
	fname := os.Args[1]

	// Read the existing address book.
	in, err := ioutil.ReadFile(fname)
	if err != nil {
		if os.IsNotExist(err) {
			fmt.Printf(&amp;quot;%s: File not found.  Creating new file.\n&amp;quot;, fname)
		} else {
			log.Fatalln(&amp;quot;Error reading file:&amp;quot;, err)
		}
	}

	// [START marshal_proto]
	book := &amp;amp;pb.AddressBook{}
	// [START_EXCLUDE]
	if err := proto.Unmarshal(in, book); err != nil {
		log.Fatalln(&amp;quot;Failed to parse address book:&amp;quot;, err)
	}

	// Add an address.
	addr, err := promptForAddress(os.Stdin)
	if err != nil {
		log.Fatalln(&amp;quot;Error with address:&amp;quot;, err)
	}
	book.People = append(book.People, addr)
	// [END_EXCLUDE]

	// Write the new address book back to disk.
	out, err := proto.Marshal(book)
	if err != nil {
		log.Fatalln(&amp;quot;Failed to encode address book:&amp;quot;, err)
	}
	if err := ioutil.WriteFile(fname, out, 0644); err != nil {
		log.Fatalln(&amp;quot;Failed to write address book:&amp;quot;, err)
	}
	// [END marshal_proto]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使用grpc&#34;&gt;使用grpc&lt;/h2&gt;

&lt;p&gt;我们需要查询, 创建, 更新, 修改, 删除五个接口.&lt;/p&gt;

&lt;h3 id=&#34;编写proto文件-1&#34;&gt;编写proto文件&lt;/h3&gt;

&lt;p&gt;事实上, 所有的定义都可以写进一个proto文件里, 不过在复杂项目中这样显然不好. 本文使用了多个不同目录下的proto文件, 以演示在复杂项目中不同的定义是怎样互相引用的.&lt;br /&gt;
此处我们为了定义五个接口而在新的目录&lt;code&gt;api/operation/&lt;/code&gt;创建了新的&lt;code&gt;operations.proto&lt;/code&gt;文件.&lt;br /&gt;
值得一提的是导入&lt;code&gt;apple.proto&lt;/code&gt;文件时指定的路径. 上文已经说了import与-I参数的关系, 实际上这两个参数还关系着生成的桩代码的位置. 在本项目中, 希望将桩代码与对应的proto文件放在一起.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package operation;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;;
// 引入protobuf官方提供的Empty结构作为部分接口的空返回值. 
import &amp;quot;google/protobuf/empty.proto&amp;quot;;
// 引入protobuf官方提供的Field_Mask用于支持修改操作. 
import &amp;quot;google/protobuf/field_mask.proto&amp;quot;;
// 引入上级目录的apple文件以复用定义
import &amp;quot;api/apple.proto&amp;quot;;

service AppleService{
  rpc DescribeApple(DescribeAppleRequest) returns (api.Apple) {}
  rpc CreateApple(CreateAppleRequest) returns (api.Apple) {}
  rpc UpdateApple(UpdateAppleRequest) returns (api.Apple) {}
  rpc ModifyApple(ModifyAppleRequest) returns (api.Apple) {}
  rpc DestroyApple(DestroyAppleRequest) returns (google.protobuf.Empty) {}
}

// 为了提供调用接口, 我们新声明了五个消息类型, 需要定义. 
message DescribeAppleRequest{
  int32 number = 1;
}
message CreateAppleRequest{
  string name = 2;
  api.Apple.Size size = 3;
}
// 更新操作: 必须指定对象全部的属性, 
// 对于未指定的属性, 应该将其设定为空或默认值; 
message UpdateAppleRequest{
  int32 number = 1;
  string name = 2;
  api.Apple.Size size = 3;
}
// 修改操作: 只需要设定对象需要变更的属性, 
// 对于未指定的属性, 会保留原来的值. 
// grpc中为了支持修改操作, 需要添加额外的FieldMask字段. 
// 不过好在该字段的值不需要用户设定, grpc会自动生成. 
message ModifyAppleRequest{
  int32 number = 1;
  string name = 2;
  api.Apple.Size size = 3;
  google.protobuf.FieldMask mask = 4;
}

message DestroyAppleRequest{
  string name = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载protoc插件-protoc-gen-go-grpc&#34;&gt;下载protoc插件: protoc-gen-go-grpc&lt;/h3&gt;

&lt;p&gt;同 protoc-gen-go 一样, 生成grpc代码也需要对应的插件: protoc-gen-go-grpc. 在&lt;code&gt;github.com/golang/protobuf&lt;/code&gt;将protoc-gen-go代码的归属权托管给了&lt;code&gt;golang.google.org/grpc-go&lt;/code&gt;(参考&lt;a href=&#34;https://github.com/golang/protobuf/issues/903&#34;&gt;golang/protobuf #903&lt;/a&gt;), 从此作为grpc-go的一个工具, 生成grpc桩代码的方式也发生了巨大的变化.&lt;br /&gt;
在protoc-go v1.4 版本之前, 也就是旧项目中, protoc-grpc是作为 protoc-gen-go的插件存在的, 也就是protoc的插件的插件.&lt;br /&gt;
而在 protoc-go v1.20 之后, 也就是新项目中, protoc-grpc是作为protoc的插件存在, 也就是“升级”了, 从插件的插件变成了独立的插件.&lt;br /&gt;
proto-gen-go-grpc 目前还没有发布预编译的新插件, 想要使用的话必须自行编译安装:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 直接安装:
go get -u google.golang.org/grpc

# 或者这样:
git clone git@github.com:grpc/grpc-go.git
cd grpc-go &amp;amp;&amp;amp; go install .
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译-1&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;由于存在新旧两种插件, 因此编译命令也有了两种.&lt;br /&gt;
值得一提的是, protoc 不支持一次性编译多个包, 如果指定了多个包, 会造成错误.&lt;br /&gt;
旧版命令:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
    --go_out=plugins=grpc,paths=source_relative:. \
    api/apple.proto 

protoc \
  -Iapi
  --go_out=plugins=grpc,paths=source_relative:. \
  api/operation/operations.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新版命令:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
  --go_out=paths=source_relative:. \
  --go-grpc_out=paths=source_relative:. \
  api/apple.proto

protoc \
  --go_out=paths=source_relative:. \
  --go-grpc_out=paths=source_relative:. \
  api/operation/operations.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显然新版命令比旧版的更长了 -,-!&lt;/p&gt;

&lt;p&gt;编译之后可以看到proto文件所在目录下多了生成的桩代码.
&lt;code&gt;apple.pb.go&lt;/code&gt;是为api/apple.proto生成的; &lt;code&gt;operations.pb.go&lt;/code&gt; 是为operations.proto中的message生成的; &lt;code&gt;operations_grpc.pb.go&lt;/code&gt; 是为operations.proto中service的部分生成的. 为什么message和service要分别生成两个文件, 我也不知道.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── README.md
├── api
│   ├── apple.pb.go
│   ├── apple.proto
│   └── operation
│       ├── operations.pb.go
│       ├── operations.proto
│       └── operations_grpc.pb.go
├── go.mod
└── main.go
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;实现接口&#34;&gt;实现接口&lt;/h3&gt;

&lt;p&gt;新建一个service 包, 将几个接口的具体实现放在里面:&lt;br /&gt;
service/service.go:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package service

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
)

// protoc-gen-go-grpc v1.20 之后, 实现服务的时候必须嵌入 UnimplementedAppleServiceServer 以保证能够向后兼容.
type AppleService struct {
	UnimplementedAppleServiceServer
}

func (*AppleService) DescribeApple(ctx context.Context, req *DescribeAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) CreateApple(ctx context.Context, req *CreateAppleRequest) (*Apple, error) {
	log.Println(req)
	return &amp;amp;Apple{}, nil
}
func (*AppleService) UpdateApple(ctx context.Context, req *UpdateAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) ModifyApple(ctx context.Context, req *ModifyAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) DestroyApple(ctx context.Context, req *DestroyAppleRequest) (*empty.Empty, error) {
	return &amp;amp;empty.Empty{}, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用-1&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;代码位于&lt;code&gt;simple-grpc&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	&amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
)


func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;AppleService{})
	reflection.Register(grpcServer)

	if l, err := net.Listen(`tcp`, `:9000`); err != nil {
		log.Fatal(`cannot listen to port 9000: `, err)
	} else if err = grpcServer.Serve(l); err != nil {
		log.Fatal(`cannot start service:`, err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使用grpc-gateway&#34;&gt;使用grpc-gateway&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/grpc-ecosystem/grpc-gateway&#34;&gt;grpc-gateway&lt;/a&gt; 是grpc-ecosystem 的子项目, 用于提供grpc的反向代理, 实现开发GRPC, 提供RestAPI的目的.&lt;br /&gt;
grpc-gateway 同样也是 protoc 的插件, 并且仅支持生成Golang语言的桩代码.&lt;br /&gt;
但是, 生成的反向代理可以作为独立的进程, 因此实际可以支持各种语言的grpc服务.  只不过作为Golang语言可以实现更多的特性, 比如复用端口同时提供grpc和http两种接口.&lt;/p&gt;

&lt;h3 id=&#34;修改operations-proto&#34;&gt;修改operations.proto&lt;/h3&gt;

&lt;p&gt;为了使用grpc-gateway, 需要在 operations.proto 中引入grpc-gateway的proto文件, 并在每个rpc中添加配置.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;syntax = &amp;quot;proto3&amp;quot;;
package operation;
option go_package=&amp;quot;github.com/violin0622/grpc-apple/operation/api&amp;quot;;
// 引入protobuf官方提供的Empty结构作为部分接口的空返回值. 
import &amp;quot;google/protobuf/empty.proto&amp;quot;;
// 引入protobuf官方提供的Field_Mask用于支持修改操作. 
import &amp;quot;google/protobuf/field_mask.proto&amp;quot;;
// 引入annotation用于定义gateway
import &amp;quot;google/api/annotations.proto&amp;quot;;
// 引入上级目录的apple文件以复用定义
import &amp;quot;apple.proto&amp;quot;;

service AppleService{
  rpc DescribeApple(DescribeAppleRequest) returns (Apple) {
    option (google.api.http).get = &amp;quot;/apples/{number}&amp;quot;;
  }
  rpc CreateApple(CreateAppleRequest) returns (Apple) {
    option (google.api.http) = {
      post: &amp;quot;/apples&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc UpdateApple(UpdateAppleRequest) returns (Apple) {
    option (google.api.http) = {
      put: &amp;quot;/apples/{number}&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc ModifyApple(ModifyAppleRequest) returns (Apple) {
    option (google.api.http) = {
      patch: &amp;quot;/apples/{number}&amp;quot;
      body: &amp;quot;*&amp;quot;
    };
  }
  rpc DestroyApple(DestroyAppleRequest) returns (google.protobuf.Empty) {
    option (google.api.http).delete = &amp;quot;/apples/{number}&amp;quot;;
  }
}

// 为了提供调用接口, 我们新声明了五个消息类型, 需要定义. 
message DescribeAppleRequest{
  int32 number = 1;
}
message CreateAppleRequest{
  string name = 2;
  Apple.Size size = 3;
}
// 更新操作: 必须指定对象全部的属性, 
// 对于未指定的属性, 应该将其设定为空或默认值; 
message UpdateAppleRequest{
  int32 number = 1;
  string name = 2;
  Apple.Size size = 3;
}
// 修改操作: 只需要设定对象需要变更的属性, 
// 对于未指定的属性, 会保留原来的值. 
// grpc中为了支持修改操作, 需要添加额外的FieldMask字段. 
// 不过好在该字段的值不需要用户设定, grpc会自动生成. 
message ModifyAppleRequest{
  int32 number = 1;
  string name = 2;
  Apple.Size size = 3;
  google.protobuf.FieldMask mask = 4;
}

message DestroyAppleRequest{
  int32 number = 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;下载-protoc-gen-grpc-gateway&#34;&gt;下载 protoc-gen-grpc-gateway&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get github.com/grpc-ecosystem/grpc-gateway
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;编译-2&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;apple.proto 我们已经编译过了并且没有修改过, 因此可以直接编译 operations.proto&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;protoc \
    -I. \
    -I$GOPATH/pkg/mod/github.com/grpc-ecosystem/grpc-gateway@v1.14.8/third_party/googleapis  \
    --go_out=paths=source_relative:. \
    --go-grpc_out=paths=source_relative:. \
    --grpc-gateway_out=paths=source_relative:. \
    api/operation/*.proto
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用-2&#34;&gt;使用&lt;/h3&gt;

&lt;p&gt;由于grpcServer监听端口会把线程Hang住, 因此需要通过&lt;code&gt;go&lt;/code&gt;操作符创建额外的goroutine用于运行监听函数.&lt;br /&gt;
程序运行起来之后会监听两个端口: grpc服务监听本地8000端口, http服务监听本地9000端口, 并把请求转发到8000端口的grpc服务上.&lt;br /&gt;
此时可以使用 curl localhost:8000 通过http方式访问, 也可以使用 grpcurl -plaintext localhost:9000 通过grpc方式访问.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net&amp;quot;
	&amp;quot;net/http&amp;quot;

	&amp;quot;github.com/golang/protobuf/ptypes/empty&amp;quot;
	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	. &amp;quot;github.com/violin0622/grpc-apple/api&amp;quot;
)

// protoc-gen-go-grpc v1.20 之后, 实现服务的时候必须嵌入 UnimplementedAppleServiceServer 以保证能够向后兼容.
type AppleService struct {
	UnimplementedAppleServiceServer
}

func (*AppleService) DescribeApple(ctx context.Context, req *DescribeAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) CreateApple(ctx context.Context, req *CreateAppleRequest) (*Apple, error) {
	log.Println(req)
	return &amp;amp;Apple{}, nil
}
func (*AppleService) UpdateApple(ctx context.Context, req *UpdateAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) ModifyApple(ctx context.Context, req *ModifyAppleRequest) (*Apple, error) {
	return &amp;amp;Apple{}, nil
}
func (*AppleService) DestroyApple(ctx context.Context, req *DestroyAppleRequest) (*empty.Empty, error) {
	return &amp;amp;empty.Empty{}, nil
}

func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;AppleService{})
	reflection.Register(grpcServer)
	l, _ := net.Listen(`tcp`, `:8000`)
	go grpcServer.Serve(l)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithInsecure()},
	)

	if err := http.ListenAndServe(`:9000`, httpServer); err != nil {
		log.Fatal(`cannot start service: `, err)
	}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway-与-grpc-使用相同的端口-使用tls&#34;&gt;gateway 与 grpc 使用相同的端口(使用TLS)&lt;/h2&gt;

&lt;p&gt;基本思路是通过判断 Content-Type 字段来分辨入请求是基于HTTP还是GRPC, 然后分别转发到对应的server handler上.&lt;br /&gt;
代码位于 reuse-port-tls/server.go&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;strings&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/credentials&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	&amp;quot;github.com/violin0622/grpc-apple/service&amp;quot;
)

func main() {
	serverCred, err := credentials.NewServerTLSFromFile(`./server.pem`, `./server.key`)
	if err != nil {
		log.Fatal(err)
	}
	clientCred, err := credentials.NewClientTLSFromFile(`./server.pem`, `localhost`)
	if err != nil {
		log.Fatal(err)
	}

	grpcServer := grpc.NewServer(grpc.Creds(serverCred))
	RegisterAppleServiceServer(grpcServer, &amp;amp;service.AppleService{})
	reflection.Register(grpcServer)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithTransportCredentials(clientCred)},
	)

	http.ListenAndServeTLS(`:8000`, `./server.pem`, `./server.key`,
		http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {

			if r.ProtoMajor == 2 &amp;amp;&amp;amp;
				strings.Contains(r.Header.Get(`Content-Type`), `application/grpc`) {
				log.Println(`grpc`)
				grpcServer.ServeHTTP(w, r)
			} else {
				log.Println(`http`)
				httpServer.ServeHTTP(w, r)
			}
		}),
	)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gateway-与-grpc-使用相同的端口-不使用tls&#34;&gt;gateway 与 grpc 使用相同的端口(不使用TLS)&lt;/h2&gt;

&lt;p&gt;代码位于 reuse-port-insecure/server.go.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;context&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;net/http&amp;quot;
	&amp;quot;strings&amp;quot;

	&amp;quot;github.com/grpc-ecosystem/grpc-gateway/runtime&amp;quot;
	&amp;quot;golang.org/x/net/http2&amp;quot;
	&amp;quot;golang.org/x/net/http2/h2c&amp;quot;
	&amp;quot;google.golang.org/grpc&amp;quot;
	&amp;quot;google.golang.org/grpc/reflection&amp;quot;

	. &amp;quot;github.com/violin0622/grpc-apple/api/operation&amp;quot;
	&amp;quot;github.com/violin0622/grpc-apple/service&amp;quot;
)

func main() {
	grpcServer := grpc.NewServer()
	RegisterAppleServiceServer(grpcServer, &amp;amp;service.AppleService{})
	reflection.Register(grpcServer)

	httpServer := runtime.NewServeMux()
	RegisterAppleServiceHandlerFromEndpoint(
		context.Background(),
		httpServer,
		`:8000`,
		[]grpc.DialOption{grpc.WithInsecure()},
	)

	http.ListenAndServe(
		`:8000`,
		h2c.NewHandler(
			http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {

				if r.ProtoMajor == 2 &amp;amp;&amp;amp;
					strings.Contains(r.Header.Get(`Content-Type`), `application/grpc`) {
					log.Println(`grpc`)
					grpcServer.ServeHTTP(w, r)
				} else {
					log.Println(`http`)
					httpServer.ServeHTTP(w, r)
				}
			}),
			&amp;amp;http2.Server{}),
	)
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Golang使用私有仓库</title>
      <link>https://violinsonata.site/2020/use-private-repo-in-golang/</link>
      <pubDate>Mon, 31 Aug 2020 14:51:20 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/use-private-repo-in-golang/</guid>
      <description>

&lt;p&gt;本文基于&lt;code&gt;go 1.13&lt;/code&gt;即以上进行演示。&lt;br /&gt;
将go代码推送到私有仓库之后， 如果想要在其他项目引用， 需要做以下设置。&lt;/p&gt;

&lt;h2 id=&#34;设置go-env&#34;&gt;设置go env&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 设置代理， 多个用逗号分隔， 最后direct是直接从项目地址拉取。 
# 这一步不是使用私有仓库必须设置的. 但是考虑到国内的网络情况, 应该大部分gopher都设置了该项吧. 
go env -w GOPROXY=&amp;quot;https://goproxy.cn,direct&amp;quot;

# 设置不使用代理的域名, 用逗号分开多个。 可以设置通配符*，或者指定路径
go env -w GOPRIVATE=&amp;quot;*.gitlab.com,private.gitlab.com/myrepo&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;设置git-token&#34;&gt;设置git token&lt;/h2&gt;

&lt;p&gt;只设置了 go env 还不够。 无论 go mod 也好， go get 也好， 都是依赖git来拉取项目代码的， 如果git没有访问仓库的权限依然不能正确拉取。&lt;br /&gt;
以 Gitlab 为例， 需要创建一个访问Token， go 控制 git 拉取代码时使用该token进行认证， 才可以拉取代码。&lt;br /&gt;
&lt;img src=&#34;https://violinsonata.site/image/posts/申请gitlab的token.png&#34; alt=&#34;申请token&#34; /&gt;&lt;/p&gt;

&lt;p&gt;创建token之后， 对git进行全局设置:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git config --global url.&amp;quot;https://{username}:{token}@private.gitlab.com/myrepo&amp;quot;.insteadOf &amp;quot;https://private.gitlab.com/myrepo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以正常拉取私有仓库的代码了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;note&lt;/code&gt; Coding的设置和Gitlab不太一样。 首先Coding的代码仓库网页URI和Git地址并不一样。&lt;br /&gt;
例如我的项目访问网页时地址是&lt;code&gt;https://mlt.coding.net/p/riverrun/gogfapi&lt;/code&gt;， 而git地址是&lt;code&gt;https://e.coding.net/mlt/riverrun/gogfapi.git&lt;/code&gt;。&lt;br /&gt;
在设置GOPRIVATE和git时， 应使用git地址， 且最后需要附带&lt;code&gt;.git&lt;/code&gt;。 在项目中引用模块时， &lt;code&gt;import&lt;/code&gt; 语句也需要写git地址， 同样需要带着&lt;code&gt;.git&lt;/code&gt;后缀。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basic Concept of Rabbitmq</title>
      <link>https://violinsonata.site/2020/basic-concept-of-rabbitmq/</link>
      <pubDate>Mon, 24 Aug 2020 15:25:07 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/basic-concept-of-rabbitmq/</guid>
      <description>

&lt;h2 id=&#34;message-消息&#34;&gt;Message 消息&lt;/h2&gt;

&lt;p&gt;消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;从消息的属性可以看出， RabbitMQ支持至少三个特性：
1. 同一个消息路由分发至不同的队列中。&lt;br /&gt;
2. 不同的消息之间有优先级。
3. 消息可以进行有选择的持久化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;publisher-生产者&#34;&gt;Publisher 生产者&lt;/h2&gt;

&lt;p&gt;一个向交换器发布消息的客户端应用程序。 生产者并不会直接将消息发送到队列中， 而是发送到服务端的交换器上， 再由交换器按预设条件将消息分发到各个队列上， 或者直接将消息丢弃。&lt;/p&gt;

&lt;h2 id=&#34;exchange-交换器&#34;&gt;Exchange 交换器&lt;/h2&gt;

&lt;p&gt;用来接收生产者发送的消息并将这些消息路由给服务器中的队列。&lt;br /&gt;
&amp;gt; 在RabbitMQ中， 消息并不是由生产者直接写入队列中的。 而是每条消息发到一个指定的交换器中， 再由交换器根据绑定的交换规则分发到队列中。 如果路由不到，或返回给生产者，或直接丢弃，或做其它处理。&lt;/p&gt;

&lt;p&gt;Exchange 具有四种类型，&lt;code&gt;direct&lt;/code&gt;, &lt;code&gt;fanout&lt;/code&gt;, &lt;code&gt;header&lt;/code&gt;, &lt;code&gt;topic&lt;/code&gt;。 &lt;code&gt;header&lt;/code&gt; 和&lt;code&gt;topic&lt;/code&gt;功能一样， 但性能较差， 不推荐使用。&lt;/p&gt;

&lt;h3 id=&#34;fanout&#34;&gt;Fanout&lt;/h3&gt;

&lt;p&gt;通过队列名进行绑定。 可以绑定多个队列， 每个消息都会发送到所有绑定的队列上。&lt;br /&gt;
扇形交换器不受RoutingKey和BindingKey的限制。&lt;br /&gt;
&amp;gt; 使用Fanout就相当于将消息广播到所有绑定的队列上。&lt;/p&gt;

&lt;h3 id=&#34;direct&#34;&gt;Direct&lt;/h3&gt;

&lt;p&gt;交换器通过BindingKey和队列进行绑定， 生产者每条发送的消息都要带有一个RoutingKey。 交换器通过BindingKey和RoutingKey的匹配进行分发。 只有完全匹配（即RoutingKey == BindingKey）的才可以分发到对应的队列中。 如果一条消息不满足任意一个绑定键， 那么它将会被丢弃。&lt;br /&gt;
绑定时有如下几个特点：&lt;br /&gt;
- 不同的队列可以通过不同的BindingKey绑定到同一个交换器上， 此时交换器会根据消息的RoutingKey选择发送到哪个队列。
- 多个不同的队列可以通过相同的BindingKey绑定到同一个交换器上， 交换器会将匹配的消息发送到通过该BindingKey绑定的所有队列上。
- 单个队列可以使用多个BindingKey绑定到同一个交换器上， 当交换器收到满足任意一个BindingKey的消息时， 都会将消息发送到该队列上。&lt;/p&gt;

&lt;h3 id=&#34;topic&#34;&gt;Topic&lt;/h3&gt;

&lt;p&gt;主题交换器只能接受特定格式的路由键——必须是使用点&lt;code&gt;.&lt;/code&gt;分隔开的若干个单词， 整个字符串最多255个字节。 与直连交换器类似， 主题交换器同样根据绑定队列时的绑定键和收到消息时的路由键来决定将消息分发到哪些队列上。 不同的是， 主题交换器允许在&lt;strong&gt;绑定键&lt;/strong&gt;中使用两种通配符：&lt;br /&gt;
1. &lt;code&gt;*&lt;/code&gt;， 代表一个由点分隔开的单词
2. &lt;code&gt;#&lt;/code&gt;， 代表0个或多个单词&lt;/p&gt;

&lt;p&gt;主题交换器同样支持直连交换器那样的复杂绑定。 当一个队列同时通过多个带有通配符的绑定键绑定到一个交换器上， 如果交换器发现一条消息的路由键同时匹配该队列的多个绑定键， 那么这条消息只会向该队列写入一次。&lt;/p&gt;

&lt;h3 id=&#34;默认交换器&#34;&gt;默认交换器&lt;/h3&gt;

&lt;p&gt;如果生产者在发送消息时不指定交换器， 可以使用空字符串指定默认交换器。 默认交换器会使用&lt;code&gt;RoutingKey&lt;/code&gt;作为分发消息的依据。&lt;/p&gt;

&lt;h2 id=&#34;routingkey-bindingkey-路由键-绑定键&#34;&gt;RoutingKey/BindingKey 路由键/绑定键&lt;/h2&gt;

&lt;p&gt;将交换器与队列绑定到一起时指定的绑定规则叫做绑定键。 生产者发送消息时指定的分发规则叫做路由键。 不过在实际编程时，这两个参数可能使用相同的名称。 例如在python代码中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 虽然参数叫 routing_key, 但实际是指定了绑定键
channel.queue_bind(exchange=&#39;topic_logs&#39;, queue=queue_name, routing_key=&#39;*.topic&#39;)

# 发送消息时指定了路由键
channel.basic_publish(exchange=&#39;topic_logs&#39;, routing_key=&#39;log.topic&#39;, body=&#39;hello world&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;binding-绑定&#34;&gt;Binding 绑定&lt;/h2&gt;

&lt;p&gt;绑定用于将服务器上的特定队列和交换器关联起来。 但是绑定操作并不是由服务器管理员执行的， 而是由客户端在生产时或消费时自行指定的。
如果一个交换器没有绑定任何队列， 那么发到这个交换器的消息就会被丢弃。&lt;/p&gt;

&lt;h2 id=&#34;queue-队列&#34;&gt;Queue 队列&lt;/h2&gt;

&lt;p&gt;用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 消息默认保存在内存中， 除非在创建队列时声明其支持持久化，  并且发送消息时声明该消息需要持久化， 这样该消息就会被刷写到磁盘中。&lt;/p&gt;

&lt;h3 id=&#34;临时队列&#34;&gt;临时队列&lt;/h3&gt;

&lt;p&gt;如果客户端在创建队列的时候使用了空字符串作为队列名， 则服务器会使用随机名称创建一个临时队列。 当消费者断开链接时， 临时队列就会被删除。 临时队列适用于消费者不关心队列中的“旧”数据， 而是希望每次连接到服务器时即可消费到最新数据的场景。&lt;br /&gt;
生产者生产消息时不需要知道队列的名字——它们只是将消息发送到交换器上。 但是消费者需要知道队列的名称。 因此临时队列需要由消费者来创建， 并且由消费者绑定到与生产者约定好的交换器上。&lt;/p&gt;

&lt;h2 id=&#34;channel-信道&#34;&gt;Channel 信道&lt;/h2&gt;

&lt;p&gt;由于创建销毁TCP链接是很昂贵的操作， 因此RabbitMQ提出了信道这一概念以复用TCP链接。 一个TCP链接中可以包含多个信道， 每个信道用于生产/消费不同的队列。&lt;/p&gt;

&lt;h2 id=&#34;vhost-虚拟机&#34;&gt;VHost 虚拟机&lt;/h2&gt;

&lt;p&gt;RabbitMQ使用vhost 进行资源隔离。 每个vhost内部可以创建独立的交换器，绑定， 队列， 信道， 不同vhost内的各项资源互不可见。 通过为不同用户分配不同vhost的访问权限， 实现用户隔离。&lt;/p&gt;

&lt;h2 id=&#34;consumer-消费者&#34;&gt;Consumer 消费者&lt;/h2&gt;

&lt;p&gt;一个从消息队列中取得消息的客户端应用程序。 在RabbitMQ中， 同一个队列可以由多个客户端同时消费。 此时RabbitMQ会按顺序将消息一个个分发给客户端， 每个客户端拿到的数据各不相同， 称为Round-Robin。 因此同一队列中的一条消息只能在全局被消费一次。&lt;/p&gt;

&lt;h2 id=&#34;消息ack&#34;&gt;消息ACK&lt;/h2&gt;

&lt;p&gt;当RabbitMQ认为消费者已经成功消费到消息之后， 就会将消息删除。 并且由于其不同客户端遵循Round-Robin机制，  这就意味着如果有一个客户端在拿到消息之后还没来得及处理就挂掉了， 则这条消息也不会被其他客户端处理到。&lt;br /&gt;
为了解决这个问题， RabbitMQ引入了ACK机制并默认开启。 开启此参数意味着只有当客户端收到并处理完了消息， 向服务器发送了ACK之后， 服务器才会将该消息标记为已消费并将其删除。 如果客户端因为种种原因未能响应ACK（如客户端挂掉， 网络超时等因素）， 则服务器会将该消息重新发送给其他消费此队列的客户端。&lt;br /&gt;
&amp;gt; 在使用ack机制时， 客户端一定要在处理完消息之后向服务器发送ACK， 否则服务器永远不知道客户端已经处理过了该消息。 它只能将消息一遍遍地发送到其他客户端上， 并且将数据一直保存在内存中。 随着堆积的消息增多，服务端内存会爆掉。&lt;/p&gt;

&lt;h2 id=&#34;持久化&#34;&gt;持久化&lt;/h2&gt;

&lt;p&gt;RabbitMQ 默认不会对消息进行持久化，其将数据存放于内存中, 宕机即会丢数。 如果需要持久化， 则需要创建一个带持久化参数的队列， 并在发送消息时指定持久化参数为True。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;channel.queue_declare(queue=&#39;task_queue&#39;, durable=True)

channel.basic_publish(exchange=&#39;&#39;,
                      routing_key=&amp;quot;task_queue&amp;quot;,
                      body=message,
                      properties=pika.BasicProperties(
                         delivery_mode = 2, # make message persistent
                      ))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>SSL/TLS的工作原理</title>
      <link>https://violinsonata.site/2020/detail-of-ssl-and-tls/</link>
      <pubDate>Thu, 13 Aug 2020 15:26:47 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/detail-of-ssl-and-tls/</guid>
      <description>

&lt;h2 id=&#34;网络通信过程中可能遇到的风险与应对&#34;&gt;网络通信过程中可能遇到的风险与应对&lt;/h2&gt;

&lt;p&gt;网络通信过程中的数据安全将要面临三个风险:
1. 窃听风险(eavesdropping)
2. 篡改风险(tampering)
3. 冒充风险(pretending)&lt;/p&gt;

&lt;p&gt;为了应对这三个风险， SSL/TLS 协议包含如下机制：&lt;/p&gt;

&lt;h3 id=&#34;1-信息使用密钥加密-使第三方无法窃听&#34;&gt;1. 信息使用密钥加密， 使第三方无法窃听。&lt;/h3&gt;

&lt;p&gt;但是通信双方加密传播数据， 就需要在通信之前先交换密钥， 而交换密钥的过程如果使用明文， 则密钥本身有可能被窃听， 从而导致通信数据也有了被窃听的风险。&lt;/p&gt;

&lt;p&gt;解决方案是借助非对称加密来交换通信密钥。 令服务器拥有私钥和公钥， 服务器把自己公钥明文地发给客户端， 客户端接着生成一个密钥， 然后拿公钥加密这个密钥， 将加密后的密钥返回给服务器， 此时该密钥只有服务器端的私钥能够解密，从而完成了通信密钥的加密传输。  公钥一般放在证书中。&lt;/p&gt;

&lt;p&gt;在实际应用中， 通常是在TLS握手阶段由客户端和服务端共同生成并交换两个明文的随机数， 再由客户端生成一个密文随机数并使用公钥加密传递给服务端， 最后双方使用相同的摘要算法对三个数计算出真正的通信密钥。&lt;/p&gt;

&lt;h3 id=&#34;2-具有校验机制-第三方无法篡改-或已经篡改立刻发现&#34;&gt;2. 具有校验机制， 第三方无法篡改， 或已经篡改立刻发现。&lt;/h3&gt;

&lt;p&gt;一般来说， 通过在发送数据时附带摘要， 即可令接收方辨别数据被篡改。&lt;/p&gt;

&lt;p&gt;但是摘要本身也是可以被篡改的， 因此摘要本身也需要被加密， 可以将摘要附在数据的后面一起被加密， 接收端解密之后再次将数据计算摘要并与发送端附带的摘要进行比对， 即可知道数据是否被篡改过。&lt;/p&gt;

&lt;h3 id=&#34;3-身份验证-第三方无法冒充&#34;&gt;3. 身份验证， 第三方无法冒充。&lt;/h3&gt;

&lt;p&gt;身份验证使用的就是证书机制， 而颁发证书的机构就是CA机构。&lt;br /&gt;
证书的工作机制比较复杂， 基本思想是引入一个权威的第三方为通信双方的身份做担保。（这个第三方不是指窃听数据的第三方。）&lt;br /&gt;
如果客户端需要保证服务器没有被冒充， 那么服务器需要向客户端提供证书以供其验证， 这种模式叫做单向验证； 如果通信双方都需要保证对方没有被冒充， 则需要互换证书各自验证， 称为双向验证。&lt;br /&gt;
证书中有几个基本信息:&lt;br /&gt;
- 颁发者。 也就是上一级CA
- 受发者。 也就是申请证书的人， 通常是一个域名或通配符域名。
- 有效期。
- 公钥。 公钥是服务端密钥对的其中之一， 客户端收到证书并验证成功后， 用此公钥加密&lt;code&gt;第三个随机数&lt;/code&gt;以交换通信密钥。
- 摘要算法。 用于指示证书签名使用的摘要算法。&lt;/p&gt;

&lt;h4 id=&#34;申请证书&#34;&gt;申请证书&lt;/h4&gt;

&lt;p&gt;假设有一个权威的认证机构CA， 服务端想要让客户端认证自己的身份， 需要将自己的证书名和公钥提交给CA供其审核。 CA自身带有一对公钥和私钥， 审核通过后， 会使用自身的私钥加密服务端提交证书的摘要（称为&lt;code&gt;签名&lt;/code&gt;）， 将签过名的证书发还给服务端。&lt;/p&gt;

&lt;h4 id=&#34;交换-验证证书&#34;&gt;交换、验证证书&lt;/h4&gt;

&lt;p&gt;既然CA是权威的， 那么客户端可以信任该CA， 并保存CA的公钥(例如， 浏览器会内置很多可信的CA机构的证书)。 在TLS握手阶段， 服务端会将证书发送给客户端， 客户端拿到证书检查颁发人， 找出本地保存的对应CA的公钥， 使用该公钥对证书的签名进行解密， 比对证书的明文内容和签名解密出的摘要是否一致。 如果一致则认为验证通过。 如果是双向认证， 则客户端也会将自身证书发向服务端， 服务端执行同样的验证。&lt;/p&gt;

&lt;h4 id=&#34;证书链&#34;&gt;证书链&lt;/h4&gt;

&lt;p&gt;世界公认权威的CA（根证书的拥有者）是有限的， 而需要验证的客户端是无限的， 如果要一一审核太慢了。 因此基于“我信任你， 你信任他， 因此我信任他”的信任传递原则， 有了证书链机制。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://violinsonata.site/image/posts/证书链.png&#34; alt=&#34;浏览器中的证书链&#34; /&gt;
&lt;center style=&#34;font-size:14px;color:#C0C0C0;text-decoration:underline&#34;&gt;本站的证书链&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;假设客户端添加了权威CA的根证书， 权威CA签发了二级CA， 二级CA签发了三级网站。 客户端与服务端网站通信时， 如果服务端只发送自身的网站证书， 则客户端只能找到颁发者二级CA， 而由于其没有信任二级CA（没有保存二级CA的公钥）， 从而无法完成验证。 因此客户端需要发送自身的证书， 以及签发者二级CA的证书。 客户端先验证网站证书是否由二级CA签发， 再验证二级CA的签发人， 直到发现某一级证书的签发人是自己信任的， 从而完成了证书验证。 如果走完证书链也没有发现可信任的签发人， 则认为该证书是不可信的&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;防伪造： 未经过CA验证的不法网站可以使用假的证书， 但由于客户端没有信任假证书的CA， 因此无法通过验证。&lt;/li&gt;
&lt;li&gt;防篡改： 签名比对机制杜绝了证书交换过程中被第三方篡改。&lt;/li&gt;
&lt;li&gt;防冒充： 钓鱼网站可以使用服务端公开的证书冒名顶替， 但是因为没有私钥， 因此无法解密客户端发送的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ssl-tls-基本的运行过程&#34;&gt;SSL/TLS 基本的运行过程&lt;/h2&gt;

&lt;p&gt;在建立链接阶段总体的流程如下：&lt;br /&gt;
1. 客户端向服务器索要并验证公钥
2. 双方协商生成“对话密钥”
3. 双方采用“对话密钥”进行加密通信&lt;/p&gt;

&lt;p&gt;TLS 报文的格式
TLS报文自身分为两层: &lt;code&gt;Record层&lt;/code&gt;和&lt;code&gt;负载层&lt;/code&gt;. Record层的结构比较简单, 就是TVL格式:
- Content Type: 用于声明负载层的类型. 对于握手报文, 就是&lt;code&gt;Handshake(22)&lt;/code&gt;, 对于数据报文, 就是&lt;code&gt;Application Data(23)&lt;/code&gt;, 对于加密变更声明, 就是&lt;code&gt;Change Cipher Spec(20)&lt;/code&gt;, 对于报警, 就是&lt;code&gt;Alert(21)&lt;/code&gt;.
- Version: 协议的版本, 现在比较常用的就是 &lt;code&gt;TLS 1.0&lt;/code&gt;, &lt;code&gt;TLS 1.1&lt;/code&gt;, &lt;code&gt;TLS 1.2&lt;/code&gt;, &lt;code&gt;TLS 1.3&lt;/code&gt;.
- Length: 负载层的长度, 字节为单位.&lt;/p&gt;

&lt;p&gt;对于一个典型的TLS握手过程, 双方总共会按顺序通信如下请求:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Client Hello&lt;/li&gt;
&lt;li&gt;Server Hello&lt;/li&gt;
&lt;li&gt;Server Certificate&lt;/li&gt;
&lt;li&gt;Server Key Exchange&lt;/li&gt;
&lt;li&gt;Certificate Request&lt;/li&gt;
&lt;li&gt;Server Hello Done&lt;/li&gt;
&lt;li&gt;Client Certificate&lt;/li&gt;
&lt;li&gt;Client Key Exchange&lt;/li&gt;
&lt;li&gt;Change Cipher Spec&lt;/li&gt;
&lt;li&gt;Encrypted Handshake Message&lt;/li&gt;
&lt;li&gt;Change Cipher Spec&lt;/li&gt;
&lt;li&gt;Encrypted Handshake Message&lt;/li&gt;
&lt;li&gt;Application Data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在没有回话复用, 单TCP包仅承载单个TLS请求的情况下, 双方的通信过程是这样的:&lt;/p&gt;

&lt;div class=&#34;mermaid&#34; align=&#34; 
                                center
                            &#34;&gt; 
    

sequenceDiagram
  participant client
  participant server

  client -&gt;&gt; + server: Client Hello
  server --&gt;&gt; - client: TCP Ack
  server -&gt;&gt; + client: Server Hello
  client --&gt;&gt; - server: TCP Ack
  server -&gt;&gt; + client: Server Certificate
  client --&gt;&gt; - server: TCP Ack
  opt RSA/DN/ECHD/ 等算法不会发送
    server -&gt;&gt; + client: Server Key Exchange
    client --&gt;&gt; - server: Tcp Ack
  end
  client -&gt;&gt; client: 验证服务端的证书/证书链
  alt 双向认证
    server -&gt;&gt; + client: Certificate Request
    client --&gt;&gt; - server: Tcp Ack
    server -&gt;&gt; + client: Server Hello Done
    client --&gt;&gt; - server: Tcp Ack
    client -&gt;&gt; + server: Client Certificate
    server --&gt;&gt; - client: TCP Ack
    server -&gt;&gt; server: 验证客户端的证书/证书链
  else 单向认证
    server -&gt;&gt; + client: Server Hello Done
    client --&gt;&gt; - server: Tcp Ack
  end
  client -&gt;&gt; + server: Client Key Exchange
  server --&gt;&gt; - client: TCP Ack
  client -&gt;&gt; + server: Change Cipher Message
  server --&gt;&gt; - client: TCP Ack
  client -&gt;&gt; + server: Encrypted Handshake Message
  server --&gt;&gt; - client: TCP Ack
  server -&gt;&gt; + client: Change Cipher Message
  client --&gt;&gt; - server: TCP Ack
  server -&gt;&gt; + client: Encrypted Handshake Message
  client --&gt;&gt; - server: TCP Ack

  loop 开始传输数据
    server -&gt;&gt; + client: Application Data
    client --&gt;&gt; - server: TCP Ack
  end


&lt;/div&gt;


&lt;script async src=&#34;https://unpkg.com/mermaid@8.2.3/dist/mermaid.min.js&#34;&gt;&lt;/script&gt;



&lt;p&gt;实际上, TLS握手的时候, 客户端与服务端双方会根据情况将多个TLS报文压缩到一个TCP数据包中, 因此在使用Wireshark抓包时经常看到一个数据包中有多个TLS报文.&lt;/p&gt;

&lt;h3 id=&#34;client-hello&#34;&gt;Client Hello&lt;/h3&gt;

&lt;p&gt;客户端向服务端发送加密通信的请求，称作 &lt;code&gt;ClientHello请求&lt;/code&gt; 。该请求使用明文传输。&lt;br /&gt;
ClientHello请求将向服务端提供以下信息：&lt;br /&gt;
- Version:&lt;br /&gt;
  客户端支持的最高加密协议版本
- Random:&lt;br /&gt;
  客户端生成的随机数random_C， 用作&lt;code&gt;对话密钥&lt;/code&gt;.
- Session Id &amp;amp; Session Length:
  会话ID. 会话ID由服务端生成, 并在Server Hello中告知客户端. 如果是第一次建立链接, 会话ID为0; 如果是短时间内再次建立连接, 会使用上次的会话ID.
- Cipher Suites &amp;amp; Cipher Suites Length:&lt;br /&gt;
  客户端支持的加密套件列表, 服务端会从中选出一个用于之后协商过程使用的套件.
- Compression Methods &amp;amp; Compression Methods Length:&lt;br /&gt;
  客户端支持的压缩方法. 目前没有用上, 一般留作空.&lt;br /&gt;
- Extention &amp;amp; Extentions Length:&lt;br /&gt;
  扩展字段. 包括会话复用在内的很多TLS的高级功能通过扩展字段来实现.  Extentions Length 是倒数第二个字段, 标识了扩展字段列表的长度(字节). 然后就是连续若干项Extention字段的列表.&lt;/p&gt;

&lt;p&gt;客户端发送的信息之中不包括服务器的域名。 也就是说， 理论上服务器只能包含一个网站， 否则会分不清应该向客户端提供哪一个网站的数字证书。 这就是为什么通常一台服务器只能有一张数字证书的原因。&lt;/p&gt;

&lt;h3 id=&#34;server-hello&#34;&gt;Server Hello&lt;/h3&gt;

&lt;p&gt;服务端使用明文向客户端发送请求，内容包括:&lt;br /&gt;
- Version:&lt;br /&gt;
  服务端选择的双方协商使用的加密协议版本. 一般会选择客户端服务端都支持的最高的版本.
- Random:&lt;br /&gt;
  服务端生成的随机数 random_S, 用于生成&lt;code&gt;对话密钥&lt;/code&gt;.
- Session ID &amp;amp; Session ID Length:&lt;br /&gt;
  服务端生成的会话ID, 或上一次链接时使用的会话ID.&lt;br /&gt;
- Cipher Suite:&lt;br /&gt;
  服务端从客户端提供的加密套件列表中选择一个, 告知客户端.&lt;br /&gt;
- Compression Method:&lt;br /&gt;
  服务端从客户端提供的压缩算法中选择一个告知客户端. 不过现在客户端一般留空, 服务端没得选, 也只能返回空.&lt;br /&gt;
- Extention &amp;amp; Extention Length:&lt;br /&gt;
  具体作用未知.&lt;/p&gt;

&lt;h3 id=&#34;server-certificate&#34;&gt;Server Certificate&lt;/h3&gt;

&lt;p&gt;服务端向客户端发送自身的证书, 明文传输.
- Certificate Length:&lt;br /&gt;
  证书长度(字节).
- Certificates:&lt;br /&gt;
  证书链.&lt;/p&gt;

&lt;h3 id=&#34;server-hello-done&#34;&gt;Server Hello Done&lt;/h3&gt;

&lt;p&gt;没有信息, 负载为空&lt;/p&gt;

&lt;h3 id=&#34;client-key-exchange&#34;&gt;Client Key Exchange&lt;/h3&gt;

&lt;p&gt;客户端收到证书后会验证证书。 如果证书不是可信机构颁布、 或者证书中的域名与实际域名不一致、 或者证书已经过期， 就会向访问者显示一个警告， 由其选择是否还要继续通信。
如果证书没有问题， 客户端就会从证书中取出服务器的公钥。 然后， 向服务器发送Client Key Exchange. 这个请求使用单独的类型, Content-Type是&lt;code&gt;Client Key Exchange(16)&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PubKey:&lt;br /&gt;
随机数 Pre-Master. 这个数字是使用服务端的公钥加密过的. 是协商密钥过程中唯一真正加密通信的数据.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;客户端会根据通信过程中双方生成的三个随机数， 使用约定的加密方法生成真正的会话密钥。
服务端收到报文后, 通过之前通信过程中生成的三个随机数 random_C, random_S, Pre-Master, 生成真正的会话密钥。&lt;/p&gt;

&lt;h3 id=&#34;encrypted-handshake-message-change-cipher-spec&#34;&gt;Encrypted Handshake Message &amp;amp; Change Cipher Spec&lt;/h3&gt;

&lt;p&gt;服务端和客户端在各自计算出真正的会话密钥后, 会向对方发送一个 Change Cipher Spec 报文, 该报文没有负载信息, 只是告知对方自己接下来要发送的报文都将使用密钥加密.&lt;br /&gt;
然后再向对方发送一个 Encrypted Handshake Message, 里面的负载是之前双方协商过的信息的哈希值, 但此次使用密钥加密负载. 双方收到对方发来的加密报文后, 解密并比对自身数据作为最后验证. 如果比对不一致则报错停止此次握手, 如果一致则TLS链接成功建立.&lt;/p&gt;

&lt;h3 id=&#34;application-data&#34;&gt;Application Data&lt;/h3&gt;

&lt;p&gt;TLS链接建立后双方通信的TLS报文都是Application Data.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;参考 &lt;a href=&#34;https://blog.csdn.net/mrpre/article/details/77867063&#34;&gt;https://blog.csdn.net/mrpre/article/details/77867063&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>使用Golang创建守护进程</title>
      <link>https://violinsonata.site/2020/create-daemon-process-in-golang/</link>
      <pubDate>Thu, 13 Aug 2020 15:07:00 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/create-daemon-process-in-golang/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package main
 
import (
    &amp;quot;os&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;os/signal&amp;quot;
    &amp;quot;syscall&amp;quot;
    &amp;quot;time&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;os/exec&amp;quot;
)
func init() {
    // 如果本进程的父进程不是init进程, 则
    // 创建与本进程相同的子进程, 然后退出, 使
    // 子进程被init进程接管, 从而创建了守护进程. 
    if os.Getppid() != 1{
        cmd := exec.Command(os.Args[0], os.Args[1:]...)
        cmd.Start()
        os.Exit(0)
    }
 
    // 监听系统信号
    go func() {
        _c := make(chan os.Signal, 1)
        signal.Notify(_c, 
            os.Interrupt, 
            syscall.SIGHUP, 
            syscall.SIGINT, 
            syscall.SIGTERM, 
            syscall.SIGQUIT, 
            syscall.SIGKILL, 
            syscall.SIGTSTP
        )
        msg := &amp;lt;- _c
        log.Println(msg)
        os.Exit(0)
    }()
}
 
func main()  {
 
    go func(){
        fp, _ := os.OpenFile(&amp;quot;log&amp;quot;, os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0644)
        log.SetOutput(fp)
        for{
            log.Println(fmt.Sprint(&amp;quot;hello &amp;quot;, os.Getpid()))
            time.Sleep(time.Second * 5)
        }
    }()
    
    for{
        time.Sleep(time.Second * 1000)
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>网络安全基本概念</title>
      <link>https://violinsonata.site/2020/basic-concepts-of-network-security/</link>
      <pubDate>Wed, 12 Aug 2020 16:30:09 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/basic-concepts-of-network-security/</guid>
      <description>

&lt;h2 id=&#34;对称加密&#34;&gt;对称加密&lt;/h2&gt;

&lt;p&gt;对称加密很简单， 就是消息传递的双方共享同一个密码。 消息发送人用密码对消息进行加密， 然后将密文发给给消息接收人， 消息接受人使用此密码对密文进行解密， 然后阅读。&lt;br /&gt;
优点： 计算量小， 加密效率高。&lt;br /&gt;
缺点： 密码安全系数并不是特别高 （知道密码的人比较多）。&lt;/p&gt;

&lt;h2 id=&#34;非对称加密&#34;&gt;非对称加密&lt;/h2&gt;

&lt;p&gt;非对称加密是指消息传递双发使用不同的密码， 两个密码分别被称为私钥和公钥。 私钥和公钥之间具备一定的数学关系： 私钥加密的内容只有对应的公钥才能解密， 公钥加密的内容只有对应的私钥才能解密。&lt;br /&gt;
需要使用此加密方式的人会具备私钥和公钥， 私钥只有自己知道， 公钥则对特定群体或者所有人公开。&lt;br /&gt;
优点： 安全， 私钥只有自己一个人知道， 不用担心被窃听。&lt;br /&gt;
缺点： 计算量较大， 效率低， 不适合对大量内容进行加密。&lt;/p&gt;

&lt;h2 id=&#34;消息摘要-简称摘要&#34;&gt;消息摘要(简称摘要)&lt;/h2&gt;

&lt;p&gt;使用单向哈希算法， 以任意长度的报文计算得到的固定长度的哈希值。 所谓单向是指改算法是不可逆的， 根据消息摘要无法计算出输入报文。&lt;br /&gt;
消息摘要的另一个特点是： 对输入报文的任何改动， 都会导致最终的计算结果 （也就是消息摘要本身） 发生巨大的变化。 因此，消息摘要可以认为是数字信息的指纹。&lt;br /&gt;
&amp;gt; 常见的消息摘要算法有SHA， MD5等。&lt;/p&gt;

&lt;h2 id=&#34;数字签名-简称签名&#34;&gt;数字签名(简称签名)&lt;/h2&gt;

&lt;p&gt;数字签名与在纸上的物理签名效果类似——保证消息的真实性与不可伪造。 签名过程通常是消息的发送方首先生成消息报文的消息摘要， 然后使用自己的私钥对消息摘要进行加密， 加密之后的消息摘要就是消息报文的签名， 将和消息报文一起发送给消息接收方。&lt;br /&gt;
如果消息接受方需要验证真伪， 首先使用消息发送方的公钥对数字签名进行解密从而得到报文消息摘要 （如果解密失败，则签名肯定有问题）。 然后使用相同的消息摘要算法重新计算接受到的消息报文的消息摘要， 如果计算得到的消息摘要与解密得到的消息摘要不一致， 则消息报文被人篡改。&lt;/p&gt;

&lt;h2 id=&#34;数字证书-简称证书&#34;&gt;数字证书(简称证书)&lt;/h2&gt;

&lt;p&gt;数字证书类似网上身份证， 由第三方权威机构签发， 用于鉴别证书持有人的身份的真实性。 数字证书上包含了证书持有人的基本信息 （如：网站域名、 邮箱地址等）、 证书持有人的公钥、 证书颁发机构信息、 证书颁发机构的数字签名以及证书有效期。&lt;br /&gt;
数字证书的申请过程通常是： 证书申请人向证书签发机构提交申请， 申请中包含申请人身份的基本信息以及申请人公钥。 证书签发机构通过各种手段核实申请来源以及申请信息的真实性。 核实通过之后， 真实签发机构向申请人签发数字证书。&lt;br /&gt;
证书签发机构也有一个证书， 其中包含了证书签发机构的公钥。 任何人都可以获得该证书， 并使用此证书来验证该机构签发的所有证书的真伪。 默认情况下， 大多数操作系统内已经内置了全球知名证书签发单位的根证书。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker容器中访问宿主机网络</title>
      <link>https://violinsonata.site/2020/access-host-network-in-docker/</link>
      <pubDate>Wed, 08 Apr 2020 14:41:12 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/access-host-network-in-docker/</guid>
      <description>

&lt;h2 id=&#34;docker容器监听宿主机端口&#34;&gt;Docker容器监听宿主机端口&lt;/h2&gt;

&lt;h3 id=&#34;使用端口映射&#34;&gt;使用端口映射&lt;/h3&gt;

&lt;p&gt;现在假设有一个Docker容器nginx， 它运行时将监听docker内的80端口， 此时宿主机的80端口并没有被占用， 也无法将请求传入容器中。&lt;br /&gt;
如果需要容器监听宿主机的80端口， 那么需要在启动容器时进行端口映射。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 由于映射了宿主机的80和443端口， 低于1024， 因此需要使用root用户启动docker. 
docker run -d \
    --name nginx \
    -p 80:80 -p 443:443 \
    nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-p&lt;/code&gt;选项接收&lt;code&gt;{宿主机端口}:{容器端口}&lt;/code&gt;格式的参数， 可以多次指定以指定多个端口映射。&lt;/p&gt;

&lt;h3 id=&#34;使用host网络模式&#34;&gt;使用host网络模式&lt;/h3&gt;

&lt;p&gt;Docker容器启动时有&lt;code&gt;host&lt;/code&gt;, &lt;code&gt;bridge&lt;/code&gt;, &lt;code&gt;none&lt;/code&gt; 三种网络模式， 默认是使用&lt;code&gt;bridge&lt;/code&gt;桥接模式， 这种模式下可以使用端口映射的方式监听宿主机端口。
不过也可以使用&lt;code&gt;--network&lt;/code&gt;选项指定&lt;code&gt;host&lt;/code&gt;模式， 这种模式下容器与宿主机共享网络， 因此可以直接监听与请求宿主机上的网络端口。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 使用host模式可以直接监听宿主机网络端口，不必使用-p进行端口映射。 
docker run -d \
    --network host \
    --name nginx-docker \
    nginx:latest

# 也可以直接访问宿主机端口。  
docker run --rm \
    --network host \
    --name curl-docker \
    alpine curl localhost:80 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker容器访问宿主机端口&#34;&gt;Docker容器访问宿主机端口&lt;/h2&gt;

&lt;p&gt;从Docker容器中访问宿主机的端口有两种方式&lt;/p&gt;

&lt;h3 id=&#34;指定宿主机ip-linux&#34;&gt;指定宿主机IP (Linux)&lt;/h3&gt;

&lt;p&gt;在安装Docker的时候，会在宿主机安装一个虚拟网卡docker0, docker0对应的地址就是容器访问宿主机的地址。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ ip addr show docker0
4: docker0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:73:74:56:03 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:73ff:fe74:5603/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到docker0对应的地址为 &lt;code&gt;172.17.0.1&lt;/code&gt;, 那么启动docker时可以这样:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm \
    --name curl-docker \
    alpine curl 172.17.0.1:80
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;指定宿主机ip-mac&#34;&gt;指定宿主机IP (mac)&lt;/h3&gt;

&lt;p&gt;macOS的情况与Linux系统不同， Docker原生不支持macOS， mac上安装的Docker程序实质上是一个带着Docker的Linux虚拟机,  因此macOS上不会有 docker0 网卡。&lt;br /&gt;
不过这种情况也有专门的解决方案， 那就是使用特殊的地址 &lt;code&gt;docker.for.mac.localhost&lt;/code&gt; 代替。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm \
    --name curl-docker \
    alpine curl docker.for.mac.localhost:80
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>MySQL常用操作</title>
      <link>https://violinsonata.site/2020/useful-operates-in-mysql/</link>
      <pubDate>Wed, 19 Feb 2020 15:14:38 +0800</pubDate>
      
      <guid>https://violinsonata.site/2020/useful-operates-in-mysql/</guid>
      <description>

&lt;h2 id=&#34;数据库概念关系&#34;&gt;数据库概念关系&lt;/h2&gt;

&lt;p&gt;服务器 -&amp;gt; 实例 -&amp;gt; 数据库 -&amp;gt; 表 -&amp;gt; 记录&lt;/p&gt;

&lt;h2 id=&#34;登录数据库实例&#34;&gt;登录数据库实例&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysql  \
    -u{用户名}  \   #如果不指定-u， 则使用 root 用户。
    -p{密码} \      #如果指定-p而不输入密码， 则会在交互式界面中询问密码。 这样可以避免密码泄漏。 
    -h{主机地址} \
    -P{服务端口}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;常用信息查看&#34;&gt;常用信息查看&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select user();      -- 当前用户
select database();  -- 当前数据库
select version();   -- 当前版本
select now();       -- 当前时间
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;数据库管理&#34;&gt;数据库管理&lt;/h2&gt;

&lt;h3 id=&#34;创建数据库&#34;&gt;创建数据库&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create database {数据库名}
    character set {字符集}      -- 可选参数
    collate {检查名}            -- 可选参数
    default encryption {Y/N};   -- 可选参数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;charactor set&lt;/code&gt; 用于指定数据库级别的字符集。 从MySQL8.0开始， 默认字符集是&lt;code&gt;utf8mb4&lt;/code&gt;, 这是一种支持 emoji 表情的utf8字符集。 🎉&lt;br /&gt;
&lt;code&gt;collate&lt;/code&gt; 用于指定数据库级别的字符型数据排序规则。 从8.0之后， 排序规则默认为&lt;code&gt;utf8mb4_0900_ai_ci&lt;/code&gt;。 一般不用改。&lt;br /&gt;
&lt;code&gt;encryption&lt;/code&gt; 用于指定数据库的加密算法。 默认为不使用加密。&lt;/p&gt;

&lt;h3 id=&#34;查看-删除数据库&#34;&gt;查看/删除数据库&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show databases;              -- 查看所有数据库
drop database {数据库名};   -- 删除指定名称的数据库
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导出数据&#34;&gt;导出数据&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;：如果在命令行指定了-p， 则导出的sql文件第一行会有个warnning：&lt;br /&gt;
&amp;gt; mysqldump: [Warning] Using a password on the command line interface can be insecure.&lt;/p&gt;

&lt;p&gt;这行warining不是注释，因此在其他数据库导入时会报语法错误。 解决办法有两个:&lt;br /&gt;
1. 在导出命令中不指定&lt;code&gt;-p&lt;/code&gt;参数， 使用交互方式输入密码。【推荐】
2. 在导出的sql文件中将这一行删除或注释掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysqldump -u{用户名} -p{密码} \
  -h{主机地址} -P{端口} \
  {数据库名}            #如果要导出所有数据库， 则库名表名都不用指定。 \
  {数据表名}            #如果要导出单个数据库所有表，则表名不用指定。 \
   &amp;gt; backup.sql         #重定向到备份文件中。 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导入数据&#34;&gt;导入数据&lt;/h3&gt;

&lt;p&gt;首先登陆数据库， 创建数据库与用户， 并为用户分配权限。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mysql -u{用户名} -p{密码} -h{主机地址} -P{端口} {数据库名} &amp;lt; backup.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导出数据-docker内&#34;&gt;导出数据（docker内）&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker exec -it mysql-instance mysqldump -u{user} -p{password} &amp;gt; backup.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;导入数据-docker内&#34;&gt;导入数据（docker内）&lt;/h3&gt;

&lt;p&gt;首先将文件拷贝到docker内， 然后在容器内的命令行执行导入命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker cp ./backup.sql mysql-instance:/tmp/backup.sql
docker exec mysql-instance &#39;mysql -u{user} -p{password} source /tmp/backup.sql&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用户管理&#34;&gt;用户管理&lt;/h2&gt;

&lt;h3 id=&#34;查看系统内所有用户及登录地址&#34;&gt;查看系统内所有用户及登录地址&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select distinct 
    concat(&#39;user: &#39;&#39;&#39;,user,&#39;&#39;&#39;@&#39;&#39;&#39;,host,&#39;&#39;&#39;;&#39;) as query 
    from mysql.user;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查看某个用户的所有权限&#34;&gt;查看某个用户的所有权限&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select * from mysql.user where user={用户名};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;mysql.user&lt;/code&gt;中， user和host两个字段共同构成主键。&lt;/p&gt;

&lt;h3 id=&#34;创建用户与授权&#34;&gt;创建用户与授权&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 创建与授权分两步
create user &#39;{用户名}&#39;@&#39;{主机域}&#39; identified by &#39;{密码}&#39;;
grant {权限列表} on {数据库名}.{数据表名} to &#39;{用户名}&#39;@&#39;{主机域}&#39;;
-- 分配所有权限
grant all on *.* to &#39;admin&#39;@&#39;localhost&#39;;
-- 查看用户的权限
show grants for &#39;{用户名}&#39;@&#39;{主机域}&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建用户时需要同时指定用户名和主机域， 因为它们共同构成&lt;code&gt;mysql.user&lt;/code&gt;的主键。 如果不限制该用户可以在哪台主机访问， 则主机域可以设定为&lt;code&gt;%&lt;/code&gt;， 代表任意主机。 如果不指定主机域， 同样使用&lt;code&gt;%&lt;/code&gt;作为默认值。&lt;/p&gt;

&lt;h2 id=&#34;数据表管理&#34;&gt;数据表管理&lt;/h2&gt;

&lt;h3 id=&#34;建表&#34;&gt;建表&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table 表名(
    -- not null, default, auto_increment, comment 都是可选参数
    id int not null  auto_increment comment &#39;主键&#39;,   
    name varchar(10) not null default &#39;&#39; comment &#39;名字&#39;,
    primary key(`id`),
    unique key `k索引名` (`name`) -- 最后一行不能以逗号结尾
)charset=utf8mb4;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;修改表&#34;&gt;修改表&lt;/h3&gt;

&lt;h4 id=&#34;新加字段&#34;&gt;新加字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- 后一个列名用于指定新列的位置
alter table 表名 add column 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null after 列名;
-- 将新字段设置为第一列
alter table 表名 add column 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null first;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;删除字段&#34;&gt;删除字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 drop 字段名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;更新字段&#34;&gt;更新字段&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 change 字段名 enum(&#39;M&#39;,&#39;F&#39;) not null ;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;修改字段数据类型&#34;&gt;修改字段数据类型&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 modify 字段名 enum(&#39;M&#39;,&#39;F&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改字段数据类型之后， 其他的配置如 not null 等不会变。&lt;/p&gt;

&lt;h4 id=&#34;添加-删除字段默认值&#34;&gt;添加/删除字段默认值&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 alter 字段名 set default 默认值;
alter table 表名 alter 字段名 drop default;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;重命名表名&#34;&gt;重命名表名&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 rename to 新表名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;索引管理&#34;&gt;索引管理&lt;/h2&gt;

&lt;p&gt;除了可以在创建数据表等时候指定索引之外， 还可以单独对索引进行管理。&lt;/p&gt;

&lt;h3 id=&#34;查看索引&#34;&gt;查看索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show table from 表名;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;创建索引&#34;&gt;创建索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create index 索引名 on 表名(字段名);
-- 创建唯一索引
create unique index 索引名 on 表名(字段名);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;删除索引&#34;&gt;删除索引&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop index 索引名 on 表名;
alter table  表名 drop index 索引名;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes中的容器配置管理：ConfigMap</title>
      <link>https://violinsonata.site/2019/configmap/</link>
      <pubDate>Mon, 16 Sep 2019 10:51:55 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/configmap/</guid>
      <description>

&lt;h2 id=&#34;什么是configmap&#34;&gt;什么是ConfigMap&lt;/h2&gt;

&lt;p&gt;ConfigMap ，即配置字典， 是Kubernetes提供的用于管理容器中程序运行所需配置的解决方案。 它是一种持久化的机制， 不会随着容器的创建销毁而变化。 容器启动时从ConfigMap中读取配置， 并且多个容器可以共享同一个ConfigMap。&lt;/p&gt;

&lt;h2 id=&#34;软件配置常见的几种形式&#34;&gt;软件配置常见的几种形式:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;环境变量&lt;br /&gt;
比如许多运行在Java虚拟机上的程序在启动时会读取&lt;code&gt;JAVA_HOME&lt;/code&gt;环境变量， 配置不同的环境变量值， 也就使用了不同的Java虚拟机。&lt;br /&gt;
再比如许多项目会使用环境变量来区分当前环境是&lt;code&gt;product&lt;/code&gt;,&lt;code&gt;develop&lt;/code&gt;,&lt;code&gt;test&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置文件&lt;br /&gt;
配置文件是最普及，最常用的一类配置形式。 无论是服务端程序还是客户端程序， 都会使用这种形式。&lt;br /&gt;
常见的配置文件格式有 &lt;code&gt;*.ini&lt;/code&gt;, &lt;code&gt;*.json&lt;/code&gt;, &lt;code&gt;*.xml&lt;/code&gt;, &lt;code&gt;*.conf&lt;/code&gt;, &lt;code&gt;*.yaml&lt;/code&gt;, &lt;code&gt;*.toml&lt;/code&gt;等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;命令行参数&lt;br /&gt;
这种形式用于命令行启动的程序， 并且常常会和配置文件，环境变量等形式搭配使用。 其优点在于灵活， 可以方便地对每次程序运行时指定不同的配置项， 因此很适合执行时间较短的程序， 例如压缩解压， 缺点在于总是会让整条命令变得又长又臭。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;远程配置中心&lt;br /&gt;
随着微服务架构的盛行， 配置不再需要存储在本地了， 程序启动之后会到远程的服务去读取配置， 用户启动时只需要“告诉”程序去哪里读取配置。  这种配置方式极大地简化了本地部署的步骤， 适用于在多台服务器上大量部署的程序， 是未来的发展趋势。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;插件&lt;br /&gt;
严格来说， 插件并不能算是一种配置形式。 因为它不像其他几种形式， 必须在程序刚刚启动时读取， 也不像其他几种形式， 通过用户编辑其内容来改变程序的行为。 插件更多的是在程序运行时根据需要或配置进行加载， 用以扩充程序的功能。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;创建配置字典的几种形式&#34;&gt;创建配置字典的几种形式&lt;/h2&gt;

&lt;p&gt;配置字典是一个键值对形式Map。 键是由用户随意指定的， 而值才是Pod中的进程期望读取的配置。 很多应用的配置格式本身就是键值对形式的， 比如Java提供的&lt;code&gt;*.properties&lt;/code&gt;文件就是键值对的列表。 在使用配置文件时应该将这个文件的内容整个作为配置字典中的&lt;code&gt;值&lt;/code&gt;, 而不是每个配置文件中的键值对对应一个配置字典中的键值对。&lt;/p&gt;

&lt;h3 id=&#34;在命令行直接通过键值对创建&#34;&gt;在命令行直接通过键值对创建&lt;/h3&gt;

&lt;p&gt;可以直接在命令行中指定键值对， 每个键值对都是一项配置。 就像这样:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Config 
      --from-literal=key1=value1 
      --from-literal=loglevel=&#39;INFO, stdout&#39; 
      --from-literal=java_home_env=/usr/lib/jre_1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过单个配置文件创建&#34;&gt;通过单个配置文件创建&lt;/h3&gt;

&lt;p&gt;也可以将一个本地的配置文件上传形成一个配置字典。 指定文件可以使用绝对路径， 也可以使用相对路径。&lt;br /&gt;
  &lt;code&gt;--from-file&lt;/code&gt;参数的key是可选的， 如果不指定的话， 默认使用文件名作为key。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-File-Config 
    --from-file=/home/app/config.properties 
    --from-file=config=/home/app/config.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过目录创建&#34;&gt;通过目录创建&lt;/h3&gt;

&lt;p&gt;很多应用都会同时使用多个配置文件， 而这些配置文件常常在同一个目录下。 因此当然也可以把一整个目录都创建成配置字典。&lt;br /&gt;
  &amp;gt; 从目录创建配置字典实际上是针对目录内的每个文件， 创建以文件名为key的配置项。 因此这种用法有两个注意点：&lt;br /&gt;
  &amp;gt; 1. 可以在一个配置字典中指定多个目录， 但是要保证所有这些目录中不能存在重名的文件。&lt;br /&gt;
  &amp;gt; 2. 不能指定key, 此时key只能是文件名。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Dir-Config 
    --from-file=/home/app 
    --from-file=config=/home/anothor
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;通过二进制文件创建&#34;&gt;通过二进制文件创建&lt;/h3&gt;

&lt;p&gt;二进制文件同样也可以用来创建配置字典。 不过并不是直接存储在配置字典中， 而是先对文件进行base64编码， 再把编码后的字符串存储在配置字典中。&lt;br /&gt;
  这是一种非常规用法， 一般不推荐。 如果文件太大的话， 会对k8s集群内的etcd造成压力。 另外上传时还可能会因为超时而中断请求。 仅适用于个别奇葩应用使用非文本形式的配置文件，或者一些程序会使用&lt;code&gt;.so&lt;/code&gt;或&lt;code&gt;.dill&lt;/code&gt;文件作为插件时使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl create configmap My-Binary-Config 
    --from-file=/home/app/config.tar 
    --from-file=/home/app/plugin.so
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用命令行创建配置字典的缺陷&#34;&gt;使用命令行创建配置字典的缺陷&lt;/h3&gt;

&lt;p&gt;使用命令行直接创建配置字典的优点是方便直接。 但是缺点也有：
  - 除非使用 &amp;ndash;namespace 指定， 或者.kube/config文件中指定了命名空间， 否则该配置字典会在default命名空间内。&lt;br /&gt;
  - 能够指定配置字典的名称， 但是不能指定配置字典的Label(当然可以在创建之后再用 kubectl lable命令添加)。&lt;br /&gt;
  - 对于大量的配置， 使用命令行显然不方便。 好在&amp;ndash;from-file选项弥补了这一点。&lt;br /&gt;
  - 这是前面说到的&amp;rdquo;又长又臭的命令&amp;rdquo;的完美诠释。&lt;/p&gt;

&lt;p&gt;如果想要添加配置字典的Label， 需要两条命令。 首先创建一个配置字典， 然后使用&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;  kubectl lable configmap My-ConfigMap key=value key2=value2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用yaml文件创建配置字典&#34;&gt;使用yaml文件创建配置字典&lt;/h3&gt;

&lt;p&gt;其实就是把想要配置的内容一股脑写到&lt;code&gt;data&lt;/code&gt;字段下面就好啦。 示例：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion:  v1
kind: ConfigMap
metadata:
  labels:
    app: flume
  namespace: flume-namespace
  name: flume-config
data:
  flume.properties: |
    agent.sources = a1
    agent.channels = a1
    agent.sinks = a1
  log4j.properties: |
    flume.root.logger=INFO,console
    log4j.rootLogger=${flume.root.logger}
  java_home_env:
    /usr/lib/jre_1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;事实上， 当想要在命令行查看已创建的配置字典内容， 使用&lt;code&gt;kubectl get config flume-config -o yaml&lt;/code&gt;时， 看到的也是上面的形式。&lt;/p&gt;

&lt;h2 id=&#34;在pod内使用configmap的几种方式&#34;&gt;在Pod内使用ConfigMap的几种方式&lt;/h2&gt;

&lt;h3 id=&#34;用于容器内的环境变量&#34;&gt;用于容器内的环境变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: java
spec:
  containers:
  - name: test-container
    image: alpine
    command: [ &amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;echo $JAVA_HOME&amp;quot; ]
    env:
    - name: JAVA_HOME
      valueFrom:
        configMapKeyRef:
          name: My-Config
          key: java_home_env
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的目录&#34;&gt;用于容器内的目录&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ &amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;ls /etc/config/&amp;quot; ]
      volumeMounts:
      - name: configDir
        mountPath: /etc/config
  volumes:
    - name: configDir
      configMap:
        # Provide the name of the ConfigMap containing the files you want
        # to add to the container
        name: My-Dir-ConfigMap
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的文件&#34;&gt;用于容器内的文件&lt;/h3&gt;

&lt;p&gt;要注意， 当使用配置字典作为容器内的配置文件时， 会将目标目录整个覆盖， 只保留配置字典中存在的&amp;rdquo;key&amp;rdquo;, 也就是对应的配置文件。&lt;br /&gt;
这样造成的后果就是不能够仅更新某个目录下面的单个文件。 例如如果想要用配置字典更新 &lt;code&gt;/etc/hosts&lt;/code&gt;文件， 那么会导致 &lt;code&gt;/etc&lt;/code&gt; 目录下的其他文件都被抹除。 因此使用时一定要小心。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
  - name: test-container
    image: k8s.gcr.io/busybox
    command: [ &amp;quot;/bin/sh&amp;quot;,&amp;quot;-c&amp;quot;,&amp;quot;cat /etc/config/keys&amp;quot; ]
    volumeMounts:
    - name: config-volume
      mountPath: /etc/config
  volumes:
  - name: config-volume
    configMap:
      name: special-config
      items:
      - key: SPECIAL_LEVEL
        path: keys
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;用于容器内的命令行&#34;&gt;用于容器内的命令行&lt;/h3&gt;

&lt;p&gt;配置字典对于命令行形式的配置没有直接的支持， 不过可以通过设置环境变量， 然后在命令行中使用环境变量来间接地实现。&lt;/p&gt;

&lt;h3 id=&#34;用于容器内的插件&#34;&gt;用于容器内的插件&lt;/h3&gt;

&lt;p&gt;配置字典用作容器内的文件时， 会将base64编码还原， 因此容器内进程看到的是一个完整的二进制文件， 而不是奇怪的编码。&lt;/p&gt;

&lt;h2 id=&#34;配置字典的更新&#34;&gt;配置字典的更新&lt;/h2&gt;

&lt;p&gt;当Pod已经运行， 此时再更新其挂载的配置字典， 那么容器内是否能够感知到配置的变更呢？ 这要取决于Pod使用配置字典的方式：
1. 如果是使用配置文件或者配置目录的形式， 那么当k8s集群的配置字典更新， 容器内挂载的文件也会同步更新。 因此对于一些能够监听配置文件变更并自动加载新配置的程序(如Apache Flume)来说， 不需要重启Pod就可以立刻应用新的配置。&lt;br /&gt;
2. 如果是使用命令行参数或环境变量的方式进行配置的， 由于环境变量是在创建容器的时候指定的， 因此无法随着配置字典的变更而变更。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>管理Kubernetes中的对象</title>
      <link>https://violinsonata.site/2019/lables/</link>
      <pubDate>Sat, 14 Sep 2019 10:51:55 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/lables/</guid>
      <description>

&lt;h2 id=&#34;namespace&#34;&gt;Namespace&lt;/h2&gt;

&lt;p&gt;Kubernetes 使用命名空间来进行隔离， 每个对象只能属于其中一个命名空间， 不通的命名空间之间相互隔离。&lt;/p&gt;

&lt;p&gt;值得一提的是， 命名空间也会影响到&lt;code&gt;Service&lt;/code&gt;的行为。 比如说， 当你在Kubernetes中的&amp;rdquo;Proxy&amp;rdquo;命名空间中创建了一个名为&amp;rdquo;Nginx&amp;rdquo;的服务， 那么此时它的全名将是&lt;code&gt;Nginx.Proxy.svc.cluster.local&lt;/code&gt;， 如果一个容器仅声明了&amp;rdquo;Nginx&amp;rdquo;, 那么kubernetes会将其分配在该容器所属的命名空间中。 这样一来， 你在开发，测试，生产环境中就不必一一更改环境配置了。&lt;/p&gt;

&lt;p&gt;然而， Kubernetes命名空间不允许嵌套， 因此这注定只能进行较粗粒度的隔离工作。 官方也不推荐使用命名空间进行细粒度的划分， 如相同应用的不同版本。&lt;/p&gt;

&lt;p&gt;说到底， 命名空间的设计初衷只是在多个团队使用同一个大规模的集群时， 提供一种互不打扰的方式。 而对于同一命名空间中的对象进行更细粒度的划分， Kubernetes官方推荐使用&lt;code&gt;Label&lt;/code&gt;进行管理。&lt;/p&gt;

&lt;h2 id=&#34;树形划分-vs-维度划分&#34;&gt;树形划分 vs 维度划分&lt;/h2&gt;

&lt;p&gt;分类一直是人类理解处理大量复杂事务的利器。 这其中有两个典型的分类方式： 按树形划分和按维度划分。&lt;/p&gt;

&lt;p&gt;树形划分就如同一棵树一样， 将所有物体分为若干大类， 每个大类内的物体又分为若干小类&amp;hellip;一直这样划分下去， 每个类别都有层次， 一个物体在同一层次只能属于一个类别。 整体看来就如同目录一样清晰分明。 科学界对生物的划分就属于这种分类， 界门纲目科属种， 层次分明， 清晰严谨。&lt;/p&gt;

&lt;p&gt;还有一种分类方式则不分层级， 而是给每个物体依据其特点打上不同的标签。 例如， 我们可以对一群人中的每个个体打上标签， 然后就可以通过标签方便的筛选出其中的&amp;rdquo;父亲&amp;rdquo;， &amp;ldquo;女性&amp;rdquo;, &amp;ldquo;5-10岁&amp;rdquo;等不同的子集。 这种分类方式弥补了树形分类只能以物体单一属性进行分类的缺陷， 可以关注物体不同的属性，因此我将其称为&amp;rdquo;按维度划分&amp;rdquo;。&lt;/p&gt;

&lt;h2 id=&#34;label&#34;&gt;Label&lt;/h2&gt;

&lt;p&gt;Kubernetes提供的&lt;code&gt;Label&lt;/code&gt;就是要求用户以维度划分的思想来管理统一命名空间内的多个对象, 乃至跨命名空间的对象。 为什么要用这种方式呢？ 因为设计者认为这种方式更加灵活， 可以从多个角度对目标进行管理， 减少操作次数， 从而简化管理。&lt;/p&gt;

&lt;p&gt;不过我个人认为， 标签虽然强大， 但是对于使用者提出了较高的要求。 如果想要如同理想情况那样管理对象， 团队成员还需要协商一套可以严格执行的标签规范， 以区分各自负责的对象而不会造成混乱 —— 也就是说， 这其实反而加大了管理的负担。&lt;/p&gt;

&lt;p&gt;Kubernetes的标签以键值对的形式存在。 &lt;code&gt;键&lt;/code&gt;是使用/分割的前缀和键名， 二者都可以随意设定， 且前缀可以省略， 但是支持的字符集仅为[a-z,0-9 A-Z.-_]。 &lt;code&gt;值&lt;/code&gt;没有前缀，其他要求和键一样。&lt;/p&gt;

&lt;p&gt;一个对象的标签可以在对象的&lt;code&gt;metadata&lt;/code&gt;属性中指定，就像下面这样。 换句话说， 任何拥有&lt;code&gt;metadata&lt;/code&gt;属性的Kubernetes对象， 都可以用标签来进行管理。 这几乎囊括了Kubernets中所有的对象。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  labels:
    this-is-a-key: this-is-a-value
    another_key:  another_value
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;selector&#34;&gt;Selector&lt;/h2&gt;

&lt;p&gt;那么为对象设定了标签之后， 要怎样通过它来实现管理呢？ 这就要用到Kubernetes提供的另一个功能：&lt;code&gt;标签选择器(Label Selector)&lt;/code&gt;。 每当我们要做出一个操作， 都可以在yaml文件中设置标签选择器， Kubernetes只会对那些通过了选择器筛选的对象执行操作。&lt;/p&gt;

&lt;p&gt;选择器也是一个键值对的列表， 每一行都是一个匹配规则， 各个规则之间是&lt;code&gt;AND&lt;/code&gt;关系。 也即是说，Kubernetes会对该命名空间内所有对象的标签进行匹配， 找出满足了选择器中声明的所有匹配规则的对象。 任何一个规则不匹配， 那么就不会对该对象执行操作。&lt;/p&gt;

&lt;p&gt;在进行匹配时， Kubernetes会选出键相同的对象，然后再比较值。 如果都相等，则算是匹配成功。 而具体到值的指定， 有两种方案：&lt;code&gt;Equality-based&lt;/code&gt;和&lt;code&gt;Set-based&lt;/code&gt;, 基于相等的选择器和基于集合的选择器。 基于相等的选择器只能指定一个值， 而基于集合的选择器可以指定多个值组成一个集合， 只要对象的相同的键所对应的值位于该集合中， 就算是匹配成功。 当然， 除了相等之外， 同样也允许反向匹配， 也就是”不等于该值&amp;rdquo;或&amp;rdquo;不属于该集合&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;说实话我个人觉得在设计方面此处的标签匹配功能强大灵活， 但是在语法设计方面有些糟糕。 没必要专门设计两个选择器， 所有的都用集合选择器就好了。 如果需要匹配单个值， 那么只需声明一个单值的集合就好。 而且既然标签不允许特殊字符， 那么使用特殊字符在选择器的值作为分隔符不是更好么而且既然标签不允许特殊字符， 那么使用特殊字符在选择器的值作为分隔符, 以这种形式声明列表不是更好么。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;selector:
- 0-key: 0-value
- a-key: value1, value2, value3
- b-key: !value
- !c-key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等价于:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;selector:
  matchLabels:
  - 0-key: 0-value
  matchExpressions:
  - key: a-key
    operator: In
    values:
    - value1
    - value2
    - value3
  - key: b-key
    operator: NotIn
    values:
    - value
  - key: c-key
    operator: DoesNotExist
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Flume: 日志收集、聚合、归档工具</title>
      <link>https://violinsonata.site/2019/flume/</link>
      <pubDate>Sun, 24 Mar 2019 16:24:47 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/flume/</guid>
      <description>&lt;p&gt;在大数据时代， 计算机技术已经不是阻碍各大互联网公司发展的壁垒——在开源浪潮下， 所有的技术都是共享的。 甚至初创公司的技术栈会比大公司的更新更先进。 在这样的背景下， 只有数据是最珍贵的， 所有的公司都将自己搜集到的用户数据视若珍宝， 从中进行大数据分析以更好的抓住用户。&lt;/p&gt;

&lt;p&gt;那么数据是从哪里来的呢？毫无疑问日志是用户数据最好的来源。 以前的日志只是用来记录服务本身的运行状态， 只要服务不出问题， 那么没有人会去查看日志， 最多为了避免单个文件过大难以查阅， 写个定时任务将日志拆分成多个小文件。 即便服务出了故障， 查看一个月以前的日志也没什么帮助(除了少数特殊情况)， 因此 为了避免日志无限堆积占用磁盘空间， 通常还会有另一个定时任务负责把太久远的日志文件删除。&lt;/p&gt;

&lt;p&gt;然而自从各大互联网公司发现了用户数据的价值之后， 一切都变了：日志不再单纯记录服务本身的信息， 也开始记录用户的基本信息与行为记录， 服务器接受的每一次请求都将记录下至少一条信息， 虽然通常这两类日志不会记录到同一个文件里， 但依然无法阻挡后一种日志文件的容量增长急速上升；为了应对增长更快的文件尺寸， 也为了能更快地分析即时用户数据， 日志文件拆分的频率越来越高， 从每周， 每天， 到每小时甚至每分钟；而那些从前的日志文件也不能随便删除了：那可都是有价值的用户数据呢！可是面对这样大量的数据， 不能把他们一直存在服务器上吧， 这样既会给服务器带来巨大的负担， 而且也难以访问从而分析这些数据。 因此， OLAP出现了， Hadoop出现了， 这些分析专用的系统正是为了存储分析大量日志及用户数据而设计的。&lt;/p&gt;

&lt;p&gt;但是随之而来了新的问题：怎样将日志数据存储到这些分析数据库呢？&lt;/p&gt;

&lt;p&gt;Flume， 一个专为转运日志数据的系统应运而生。 Flume是一个用于收集、过滤、聚合、转运大量日志数据的工具， 其具有分布式， 高可靠， 高可用等特点。  而其运行却可以不依赖任何第三方服务， 只要有 JRE1.8 以上的Java运行环境即可。 整体可以说是简洁轻便， 灵活轻量。&lt;/p&gt;

&lt;p&gt;配置方面， 为了易于理解， 它使用一个简洁的数据模型来定义线上服务的配置：&lt;br /&gt;
&lt;img src=&#34;https://flume.apache.org/_images/DevGuide_image00.png&#34; alt=&#34;image&#34; /&gt;&lt;br /&gt;
其中一些基本概念如下：&lt;br /&gt;
- &lt;strong&gt;Source&lt;/strong&gt;： 收集数据——从数据源处读取数据， 封装成一个个的Events后发送到Channel。&lt;br /&gt;
- &lt;strong&gt;Channel&lt;/strong&gt;： 传输数据——负责以Event形式暂存数据。 之所以存在Channel而不是直接由Source端向Sink端发送数据是因为Source端读取数据的速度通常不是恒定的， 毕竟日志数据产生的快慢谁也无法掌握， 所以将数据存入Channel用于做个缓冲， 起到削峰填谷的作用。&lt;br /&gt;
- &lt;strong&gt;Sink&lt;/strong&gt;： 存储数据——数据的写入端。 负责从Channel端取出Event， 解封成原始数据， 存入目标位置。&lt;br /&gt;
- &lt;strong&gt;Agent&lt;/strong&gt;： 一个完整的Flume配置的最小单位。 一个Agent代表把数据从原始位置转移至目标位置的过程。 一个典型的Agent包含一个Source, 一个Channel， 一个Sink。 不过这并不是说想要启动一个Flume进程就必须凑齐这三个组件， 其实Source， Sink， Channel三部分可以部署在不同的服务器上， 例如在生成日志的服务器上配置一个Source用于收集日志， 然后配置一个远程服务如Kafka作为Channel， 以无Sink的形式启动一个Flume进程， 而在数据库服务器上， 同样配置一个Kafka Channel用于接收Kafka中的日志数据， 然后配置一个SQL Sink用于将日志存入数据库， 从而实现分布式配置。&lt;br /&gt;
- &lt;strong&gt;Event&lt;/strong&gt;：以字节形式按行封装数据， 除此之外每个Event还包含一个数据头， 可以以Key-Value形式存储了一些用户自定义的元数据。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&lt;译&gt;并发模型</title>
      <link>https://violinsonata.site/2019/concurrency-model/</link>
      <pubDate>Sat, 02 Mar 2019 19:23:36 +0800</pubDate>
      
      <guid>https://violinsonata.site/2019/concurrency-model/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;本文翻译自 &lt;a href=&#34;http://tutorials.jenkov.com/java-concurrency/index.html&#34;&gt;http://tutorials.jenkov.com/java-concurrency/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;并发系统可以使用不同的并发模型来实现。&lt;code&gt;并发模型&lt;/code&gt;阐述了系统中的多个线程怎样合作来完成给定的任务。不同的并发模型把任务按照不同的方式拆分，且线程之间或许通过不同的方式来通信和协作。这篇文章比较深入地介绍了截至当前(2015年)最流行的几个并发模型。&lt;/p&gt;

&lt;h2 id=&#34;并发模型和分布式系统的相似性&#34;&gt;并发模型和分布式系统的相似性&lt;/h2&gt;

&lt;p&gt;这篇文章中介绍的几种并发模型和不同的分布式系统架构十分相似。在一个并发的操作系统中，不同的线程之间会互相通信；在分布式系统中，不同的进程会互相通信(或许它们位于不同的计算机):进程和线程实际上非常相似。这就是不同的并发模型看起来和不同的分布式系统架构十分相似的原因。&lt;/p&gt;

&lt;p&gt;当然，分布式系统还会面临更多额外的挑战比如网络失败，或者远端计算机宕机等。不过运行在大型服务器上的并发操作系统也有可能会面临相似的问题，比如某个CPU、网卡、磁盘挂掉了之类的。遇到这种事的可能性会很低，但在理论上依然会发生。(译注:现在的服务器上确实会配备多个CPU，网卡及磁盘。这样的设计一方面是为了提高服务器性能，另一方面也是出于可用性考虑。也就是说，某个硬件坏掉并不只是理论上的可能，它确实会发生。)&lt;/p&gt;

&lt;p&gt;正因为并发模型和分布式系统架构如此相似，它们经常可以互相借鉴经验。例如，在多个线程之间分派任务的模型通常与分布式系统的负载均衡模型相似。还有错误处理技术如日志，故障切换(fail-over), 幂等也都相同。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&#34;并行执行模型&#34;&gt;并行执行模型&lt;/h2&gt;

&lt;p&gt;第一个并发模型被称为&lt;code&gt;并行执行&lt;/code&gt;。输入的任务被分派给不同的执行者。如下图所示:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/02/kq1Uzj.png&#34; alt=&#34;image&#34; /&gt;
在并行执行模型中，分派者把任务拆分并分派给不同的执行者。每个执行者都可以完成分派下来的整个任务。所有的执行者在不同的线程中并行地执行，这些线程或许是在不同的CPU上。&lt;/p&gt;

&lt;p&gt;想象一家汽车厂实现了并行工作模型，每个执行者都将会生产一辆汽车。单个执行者将会从头到尾地生产分派给他的那辆特定的汽车。&lt;/p&gt;

&lt;p&gt;并行执行模型是在Java应用中最常用的并发模型(尽管现在正渐渐改变)。&lt;code&gt;Java.util.concurrent&lt;/code&gt; 包中有许多并发工具都是为了这个模型准备的。&lt;/p&gt;

&lt;h2 id=&#34;并行执行的优点&#34;&gt;并行执行的优点&lt;/h2&gt;

&lt;p&gt;并行执行模型的优点就是易于理解。如果要提高并发程度，只需要增加执行者的数量就可以了。&lt;/p&gt;

&lt;p&gt;例如，你要实现实现一个网络爬虫，你可以利用不同数量的执行者线程来爬取相同总数量的页面，然后比较使用多少执行者可以在最短时间内完成任务(也就是性能最高)。因为网络爬虫是一个对IO敏感的任务，因此或许你会发现每个CPU执行少量线程是个最好的选择。每个CPU一个线程就太少了，因为这将会花费大量的时间在等待数据下载。&lt;/p&gt;

&lt;h2 id=&#34;并行执行的缺点&#34;&gt;并行执行的缺点&lt;/h2&gt;

&lt;p&gt;在简单易于理解的外表下，并行执行模型也有一些缺点，下面将介绍其中最显著的几个。&lt;/p&gt;

&lt;h3 id=&#34;分享状态会带来复杂度&#34;&gt;分享状态会带来复杂度&lt;/h3&gt;

&lt;p&gt;在现实中并行执行模型比上面阐述的要复杂一些。每个执行者常常需要访问一些公共的数据，可能在内存，也可能在数据库。如下图所示:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/02/kq1NWQ.png&#34; alt=&#34;image&#34; /&gt;
这些状态有时候通过一些通信机制来共享，如任务队列。但有些状态是业务数据，数据缓存，数据库连接池等等。&lt;/p&gt;

&lt;p&gt;一旦引入了共享的状态，那么事情就变得复杂了。线程之间需要一种机制来保证某一个线程对共享数据做出的变更对于其他线程来说是可见的(需要将新的数据直接推到主存中而不是缓存在某个CPU自己的cache中)。线程之间要避免竞态条件，死锁，以及其他许多共享状态的并发问题。&lt;/p&gt;

&lt;p&gt;另外，当线程在访问共享数据时的互相等待行为也会造成并发性的丢失。许多并发的数据结构是阻塞性的，意味着任何时间只能由一个或一小部分线程能同时访问它们，这将导致在访问这类数据结构时会发生竞争。激烈的竞争将导致访问这类数据结构的那部分代码在一定程度上变成串行执行的。&lt;/p&gt;

&lt;p&gt;现代的&lt;code&gt;非阻塞并发算法&lt;/code&gt;在一定程度上可以降低竞争以提升性能，但非阻塞算法的实现非常复杂。&lt;/p&gt;

&lt;p&gt;另一个选择是使用持久数据结构。它在修改时始终保留自身的先前版本。这样一来，如果多个线程指向了同一个持久数据结构并且其中某个线程修改了数据，这个线程将获取一个指向新数据结构的引用。所有其他的线程依然持有指向旧版本数据结构的引用。Scala语言包含了几个这样的持久数据结构。&lt;/p&gt;

&lt;p&gt;持久数据结构是并发修改状态的一个优雅的解决方案，但也不是万能的。&lt;/p&gt;

&lt;p&gt;例如，一个持久的链表会将所有的新节点插入链表头部，并返回一个指向新节点的引用。当一个线程插入新数据之后，所有其他线程仍将持有指向前一个版本的头节点的引用，然而如今那已经是事实上的第二个节点了。也就是对于其他线程来说，这个链表的变更是不可见的。&lt;/p&gt;

&lt;p&gt;持久链表的底层实现是链表，然而链表在现代硬件上的性能并不太好。链表中的每个元素都是分离开的，这些元素的分布甚至可能跨越整个内存区域。现代CPU在顺序访问数据的时候是非常快的，所以在现代的硬件上用数组的性能比用链表快得多，因为数组就是按顺序存放数据的。CPU缓存可以一次载入数组中的一大块数据，然后这部分数据就可以直接在CPU缓存中读取了。同样的事在使用链表存放数据时几乎不可能发生。&lt;/p&gt;

&lt;h3 id=&#34;无状态执行者&#34;&gt;无状态执行者&lt;/h3&gt;

&lt;p&gt;共享的状态或许会被操作系统中的其他线程更改，因此每次需要该状态的时候都不得不重新读入，以此来保证自己持有的状态是最新的。无论共享的状态是在内存中，还是数据库中都必须如此。一个本身不持有状态，但是每次需要都重新去读取状态的执行者，被称为&lt;code&gt;无状态的&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;每次都重新读取状态信息是很慢的，尤其是状态被存储在外部数据库的时候。&lt;/p&gt;

&lt;h3 id=&#34;任务的执行顺序是不确定的&#34;&gt;任务的执行顺序是不确定的&lt;/h3&gt;

&lt;p&gt;并行执行模型的另一个缺陷是任务的执行顺序是不可知的。没有什么手段可以保证哪个任务先执行，哪个任务后执行。&lt;/p&gt;

&lt;p&gt;非确定的执行顺序带来的后果就是很难确定某一个时间点整个系统的状态。同样也很难保证一个特定任务在另一特定任务之前执行。&lt;/p&gt;

&lt;h2 id=&#34;流水线&#34;&gt;流水线&lt;/h2&gt;

&lt;p&gt;第二个并发模型我将其称为&lt;code&gt;流水线模型&lt;/code&gt;。其他开发者根据其社区或平台的不同会使用不同的名称(例如交互式系统/事件驱动系统)。下图解释了流水线模型的模式。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9pcG9.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;多个执行者的组织方式就像是工厂里面流水线旁边的工人们一样。每个执行者仅仅处理自己的一部分任务。这一个执行者做完了，下一个执行者接上。&lt;/p&gt;

&lt;p&gt;每个执行者都是一个单独的线程，且每个执行者之间没有共享的状态。因此有时该模型也被称为&lt;code&gt;无共享并发模型&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;使用流水线模型的系统通常是被设计用来*无阻塞*地进行IO。无阻塞地IO的意思是当一个执行者开始一个IO操作的时候(例如从网络中读取一个文件或一些数据)，这个执行者不必阻塞地等待这个IO操作结束。IO操作是很耗时的，所以阻塞地等待IO操作是对于CPU资源的浪费。CPU这个时候可以分配给其他的 执行者，当IO操作完成的时候，操作结果(例如读取到的数据或文件)再传递给那个执行者。&lt;/p&gt;

&lt;p&gt;得益于无阻塞IO的特性，可以将IO操作作为多个执行者之间切换的边界。一个执行者可以尽情地占用CPU资源来执行任务，直到它不得不开始一次IO操作，此时它将交出CPU资源。当IO操作完成之后，流水线上的下一个执行者将继续工作，直到它也遇到了一次IO操作。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9CRHK.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;事实上，整个任务或许不会仅仅由一条流水线组成。大多数系统都可以同时运行多个任务，从执行者到执行者之间的任务流取决于任务本身。事实上，一个任务或许会同时有多个不同的虚拟流水线。因此看起来将是下面这样:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9Pwrt.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一个任务甚至可以传递给多个执行者来并发的进行处理。例如，一个任务可以同时传递给给一个excutor和一个Logger。下图展示了三条流水线将它们的任务传递给同一个执行者来结束各自的任务:
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A9PIaT.png&#34; alt=&#34;image&#34; /&gt;
当然流水线模型可以做得比这复杂得多。&lt;/p&gt;

&lt;h3 id=&#34;交互与事件驱动的系统&#34;&gt;交互与事件驱动的系统&lt;/h3&gt;

&lt;p&gt;使用流水线模型的系统有时也被称为交互式系统或事件驱动的系统。系统内的执行者们对于系统内发生的事件做出响应，无论是事件是来自系统之外还是来自于系统内其他的执行者。所谓事件的典型例子是HTTP请求，或者将一个文件载入内存完成。&lt;/p&gt;

&lt;p&gt;在写这篇文章时已经有一些有趣的交互式/事件驱动的平台，未来还会有更多。这些平台包括:
- Vert.x
- Akka
- Node.Js&lt;/p&gt;

&lt;h3 id=&#34;actors-vs-channels&#34;&gt;Actors vs. Channels&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Actors模型&lt;/code&gt;和&lt;code&gt;Channels模型&lt;/code&gt;是流水线模型的两个相似的案例。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;Actors模型&lt;/code&gt;中每个执行者被叫做&lt;code&gt;Actor&lt;/code&gt;。Actor相互之间可以直接发送消息。这些消息会被异步地发送和处理。Actor可以用来实现一个或多个上面讨论的流水线,如下图所示。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A91xcq.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;Channel模型&lt;/code&gt;中，执行者之间不会直接通信。相反他们会通过不同的channel来发布消息(或事件)，而不关心谁会订阅到这些消息；其他执行者可以订阅这些channel来接收消息，也不关心是谁发布了这些消息。该模型如下图所示。
&lt;img src=&#34;https://s2.ax1x.com/2019/03/10/A93B5Q.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一个执行者不必知道哪一个执行者接下来会继续执行任务。它只需要关心应该将任务或消息传递给哪个channel。接收消息的执行者可以订阅或取消订阅channels而不会对发布者造成任何影响。这可以降低执行者之间的耦合度。&lt;/p&gt;

&lt;h2 id=&#34;流水线模型的优势&#34;&gt;流水线模型的优势&lt;/h2&gt;

&lt;p&gt;与并行执行模型相比，流水线模型有如下几个优势。&lt;/p&gt;

&lt;h3 id=&#34;没有共享的状态&#34;&gt;没有共享的状态&lt;/h3&gt;

&lt;p&gt;各个执行者之间没有共享的状态，这意味着实现每个执行者的时候，不需要考虑那些在并行执行模型中很常见的并发问题。这使得实现更加简洁，你实现一个执行者的时候可以假装它就是一个唯一的线程。&lt;/p&gt;

&lt;h3 id=&#34;有状态的执行&#34;&gt;有状态的执行&lt;/h3&gt;

&lt;p&gt;既然每个执行者都确认不会有其他执行者来修改它自己的数据，那么一个执行者就可以是有状态的了。在这里&amp;rdquo;有状态&amp;rdquo;的意思是一个执行者可以在内存中持有它需要的数据，只把修改了的部分写回外部存储之中。因此一个有状态的执行者比无状态的执行者的执行效率要高一些。&lt;/p&gt;

&lt;h3 id=&#34;更好的硬件适配性&#34;&gt;更好的硬件适配性&lt;/h3&gt;

&lt;p&gt;单线程的代码还有个优势就是它通常更适配底层硬件的工作方式。&lt;/p&gt;

&lt;p&gt;首先，当你确认代码在单线程环境下工作室，你通常可以设计更强大的数据结构和算法。&lt;/p&gt;

&lt;p&gt;其次，单线程的有状态执行者可以向上面提到的那样在内存中持有数据。如果一段数据保存在内存中，那么同样很有可能会缓存在CPU的cache中。这可以进一步提高访问数据的速度。&lt;/p&gt;

&lt;p&gt;我将这种更适应底层硬件工作机制的代码组织方式称为&lt;code&gt;硬件适配性&lt;/code&gt;(hardware confirmity)。有些开发者将其称为&lt;code&gt;mechanical sympathy&lt;/code&gt;。我更喜欢前者因为计算机很少有固定的部分，并且&amp;rdquo;sympathy&amp;rdquo;这个词在这里所暗示的&amp;rdquo;更加匹配&amp;rdquo;的意思，我觉得使用&amp;rdquo;confirm&amp;rdquo;这个词会表达地更加贴切。好吧，这都不重要，随你喜欢用哪个都行。&lt;/p&gt;

&lt;h3 id=&#34;安排任务顺序是可行的&#34;&gt;安排任务顺序是可行的&lt;/h3&gt;

&lt;p&gt;在使用流水线模型的并发系统中安排每个执行者的先后顺序是可行的。执行顺序可以确定，那么在任意时间点确认整个系统的状态也就成为了可能。此外，你可以把所有的任务都记下日志。而这份日志可以在日后系统崩溃时用于重建整个系统的状态。所有任务以一种确定的顺序写入日志，这也就是执行者顺序的保证。&lt;/p&gt;

&lt;p&gt;保证任务的执行顺序不是一件容易的事，但是却经常会有这样的需求。如果可以，这能够大幅简化类似备份，数据恢复，数据主从复制之类的任务——所有这些同可以通过日志实现。&lt;/p&gt;

&lt;h2 id=&#34;流水线模型的缺陷&#34;&gt;流水线模型的缺陷&lt;/h2&gt;

&lt;p&gt;流水线模型的一个缺陷在于，一个任务经常会在项目中的多个执行者以及类之间传播，因此对于一个给定的任务，很难去观察当前正在执行的究竟是哪段代码。&lt;/p&gt;

&lt;p&gt;另外写代码或许也会更难。执行者的代码有时候会被写成回调(callback handler)形式。多层嵌套的回调被开发者们称为&lt;code&gt;回调深渊&lt;/code&gt;。回调深渊很直白地说明横跨整个回调流程去追踪代码的执行位置是极其困难的。确认是否每个回调流程代码都访问了它需要的数据同样是极难的。&lt;/p&gt;

&lt;p&gt;在并发执行模型中，做到这一点或许还简单点。你可以找到执行者的代码，从头到尾读下来。当然，并行执行模型的代码同样会使任务横跨许多不同的类，但是通常顺序执行的代码可读性更高一些。&lt;/p&gt;

&lt;h2 id=&#34;函数式编程&#34;&gt;函数式编程&lt;/h2&gt;

&lt;p&gt;函数式并行是近几年(2015)经常被讨论的并发模型。&lt;/p&gt;

&lt;p&gt;该模型的基本思路是你可以通过函数调用的方式来实现程序。函数可以视为可以互相发送消息的&amp;rdquo;代理(agents)&amp;ldquo;或&amp;rdquo;参与者(actors)&amp;ldquo;,就像是流水线模型中的那样。当一个函数调用其它函数时，就如同发送了一个消息一样。&lt;/p&gt;

&lt;p&gt;传递给函数的所有参数都是拷贝值，所以一个函数无法修改该函数之外的实体的数据。这种必要的拷贝可以避免共享数据上的竞态条件。这使得函数式的执行过程就像是原子操作一样。每个函数调用相互之间都是相互独立的。&lt;/p&gt;

&lt;p&gt;既然每次函数调用之间是互相独立的，那么它们当然可以分配给不同的CPU来并行地执行。这意味着如果一个算法是用函数式的方式实现的，那么它就可以同时在多个CPU上并行地执行。&lt;/p&gt;

&lt;p&gt;在Java7的&lt;code&gt;java.util.concurrent&lt;/code&gt;包中有一个&lt;code&gt;ForkAndJoinPool&lt;/code&gt;可以帮你实现类似于函数式编程的机制。而在Java8中我们有了&lt;code&gt;streams&lt;/code&gt;机制可以帮助你并行地迭代大的集合。要注意有些开发者对于&lt;code&gt;ForkAndJoinPool&lt;/code&gt;持批评的态度。&lt;/p&gt;

&lt;p&gt;函数式编程并行的难点在于确定将哪个函数并行地执行。跨多个CPU进行合作的函数会带来开销。并行执行的函数所完成的那部分任务量应该值得花费这些开销。如果一个函数很小，尝试将它们并行或许反而会比单线程单CPU执行更慢。&lt;/p&gt;

&lt;p&gt;按照我的理解，如果你可以用函数式编程实现一个算法，那么同样也可以用流水线模型来相似的实现。使用事件驱动模型，你可以更多地控制哪些需要并行，需要什么程度的并行。&lt;/p&gt;

&lt;p&gt;另外，只有当将被拆分的任务是程序中当前正在执行的唯一一个任务时，考虑将任务拆分并分派到多个CPU并行执行才有意义。而如果系统此时正在执行多个不同的任务(例如Web服务器，数据库服务以及其他各种任务),将一个任务拆分成并行执行是没有意义的。因为计算机内的其他CPU此时正忙于处理系统内其他的任务，所以没有理由将任务分布式的方式更低效地执行。此时你更应该考虑用流水线模型来处理，因为它的开销更小(在单线程环境下顺序地执行)并且有更好的硬件适配性。&lt;/p&gt;

&lt;h2 id=&#34;哪个并发模型最好&#34;&gt;哪个并发模型最好？&lt;/h2&gt;

&lt;p&gt;那么，哪个并发模型是最好的呢？&lt;/p&gt;

&lt;p&gt;通常来说，这取决于你希望用你的系统做什么。如果你的任务天然就是并行的，每一部分都是独立的且没有共享状态，那么你或许可以使用并行执行模型。&lt;/p&gt;

&lt;p&gt;许多任务并不是天然并行和独立的。在这种情况下我认为相比于并行模型，流水线模型可能更合适。&lt;/p&gt;

&lt;p&gt;你不需要从底层实现流水线模型，许多现代的平台比如&lt;code&gt;Vert.x&lt;/code&gt;已经帮你做了很多。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>